{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyn_kq4DFr5M",
        "outputId": "4f0037e8-0833-410b-9a47-5b9f1a17ab9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import traceback\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "print('Bibliotecas importadas com sucesso!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqrBpZ2BFr5N",
        "outputId": "1e9eacf2-01d0-4915-de5b-3e2afd5a7e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset baixado do GitHub e salvo em cache\n",
            "Dataset carregado: (7744, 23)\n",
            "Colunas: ['Country', 'Year', '0', '1', '5', '10', '15', '20', '25', '30', '35', '40', '45', '50', '55', '60', '65', '70', '75', '80', '85', '90', 'Gender']\n",
            "\n",
            "Primeiras linhas:\n",
            "   Country  Year        0        1        5       10       15       20  \\\n",
            "0        0  1950  0.02836  0.00182  0.00089  0.00076  0.00138  0.00206   \n",
            "1        0  1951  0.02832  0.00189  0.00081  0.00077  0.00169  0.00223   \n",
            "2        0  1952  0.02791  0.00171  0.00069  0.00064  0.00156  0.00203   \n",
            "3        0  1953  0.02632  0.00170  0.00076  0.00069  0.00153  0.00189   \n",
            "4        0  1954  0.02558  0.00176  0.00064  0.00062  0.00146  0.00183   \n",
            "\n",
            "        25       30  ...       50       55       60       65       70  \\\n",
            "0  0.00164  0.00188  ...  0.01097  0.01736  0.02767  0.04246  0.06596   \n",
            "1  0.00183  0.00193  ...  0.01125  0.01843  0.02888  0.04370  0.06585   \n",
            "2  0.00185  0.00188  ...  0.01124  0.01791  0.02854  0.04394  0.06474   \n",
            "3  0.00165  0.00177  ...  0.01064  0.01718  0.02711  0.04100  0.06427   \n",
            "4  0.00171  0.00180  ...  0.01050  0.01694  0.02633  0.04107  0.06560   \n",
            "\n",
            "        75       80       85        90  Gender  \n",
            "0  0.10047  0.14520  0.22969  0.315457       0  \n",
            "1  0.10323  0.14723  0.23061  0.357143       0  \n",
            "2  0.10028  0.14528  0.21930  0.324675       0  \n",
            "3  0.09634  0.13970  0.22124  0.310559       0  \n",
            "4  0.10249  0.14020  0.22655  0.324675       0  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "# Carregar os dados\n",
        "url = \"https://raw.githubusercontent.com/cleodecker/tcc/main/df_all.csv\"\n",
        "cache_file = \"df_all.csv\"\n",
        "\n",
        "if not os.path.exists(cache_file):\n",
        "    df = pd.read_csv(url)\n",
        "    df.to_csv(cache_file, index=False)\n",
        "    print(\"Dataset baixado do GitHub e salvo em cache\")\n",
        "else:\n",
        "    df = pd.read_csv(cache_file)\n",
        "    print(\"Dataset carregado do cache local\")\n",
        "print(f'Dataset carregado: {df.shape}')\n",
        "print(f'Colunas: {list(df.columns)}')\n",
        "print(f'\\nPrimeiras linhas:')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_2wydRlbFr5O"
      },
      "outputs": [],
      "source": [
        "# Função para calcular sMAPE\n",
        "def smape(y_true, y_pred):\n",
        "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "\n",
        "# Função para calcular intervalos de confiança\n",
        "def calculate_confidence_intervals(predictions, residuals, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calcula intervalos de confiança baseados nos resíduos do modelo\n",
        "    \"\"\"\n",
        "    alpha = 1 - confidence\n",
        "    std_residuals = np.std(residuals)\n",
        "    z_score = 1.96  # Para 95% de confiança\n",
        "\n",
        "    margin_error = z_score * std_residuals\n",
        "    lower_bound = predictions - margin_error\n",
        "    upper_bound = predictions + margin_error\n",
        "\n",
        "    return lower_bound, upper_bound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q7bAYxcvFr5P"
      },
      "outputs": [],
      "source": [
        "# Função de pré-processamento\n",
        "def preprocess_data(df, country_code=49, sequence_length=10):\n",
        "    \"\"\"\n",
        "    Pré-processa dados para modelo LCCNN com transformação log + normalização\n",
        "    para ambos os sexos (0 e 1) simultaneamente.\n",
        "\n",
        "    Retorna:\n",
        "        dict_processed: Dicionário com estrutura {gender: {age_group: processed_data}}\n",
        "        dict_scalers: Dicionário com scalers {gender: {age_group: scaler}}\n",
        "        metadata: Informações adicionais\n",
        "    \"\"\"\n",
        "    # Converter country_code se necessário\n",
        "    if isinstance(country_code, str):\n",
        "        country_code = int(country_code)\n",
        "\n",
        "    # Filtrar dados do país\n",
        "    country_data = df[df['Country'] == country_code].copy()\n",
        "\n",
        "    if country_data.empty:\n",
        "        print(f'AVISO: Nenhum dado encontrado para País={country_code}')\n",
        "        return None, None, None\n",
        "\n",
        "    print(f'Dados do país {country_code}: {len(country_data)} registros')\n",
        "\n",
        "    # Identificar colunas de idade\n",
        "    exclude_cols = ['Country', 'Year', 'Gender']\n",
        "    age_columns = sorted([col for col in df.columns if col not in exclude_cols],\n",
        "                         key=lambda x: int(x))\n",
        "\n",
        "    # Estruturas para armazenamento\n",
        "    dict_processed = {0: {}, 1: {}}\n",
        "    dict_scalers = {0: {}, 1: {}}\n",
        "    metadata = {\n",
        "        'years': sorted(country_data['Year'].unique()),\n",
        "        'age_columns': age_columns\n",
        "    }\n",
        "\n",
        "    # Processar cada gênero separadamente\n",
        "    for gender in [0, 1]:\n",
        "        print(f'\\nProcessando gênero {gender}...')\n",
        "        gender_data = country_data[country_data['Gender'] == gender].sort_values('Year')\n",
        "\n",
        "        for age_col in age_columns:\n",
        "            # Extrair série temporal\n",
        "            time_series = gender_data[age_col].values.reshape(-1, 1)\n",
        "\n",
        "            # Aplicar transformação logarítmica\n",
        "            log_series = np.log1p(time_series)\n",
        "\n",
        "            # Normalizar\n",
        "            scaler = MinMaxScaler()\n",
        "            normalized_data = scaler.fit_transform(log_series)\n",
        "\n",
        "            # Criar sequências\n",
        "            X, y = [], []\n",
        "            sequence_years = []\n",
        "\n",
        "            for i in range(sequence_length, len(normalized_data)):\n",
        "                X.append(normalized_data[i-sequence_length:i, 0])\n",
        "                y.append(normalized_data[i, 0])\n",
        "                sequence_years.append(gender_data['Year'].iloc[i])\n",
        "\n",
        "            if len(X) > 0:\n",
        "                dict_processed[gender][age_col] = {\n",
        "                    'X': np.array(X),\n",
        "                    'y': np.array(y),\n",
        "                    'original_data': time_series.flatten(),\n",
        "                    'sequence_years': np.array(sequence_years)\n",
        "                }\n",
        "                dict_scalers[gender][age_col] = scaler\n",
        "\n",
        "                # Verificação básica\n",
        "                n_sequences = len(X)\n",
        "                min_year = min(sequence_years)\n",
        "                max_year = max(sequence_years)\n",
        "                print(f'  Grupo {age_col}: {n_sequences} sequências ({min_year}-{max_year})')\n",
        "\n",
        "    return dict_processed, dict_scalers, metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wzsAgYQlFr5P"
      },
      "outputs": [],
      "source": [
        "# Função LCCNN\n",
        "def create_lccnn_model(sequence_length=10, n_features=1):\n",
        "    \"\"\"\n",
        "    Cria modelo LCCNN (CNN + LSTM) aprimorado com:\n",
        "    - Camadas convolucionais para extração de características locais\n",
        "    - Funções de ativação ReLU\n",
        "    - Regularização L2\n",
        "    - Batch Normalization\n",
        "    - Ajuste de hiperparâmetros\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # Bloco Convolucional 1\n",
        "        Conv1D(filters=64, kernel_size=3, activation='relu',\n",
        "               input_shape=(sequence_length, n_features),\n",
        "               padding='same', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Bloco Convolucional 2\n",
        "        Conv1D(filters=128, kernel_size=3, activation='relu',\n",
        "               padding='same', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        # Camadas LSTM\n",
        "        LSTM(100, return_sequences=True,\n",
        "             kernel_regularizer=l2(0.001)), # Fix: Removed the misplaced parenthesis here\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        LSTM(50, return_sequences=False,\n",
        "             kernel_regularizer=l2(0.001)),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        # Camadas Densas\n",
        "        Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)  # Camada de saída (sem ativação para regressão)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "                  loss='mse',\n",
        "                  metrics=['mae', 'mse'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processar dados para o país (ambos os gêneros)\n",
        "print('=== PROCESSANDO DADOS PARA PAÍS 49 (BRASIL) ===')\n",
        "processed_data, scalers_dict, metadata = preprocess_data(df, country_code=49, sequence_length=10)\n",
        "\n",
        "if processed_data is not None:\n",
        "    # Separar dados por gênero\n",
        "    data_male = processed_data[0]   # Dados para homens (gender=0)\n",
        "    scalers_male = scalers_dict[0]\n",
        "\n",
        "    data_female = processed_data[1] # Dados para mulheres (gender=1)\n",
        "    scalers_female = scalers_dict[1]\n",
        "\n",
        "    # Metadados\n",
        "    age_cols = metadata['age_columns']\n",
        "    years = metadata['years']\n",
        "\n",
        "    print(f'\\nDados processados:')\n",
        "    print(f'Grupos etários: {len(age_cols)}')\n",
        "    print(f'Anos disponíveis: {min(years)} - {max(years)}')\n",
        "    print(f'  Homens: {len(data_male)} grupos etários com dados')\n",
        "    print(f'  Mulheres: {len(data_female)} grupos etários com dados')\n",
        "\n",
        "    # Verificar um grupo específico para homens\n",
        "    sample_age_group = age_cols[0]\n",
        "    if sample_age_group in data_male:\n",
        "        male_sample = data_male[sample_age_group]\n",
        "        print(f\"\\nExemplo grupo masculino '{sample_age_group}':\")\n",
        "        print(f\"  Sequências X: {male_sample['X'].shape}\")\n",
        "        print(f\"  Alvos y: {male_sample['y'].shape}\")\n",
        "        print(f\"  Anos das sequências: {male_sample['sequence_years'][:5]}...{male_sample['sequence_years'][-5:]}\")\n",
        "\n",
        "    # Verificar um grupo específico para mulheres\n",
        "    if sample_age_group in data_female:\n",
        "        female_sample = data_female[sample_age_group]\n",
        "        print(f\"\\nExemplo grupo feminino '{sample_age_group}':\")\n",
        "        print(f\"  Sequências X: {female_sample['X'].shape}\")\n",
        "        print(f\"  Alvos y: {female_sample['y'].shape}\")\n",
        "        print(f\"  Anos das sequências: {female_sample['sequence_years'][:5]}...{female_sample['sequence_years'][-5:]}\")\n",
        "else:\n",
        "    print('Erro no processamento dos dados')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB6OlHlL-ExU",
        "outputId": "41509f55-d3e7-4821-ccf3-8566d442809d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PROCESSANDO DADOS PARA PAÍS 49 (BRASIL) ===\n",
            "Dados do país 49: 48 registros\n",
            "\n",
            "Processando gênero 0...\n",
            "  Grupo 0: 14 sequências (2010-2023)\n",
            "  Grupo 1: 14 sequências (2010-2023)\n",
            "  Grupo 5: 14 sequências (2010-2023)\n",
            "  Grupo 10: 14 sequências (2010-2023)\n",
            "  Grupo 15: 14 sequências (2010-2023)\n",
            "  Grupo 20: 14 sequências (2010-2023)\n",
            "  Grupo 25: 14 sequências (2010-2023)\n",
            "  Grupo 30: 14 sequências (2010-2023)\n",
            "  Grupo 35: 14 sequências (2010-2023)\n",
            "  Grupo 40: 14 sequências (2010-2023)\n",
            "  Grupo 45: 14 sequências (2010-2023)\n",
            "  Grupo 50: 14 sequências (2010-2023)\n",
            "  Grupo 55: 14 sequências (2010-2023)\n",
            "  Grupo 60: 14 sequências (2010-2023)\n",
            "  Grupo 65: 14 sequências (2010-2023)\n",
            "  Grupo 70: 14 sequências (2010-2023)\n",
            "  Grupo 75: 14 sequências (2010-2023)\n",
            "  Grupo 80: 14 sequências (2010-2023)\n",
            "  Grupo 85: 14 sequências (2010-2023)\n",
            "  Grupo 90: 14 sequências (2010-2023)\n",
            "\n",
            "Processando gênero 1...\n",
            "  Grupo 0: 14 sequências (2010-2023)\n",
            "  Grupo 1: 14 sequências (2010-2023)\n",
            "  Grupo 5: 14 sequências (2010-2023)\n",
            "  Grupo 10: 14 sequências (2010-2023)\n",
            "  Grupo 15: 14 sequências (2010-2023)\n",
            "  Grupo 20: 14 sequências (2010-2023)\n",
            "  Grupo 25: 14 sequências (2010-2023)\n",
            "  Grupo 30: 14 sequências (2010-2023)\n",
            "  Grupo 35: 14 sequências (2010-2023)\n",
            "  Grupo 40: 14 sequências (2010-2023)\n",
            "  Grupo 45: 14 sequências (2010-2023)\n",
            "  Grupo 50: 14 sequências (2010-2023)\n",
            "  Grupo 55: 14 sequências (2010-2023)\n",
            "  Grupo 60: 14 sequências (2010-2023)\n",
            "  Grupo 65: 14 sequências (2010-2023)\n",
            "  Grupo 70: 14 sequências (2010-2023)\n",
            "  Grupo 75: 14 sequências (2010-2023)\n",
            "  Grupo 80: 14 sequências (2010-2023)\n",
            "  Grupo 85: 14 sequências (2010-2023)\n",
            "  Grupo 90: 14 sequências (2010-2023)\n",
            "\n",
            "Dados processados:\n",
            "Grupos etários: 20\n",
            "Anos disponíveis: 2000 - 2023\n",
            "  Homens: 20 grupos etários com dados\n",
            "  Mulheres: 20 grupos etários com dados\n",
            "\n",
            "Exemplo grupo masculino '0':\n",
            "  Sequências X: (14, 10)\n",
            "  Alvos y: (14,)\n",
            "  Anos das sequências: [2010 2011 2012 2013 2014]...[2019 2020 2021 2022 2023]\n",
            "\n",
            "Exemplo grupo feminino '0':\n",
            "  Sequências X: (14, 10)\n",
            "  Alvos y: (14,)\n",
            "  Anos das sequências: [2010 2011 2012 2013 2014]...[2019 2020 2021 2022 2023]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para treinar modelo e fazer previsões com LOG + NORMALIZAÇÃO\n",
        "def train_and_predict(data_dict, scalers_dict, gender_name, years_available, sequence_length=10):\n",
        "    \"\"\"\n",
        "    Treina modelos para cada grupo etário e faz previsões\n",
        "    Período de treino: 2000-2014 | Período de teste: 2015-2019\n",
        "    \"\"\"\n",
        "    models = {}\n",
        "    predictions_dict = {}\n",
        "    metrics_dict = {}\n",
        "\n",
        "    print(f'\\n=== TREINANDO MODELOS PARA {gender_name.upper()} ===')\n",
        "\n",
        "    for age_group in data_dict.keys():\n",
        "        print(f'\\nTreinando modelo para grupo etário {age_group}...')\n",
        "\n",
        "        # Dados de treino\n",
        "        X = data_dict[age_group]['X']\n",
        "        y = data_dict[age_group]['y']\n",
        "        years_for_sequences = data_dict[age_group]['sequence_years']\n",
        "\n",
        "        # Verificar se temos dados suficientes para os períodos desejados\n",
        "        available_years = set(years_for_sequences)\n",
        "        train_years = set(range(2000, 2015))  # 2000-2014\n",
        "        test_years = set(range(2015, 2020))   # 2015-2019\n",
        "\n",
        "        if not train_years.intersection(available_years):\n",
        "            print(f'AVISO: Nenhum ano de treino (2000-2014) disponível para grupo {age_group}')\n",
        "            continue\n",
        "\n",
        "        if not test_years.intersection(available_years):\n",
        "            print(f'AVISO: Nenhum ano de teste (2015-2019) disponível para grupo {age_group}')\n",
        "            continue\n",
        "\n",
        "        # Criar máscaras para treino e teste\n",
        "        train_mask = np.isin(years_for_sequences, list(range(2000, 2015)))\n",
        "        test_mask = np.isin(years_for_sequences, list(range(2015, 2020)))\n",
        "\n",
        "        # Aplicar máscaras\n",
        "        X_train, y_train = X[train_mask], y[train_mask]\n",
        "        X_test, y_test = X[test_mask], y[test_mask]\n",
        "\n",
        "        # Verificar se temos dados suficientes após a divisão\n",
        "        if len(X_train) < 5:\n",
        "            print(f'Dados de treino insuficientes para grupo etário {age_group} (apenas {len(X_train)} amostras)')\n",
        "            continue\n",
        "\n",
        "        if len(X_test) < 1:\n",
        "            print(f'Dados de teste insuficientes para grupo etário {age_group} (apenas {len(X_test)} amostras)')\n",
        "            continue\n",
        "\n",
        "        print(f'Grupo {age_group}: {len(X_train)} amostras de treino, {len(X_test)} amostras de teste')\n",
        "\n",
        "        # Reshape para LSTM\n",
        "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "        # Criar e treinar modelo com callbacks\n",
        "        model = create_lccnn_model(sequence_length=X_train.shape[1])\n",
        "\n",
        "        # Callbacks para melhorar treinamento\n",
        "        early_stop = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=15,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        reduce_lr = ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=5,\n",
        "            min_lr=0.00001\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            history = model.fit(\n",
        "                X_train, y_train,\n",
        "                epochs=200,  # Aumentado devido à complexidade do modelo\n",
        "                batch_size=16,  # Reduzido para melhor generalização\n",
        "                validation_data=(X_test, y_test),\n",
        "                callbacks=[early_stop, reduce_lr],\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            models[age_group] = model\n",
        "\n",
        "            # Fazer previsões no conjunto de teste\n",
        "            y_pred = model.predict(X_test, verbose=0)\n",
        "\n",
        "            # Desnormalizar previsões\n",
        "            scaler = scalers_dict[age_group]\n",
        "            y_test_denorm = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "            y_pred_denorm = scaler.inverse_transform(y_pred).flatten()\n",
        "\n",
        "            # Aplicar inversa do LOG (expm1)\n",
        "            y_test_orig = np.expm1(y_test_denorm)\n",
        "            y_pred_orig = np.expm1(y_pred_denorm)\n",
        "\n",
        "            # Calcular métricas\n",
        "            rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
        "            mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
        "            smape_val = smape(y_test_orig, y_pred_orig)\n",
        "\n",
        "            metrics_dict[age_group] = {\n",
        "                'RMSE': rmse,\n",
        "                'MAE': mae,\n",
        "                'sMAPE': smape_val,\n",
        "                'history': history.history  # Salvar histórico para análise\n",
        "            }\n",
        "\n",
        "            print(f'Grupo {age_group} - RMSE: {rmse:.6f}, MAE: {mae:.6f}, sMAPE: {smape_val:.2f}%')\n",
        "\n",
        "            # Fazer previsões para 2020-2070\n",
        "            last_sequence = data_dict[age_group]['X'][-1].reshape(1, -1, 1)\n",
        "            future_predictions = []\n",
        "            future_uncertainty = []  # Para capturar incerteza\n",
        "\n",
        "            # Calcular resíduos para intervalos de confiança\n",
        "            residuals = y_test_orig - y_pred_orig\n",
        "\n",
        "            for year in range(2020, 2071):\n",
        "                # Gerar 100 previsões com dropout ativo para estimar incerteza\n",
        "                preds = []\n",
        "                for _ in range(100):\n",
        "                    pred = model.predict(last_sequence, verbose=0)\n",
        "                    preds.append(pred[0, 0])\n",
        "\n",
        "                median_pred = np.median(preds)\n",
        "                std_dev = np.std(preds)\n",
        "\n",
        "                future_predictions.append(median_pred)\n",
        "                future_uncertainty.append(std_dev)\n",
        "\n",
        "                # Atualizar sequência para próxima previsão\n",
        "                last_sequence = np.roll(last_sequence, -1, axis=1)\n",
        "                last_sequence[0, -1, 0] = median_pred\n",
        "\n",
        "            # Desnormalizar previsões futuras\n",
        "            future_predictions = np.array(future_predictions).reshape(-1, 1)\n",
        "            future_predictions_denorm = scaler.inverse_transform(future_predictions).flatten()\n",
        "\n",
        "            # Aplicar inversa do LOG nas previsões futuras\n",
        "            future_predictions_orig = np.expm1(future_predictions_denorm)\n",
        "\n",
        "            # Calcular intervalos de confiança com incerteza estimada\n",
        "            lower_bound = future_predictions_orig - 1.96 * np.array(future_uncertainty)\n",
        "            upper_bound = future_predictions_orig + 1.96 * np.array(future_uncertainty)\n",
        "\n",
        "            predictions_dict[age_group] = {\n",
        "                'years': list(range(2020, 2071)),\n",
        "                'predictions': future_predictions_orig,\n",
        "                'lower_bound': lower_bound,\n",
        "                'upper_bound': upper_bound,\n",
        "                'uncertainty': future_uncertainty\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Erro ao treinar modelo para grupo {age_group}: {str(e)}')\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    return models, predictions_dict, metrics_dict"
      ],
      "metadata": {
        "id": "b8mYM1FDDFHn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCOOTE6bFr5R",
        "outputId": "3a1bc61b-6602-4526-ab36-97f4bf36a2b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 0.7558 - mae: 0.3818 - mse: 0.2944 - val_loss: 0.5694 - val_mae: 0.3108 - val_mse: 0.1080 - learning_rate: 5.0000e-04\n",
            "Epoch 197/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.8064 - mae: 0.3897 - mse: 0.3451 - val_loss: 0.5684 - val_mae: 0.3096 - val_mse: 0.1071 - learning_rate: 5.0000e-04\n",
            "Epoch 198/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.6589 - mae: 0.3802 - mse: 0.1975 - val_loss: 0.5666 - val_mae: 0.3074 - val_mse: 0.1053 - learning_rate: 5.0000e-04\n",
            "Epoch 199/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.5625 - mae: 0.2309 - mse: 0.1012 - val_loss: 0.5654 - val_mae: 0.3060 - val_mse: 0.1041 - learning_rate: 5.0000e-04\n",
            "Epoch 200/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - loss: 0.6618 - mae: 0.3849 - mse: 0.2006 - val_loss: 0.5640 - val_mae: 0.3043 - val_mse: 0.1028 - learning_rate: 5.0000e-04\n",
            "Grupo 20 - RMSE: 0.000228, MAE: 0.000216, sMAPE: 7.97%\n",
            "\n",
            "Treinando modelo para grupo etário 25...\n",
            "Grupo 25: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - loss: 0.8628 - mae: 0.5477 - mse: 0.3917 - val_loss: 0.5571 - val_mae: 0.2545 - val_mse: 0.0864 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 1.3009 - mae: 0.7332 - mse: 0.8303 - val_loss: 0.5526 - val_mae: 0.2494 - val_mse: 0.0822 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.0094 - mae: 0.5209 - mse: 0.5389 - val_loss: 0.5507 - val_mae: 0.2473 - val_mse: 0.0805 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.6290 - mae: 0.8626 - mse: 1.1588 - val_loss: 0.5485 - val_mae: 0.2447 - val_mse: 0.0785 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 1.4455 - mae: 0.7985 - mse: 0.9754 - val_loss: 0.5476 - val_mae: 0.2438 - val_mse: 0.0777 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.0333 - mae: 1.1642 - mse: 1.5634 - val_loss: 0.5466 - val_mae: 0.2428 - val_mse: 0.0769 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 2.6039 - mae: 1.1487 - mse: 2.1342 - val_loss: 0.5466 - val_mae: 0.2428 - val_mse: 0.0769 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 1.8976 - mae: 1.0825 - mse: 1.4280 - val_loss: 0.5460 - val_mae: 0.2422 - val_mse: 0.0765 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 1.7299 - mae: 0.9127 - mse: 1.2604 - val_loss: 0.5455 - val_mae: 0.2417 - val_mse: 0.0761 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 1.1419 - mae: 0.7070 - mse: 0.6725 - val_loss: 0.5451 - val_mae: 0.2412 - val_mse: 0.0757 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 1.5552 - mae: 0.8720 - mse: 1.0859 - val_loss: 0.5451 - val_mae: 0.2413 - val_mse: 0.0758 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 2.7699 - mae: 1.2845 - mse: 2.3006 - val_loss: 0.5446 - val_mae: 0.2407 - val_mse: 0.0754 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.8399 - mae: 0.4747 - mse: 0.3707 - val_loss: 0.5444 - val_mae: 0.2405 - val_mse: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 3.2372 - mae: 1.4062 - mse: 2.7681 - val_loss: 0.5438 - val_mae: 0.2398 - val_mse: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.9396 - mae: 0.9533 - mse: 1.4705 - val_loss: 0.5437 - val_mae: 0.2398 - val_mse: 0.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 1.1511 - mae: 0.6992 - mse: 0.6821 - val_loss: 0.5428 - val_mae: 0.2387 - val_mse: 0.0739 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.9281 - mae: 0.6079 - mse: 0.4592 - val_loss: 0.5423 - val_mae: 0.2380 - val_mse: 0.0734 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 1.6897 - mae: 0.8676 - mse: 1.2208 - val_loss: 0.5415 - val_mae: 0.2370 - val_mse: 0.0726 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 1.0673 - mae: 0.6193 - mse: 0.5985 - val_loss: 0.5411 - val_mae: 0.2366 - val_mse: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.5550 - mae: 0.9854 - mse: 1.0862 - val_loss: 0.5406 - val_mae: 0.2361 - val_mse: 0.0719 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.3464 - mae: 0.6877 - mse: 0.8776 - val_loss: 0.5400 - val_mae: 0.2352 - val_mse: 0.0713 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.1141 - mae: 0.5634 - mse: 0.6454 - val_loss: 0.5396 - val_mae: 0.2347 - val_mse: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.1902 - mae: 0.9603 - mse: 1.7215 - val_loss: 0.5394 - val_mae: 0.2346 - val_mse: 0.0708 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 1.6448 - mae: 0.8822 - mse: 1.1762 - val_loss: 0.5394 - val_mae: 0.2347 - val_mse: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.6855 - mae: 1.0297 - mse: 1.2170 - val_loss: 0.5390 - val_mae: 0.2342 - val_mse: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.0240 - mae: 0.6772 - mse: 0.5555 - val_loss: 0.5379 - val_mae: 0.2328 - val_mse: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.8184 - mae: 0.8845 - mse: 1.3500 - val_loss: 0.5377 - val_mae: 0.2325 - val_mse: 0.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 2.0341 - mae: 0.7601 - mse: 1.5657 - val_loss: 0.5372 - val_mae: 0.2319 - val_mse: 0.0689 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 2.2745 - mae: 0.9367 - mse: 1.8062 - val_loss: 0.5365 - val_mae: 0.2309 - val_mse: 0.0682 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 1.1917 - mae: 0.7008 - mse: 0.7234 - val_loss: 0.5361 - val_mae: 0.2303 - val_mse: 0.0678 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 1.2528 - mae: 0.7559 - mse: 0.7845 - val_loss: 0.5354 - val_mae: 0.2295 - val_mse: 0.0672 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.8600 - mae: 0.4518 - mse: 0.3918 - val_loss: 0.5351 - val_mae: 0.2292 - val_mse: 0.0670 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.9805 - mae: 0.6854 - mse: 0.5123 - val_loss: 0.5348 - val_mae: 0.2287 - val_mse: 0.0667 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.7498 - mae: 0.4892 - mse: 0.2817 - val_loss: 0.5343 - val_mae: 0.2281 - val_mse: 0.0662 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 0.8364 - mae: 0.5364 - mse: 0.3683 - val_loss: 0.5340 - val_mae: 0.2278 - val_mse: 0.0660 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.2085 - mae: 0.7706 - mse: 0.7404 - val_loss: 0.5338 - val_mae: 0.2274 - val_mse: 0.0657 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.8211 - mae: 0.9953 - mse: 1.3530 - val_loss: 0.5334 - val_mae: 0.2270 - val_mse: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 2.0778 - mae: 1.0411 - mse: 1.6098 - val_loss: 0.5330 - val_mae: 0.2265 - val_mse: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.0073 - mae: 0.5653 - mse: 0.5394 - val_loss: 0.5323 - val_mae: 0.2254 - val_mse: 0.0644 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.6278 - mae: 0.3323 - mse: 0.1599 - val_loss: 0.5318 - val_mae: 0.2248 - val_mse: 0.0639 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 1.1762 - mae: 0.7652 - mse: 0.7084 - val_loss: 0.5314 - val_mae: 0.2243 - val_mse: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.0775 - mae: 0.5994 - mse: 0.6097 - val_loss: 0.5310 - val_mae: 0.2238 - val_mse: 0.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.7781 - mae: 0.3451 - mse: 0.3104 - val_loss: 0.5304 - val_mae: 0.2229 - val_mse: 0.0627 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.1557 - mae: 0.7082 - mse: 0.6880 - val_loss: 0.5306 - val_mae: 0.2233 - val_mse: 0.0629 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.9957 - mae: 0.6806 - mse: 0.5281 - val_loss: 0.5310 - val_mae: 0.2240 - val_mse: 0.0634 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.1721 - mae: 0.6981 - mse: 0.7044 - val_loss: 0.5308 - val_mae: 0.2236 - val_mse: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.9926 - mae: 0.6608 - mse: 0.5250 - val_loss: 0.5307 - val_mae: 0.2236 - val_mse: 0.0632 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.6650 - mae: 0.7848 - mse: 1.1974 - val_loss: 0.5301 - val_mae: 0.2228 - val_mse: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.8523 - mae: 0.5227 - mse: 0.3848 - val_loss: 0.5301 - val_mae: 0.2228 - val_mse: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 1.1377 - mae: 0.6924 - mse: 0.6703 - val_loss: 0.5298 - val_mae: 0.2224 - val_mse: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1.5729 - mae: 0.8384 - mse: 1.1055 - val_loss: 0.5298 - val_mae: 0.2225 - val_mse: 0.0624 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.5130 - mae: 0.8506 - mse: 1.0456 - val_loss: 0.5301 - val_mae: 0.2230 - val_mse: 0.0628 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 1.1697 - mae: 0.4957 - mse: 0.7023 - val_loss: 0.5304 - val_mae: 0.2235 - val_mse: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.5769 - mae: 0.2460 - mse: 0.1096 - val_loss: 0.5310 - val_mae: 0.2244 - val_mse: 0.0637 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.7349 - mae: 0.2843 - mse: 0.2676 - val_loss: 0.5308 - val_mae: 0.2242 - val_mse: 0.0636 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.7069 - mae: 0.4208 - mse: 0.2397 - val_loss: 0.5303 - val_mae: 0.2234 - val_mse: 0.0630 - learning_rate: 1.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 1.5022 - mae: 0.9168 - mse: 1.0350 - val_loss: 0.5304 - val_mae: 0.2236 - val_mse: 0.0632 - learning_rate: 1.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.8187 - mae: 0.5257 - mse: 0.3515 - val_loss: 0.5296 - val_mae: 0.2225 - val_mse: 0.0625 - learning_rate: 1.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.5542 - mae: 0.9368 - mse: 1.0870 - val_loss: 0.5294 - val_mae: 0.2221 - val_mse: 0.0622 - learning_rate: 1.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.6265 - mae: 0.2794 - mse: 0.1593 - val_loss: 0.5292 - val_mae: 0.2219 - val_mse: 0.0620 - learning_rate: 1.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.5572 - mae: 0.9522 - mse: 1.0900 - val_loss: 0.5286 - val_mae: 0.2209 - val_mse: 0.0614 - learning_rate: 1.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.7402 - mae: 0.4566 - mse: 0.2731 - val_loss: 0.5283 - val_mae: 0.2204 - val_mse: 0.0611 - learning_rate: 1.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 2.0655 - mae: 1.0136 - mse: 1.5983 - val_loss: 0.5276 - val_mae: 0.2195 - val_mse: 0.0605 - learning_rate: 1.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 1.1193 - mae: 0.6954 - mse: 0.6521 - val_loss: 0.5270 - val_mae: 0.2185 - val_mse: 0.0599 - learning_rate: 1.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 1.1556 - mae: 0.7171 - mse: 0.6885 - val_loss: 0.5267 - val_mae: 0.2181 - val_mse: 0.0595 - learning_rate: 1.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 1.0525 - mae: 0.7320 - mse: 0.5854 - val_loss: 0.5268 - val_mae: 0.2183 - val_mse: 0.0597 - learning_rate: 1.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 1.4237 - mae: 0.7350 - mse: 0.9566 - val_loss: 0.5265 - val_mae: 0.2178 - val_mse: 0.0594 - learning_rate: 1.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.6652 - mae: 0.9019 - mse: 1.1981 - val_loss: 0.5262 - val_mae: 0.2174 - val_mse: 0.0592 - learning_rate: 1.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.6384 - mae: 0.3622 - mse: 0.1713 - val_loss: 0.5259 - val_mae: 0.2170 - val_mse: 0.0589 - learning_rate: 1.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - loss: 0.9837 - mae: 0.5500 - mse: 0.5166 - val_loss: 0.5257 - val_mae: 0.2167 - val_mse: 0.0587 - learning_rate: 1.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 0.7369 - mae: 0.4016 - mse: 0.2699 - val_loss: 0.5256 - val_mae: 0.2165 - val_mse: 0.0585 - learning_rate: 1.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.1410 - mae: 0.6315 - mse: 0.6740 - val_loss: 0.5252 - val_mae: 0.2160 - val_mse: 0.0582 - learning_rate: 1.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.5636 - mae: 0.9316 - mse: 1.0965 - val_loss: 0.5252 - val_mae: 0.2159 - val_mse: 0.0582 - learning_rate: 1.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.6006 - mae: 0.3240 - mse: 0.1335 - val_loss: 0.5249 - val_mae: 0.2153 - val_mse: 0.0578 - learning_rate: 1.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.6494 - mae: 0.9673 - mse: 1.1824 - val_loss: 0.5247 - val_mae: 0.2150 - val_mse: 0.0576 - learning_rate: 1.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 1.0925 - mae: 0.7065 - mse: 0.6255 - val_loss: 0.5245 - val_mae: 0.2148 - val_mse: 0.0575 - learning_rate: 1.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 0.9729 - mae: 0.6357 - mse: 0.5059 - val_loss: 0.5238 - val_mae: 0.2135 - val_mse: 0.0568 - learning_rate: 1.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.9324 - mae: 0.5592 - mse: 0.4654 - val_loss: 0.5238 - val_mae: 0.2136 - val_mse: 0.0568 - learning_rate: 1.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 1.0301 - mae: 0.7250 - mse: 0.5631 - val_loss: 0.5232 - val_mae: 0.2127 - val_mse: 0.0563 - learning_rate: 1.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.7304 - mae: 0.4140 - mse: 0.2634 - val_loss: 0.5233 - val_mae: 0.2128 - val_mse: 0.0563 - learning_rate: 1.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 0.7212 - mae: 0.3836 - mse: 0.2543 - val_loss: 0.5230 - val_mae: 0.2124 - val_mse: 0.0561 - learning_rate: 1.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 0.7127 - mae: 0.4429 - mse: 0.2458 - val_loss: 0.5229 - val_mae: 0.2122 - val_mse: 0.0559 - learning_rate: 1.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 0.7673 - mae: 0.4521 - mse: 0.3004 - val_loss: 0.5228 - val_mae: 0.2121 - val_mse: 0.0559 - learning_rate: 1.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.6233 - mae: 0.2922 - mse: 0.1564 - val_loss: 0.5231 - val_mae: 0.2125 - val_mse: 0.0561 - learning_rate: 1.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 1.4631 - mae: 0.8570 - mse: 0.9962 - val_loss: 0.5227 - val_mae: 0.2119 - val_mse: 0.0558 - learning_rate: 1.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 1.0293 - mae: 0.6158 - mse: 0.5624 - val_loss: 0.5218 - val_mae: 0.2105 - val_mse: 0.0550 - learning_rate: 1.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 1.6354 - mae: 0.9458 - mse: 1.1686 - val_loss: 0.5216 - val_mae: 0.2101 - val_mse: 0.0547 - learning_rate: 1.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.3353 - mae: 0.8004 - mse: 0.8684 - val_loss: 0.5219 - val_mae: 0.2107 - val_mse: 0.0551 - learning_rate: 1.0000e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.7799 - mae: 0.4226 - mse: 0.3130 - val_loss: 0.5216 - val_mae: 0.2101 - val_mse: 0.0547 - learning_rate: 1.0000e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.5189 - mae: 0.2009 - mse: 0.0520 - val_loss: 0.5215 - val_mae: 0.2101 - val_mse: 0.0547 - learning_rate: 1.0000e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.8098 - mae: 0.4927 - mse: 0.3430 - val_loss: 0.5217 - val_mae: 0.2104 - val_mse: 0.0549 - learning_rate: 1.0000e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.6733 - mae: 0.3614 - mse: 0.2065 - val_loss: 0.5216 - val_mae: 0.2102 - val_mse: 0.0548 - learning_rate: 1.0000e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.7105 - mae: 1.0435 - mse: 1.2437 - val_loss: 0.5215 - val_mae: 0.2101 - val_mse: 0.0547 - learning_rate: 2.0000e-05\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.5948 - mae: 0.3161 - mse: 0.1280 - val_loss: 0.5215 - val_mae: 0.2100 - val_mse: 0.0547 - learning_rate: 2.0000e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.8836 - mae: 0.5763 - mse: 0.4168 - val_loss: 0.5217 - val_mae: 0.2103 - val_mse: 0.0549 - learning_rate: 2.0000e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.2735 - mae: 0.7169 - mse: 0.8067 - val_loss: 0.5226 - val_mae: 0.2119 - val_mse: 0.0558 - learning_rate: 2.0000e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 1.5196 - mae: 0.9783 - mse: 1.0528 - val_loss: 0.5226 - val_mae: 0.2118 - val_mse: 0.0558 - learning_rate: 2.0000e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.5965 - mae: 0.2306 - mse: 0.1297 - val_loss: 0.5226 - val_mae: 0.2118 - val_mse: 0.0558 - learning_rate: 1.0000e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 1.3922 - mae: 0.8016 - mse: 0.9254 - val_loss: 0.5228 - val_mae: 0.2121 - val_mse: 0.0560 - learning_rate: 1.0000e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1.2851 - mae: 0.7847 - mse: 0.8183 - val_loss: 0.5234 - val_mae: 0.2131 - val_mse: 0.0566 - learning_rate: 1.0000e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.4059 - mae: 0.7932 - mse: 0.9391 - val_loss: 0.5222 - val_mae: 0.2112 - val_mse: 0.0554 - learning_rate: 1.0000e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.7256 - mae: 0.3834 - mse: 0.2588 - val_loss: 0.5220 - val_mae: 0.2108 - val_mse: 0.0552 - learning_rate: 1.0000e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.6981 - mae: 0.4035 - mse: 0.2313 - val_loss: 0.5216 - val_mae: 0.2102 - val_mse: 0.0548 - learning_rate: 1.0000e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.8190 - mae: 0.5658 - mse: 0.3522 - val_loss: 0.5214 - val_mae: 0.2099 - val_mse: 0.0546 - learning_rate: 1.0000e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.8498 - mae: 0.5496 - mse: 0.3830 - val_loss: 0.5218 - val_mae: 0.2105 - val_mse: 0.0550 - learning_rate: 1.0000e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.7880 - mae: 0.4665 - mse: 0.3212 - val_loss: 0.5213 - val_mae: 0.2097 - val_mse: 0.0545 - learning_rate: 1.0000e-05\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.9602 - mae: 0.5223 - mse: 0.4934 - val_loss: 0.5212 - val_mae: 0.2094 - val_mse: 0.0544 - learning_rate: 1.0000e-05\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.0541 - mae: 0.7125 - mse: 0.5874 - val_loss: 0.5216 - val_mae: 0.2101 - val_mse: 0.0548 - learning_rate: 1.0000e-05\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - loss: 0.8716 - mae: 0.4598 - mse: 0.4049 - val_loss: 0.5218 - val_mae: 0.2105 - val_mse: 0.0550 - learning_rate: 1.0000e-05\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 1.1638 - mae: 0.7912 - mse: 0.6970 - val_loss: 0.5221 - val_mae: 0.2110 - val_mse: 0.0553 - learning_rate: 1.0000e-05\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - loss: 0.8462 - mae: 0.5177 - mse: 0.3794 - val_loss: 0.5217 - val_mae: 0.2103 - val_mse: 0.0549 - learning_rate: 1.0000e-05\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 1.2222 - mae: 0.6994 - mse: 0.7554 - val_loss: 0.5223 - val_mae: 0.2112 - val_mse: 0.0555 - learning_rate: 1.0000e-05\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.5572 - mae: 0.2689 - mse: 0.0904 - val_loss: 0.5224 - val_mae: 0.2113 - val_mse: 0.0556 - learning_rate: 1.0000e-05\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.4819 - mae: 0.6917 - mse: 1.0151 - val_loss: 0.5228 - val_mae: 0.2119 - val_mse: 0.0560 - learning_rate: 1.0000e-05\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.7905 - mae: 0.5163 - mse: 0.3237 - val_loss: 0.5224 - val_mae: 0.2114 - val_mse: 0.0557 - learning_rate: 1.0000e-05\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - loss: 0.7489 - mae: 0.4567 - mse: 0.2821 - val_loss: 0.5230 - val_mae: 0.2123 - val_mse: 0.0562 - learning_rate: 1.0000e-05\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.7640 - mae: 0.9950 - mse: 1.2972 - val_loss: 0.5231 - val_mae: 0.2124 - val_mse: 0.0564 - learning_rate: 1.0000e-05\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.9614 - mae: 0.6396 - mse: 0.4946 - val_loss: 0.5235 - val_mae: 0.2129 - val_mse: 0.0567 - learning_rate: 1.0000e-05\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 1.2376 - mae: 0.7873 - mse: 0.7708 - val_loss: 0.5242 - val_mae: 0.2141 - val_mse: 0.0575 - learning_rate: 1.0000e-05\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.4944 - mae: 0.1341 - mse: 0.0277 - val_loss: 0.5247 - val_mae: 0.2148 - val_mse: 0.0579 - learning_rate: 1.0000e-05\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 0.8756 - mae: 0.4773 - mse: 0.4088 - val_loss: 0.5253 - val_mae: 0.2157 - val_mse: 0.0585 - learning_rate: 1.0000e-05\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.9569 - mae: 1.0000 - mse: 1.4901 - val_loss: 0.5265 - val_mae: 0.2175 - val_mse: 0.0597 - learning_rate: 1.0000e-05\n",
            "Grupo 25 - RMSE: 0.000211, MAE: 0.000190, sMAPE: 7.52%\n",
            "\n",
            "Treinando modelo para grupo etário 30...\n",
            "Grupo 30: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 5.6223 - mae: 1.9395 - mse: 5.1517 - val_loss: 0.4991 - val_mae: 0.1410 - val_mse: 0.0289 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step - loss: 6.2353 - mae: 1.9508 - mse: 5.7650 - val_loss: 0.5000 - val_mae: 0.1441 - val_mse: 0.0299 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 2.0505 - mae: 1.0466 - mse: 1.5804 - val_loss: 0.5001 - val_mae: 0.1447 - val_mse: 0.0301 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 3.1872 - mae: 1.6027 - mse: 2.7172 - val_loss: 0.5009 - val_mae: 0.1476 - val_mse: 0.0309 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.0558 - mae: 0.4797 - mse: 0.5859 - val_loss: 0.5021 - val_mae: 0.1520 - val_mse: 0.0322 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 1.1761 - mae: 0.7747 - mse: 0.7062 - val_loss: 0.5027 - val_mae: 0.1541 - val_mse: 0.0329 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 2.1264 - mae: 1.1258 - mse: 1.6566 - val_loss: 0.5029 - val_mae: 0.1551 - val_mse: 0.0331 - learning_rate: 1.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 1.0074 - mae: 0.6319 - mse: 0.5376 - val_loss: 0.5033 - val_mae: 0.1564 - val_mse: 0.0335 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 4.0319 - mae: 1.5133 - mse: 3.5621 - val_loss: 0.5029 - val_mae: 0.1550 - val_mse: 0.0331 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 2.2981 - mae: 1.0744 - mse: 1.8284 - val_loss: 0.5025 - val_mae: 0.1538 - val_mse: 0.0327 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 3.4829 - mae: 1.4204 - mse: 3.0132 - val_loss: 0.5024 - val_mae: 0.1534 - val_mse: 0.0326 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.4792 - mae: 0.9485 - mse: 1.0094 - val_loss: 0.5019 - val_mae: 0.1519 - val_mse: 0.0321 - learning_rate: 2.0000e-05\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.4116 - mae: 0.8413 - mse: 0.9419 - val_loss: 0.5016 - val_mae: 0.1510 - val_mse: 0.0318 - learning_rate: 2.0000e-05\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 1.8038 - mae: 0.8709 - mse: 1.3340 - val_loss: 0.5014 - val_mae: 0.1504 - val_mse: 0.0316 - learning_rate: 2.0000e-05\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 3.2423 - mae: 1.3294 - mse: 2.7725 - val_loss: 0.5007 - val_mae: 0.1483 - val_mse: 0.0310 - learning_rate: 2.0000e-05\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 1.5821 - mae: 0.8812 - mse: 1.1124 - val_loss: 0.5003 - val_mae: 0.1469 - val_mse: 0.0306 - learning_rate: 2.0000e-05\n",
            "Grupo 30 - RMSE: 0.000214, MAE: 0.000178, sMAPE: 6.91%\n",
            "\n",
            "Treinando modelo para grupo etário 35...\n",
            "Grupo 35: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 0.5861 - mae: 0.3072 - mse: 0.1156 - val_loss: 0.4921 - val_mae: 0.1238 - val_mse: 0.0220 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.8376 - mae: 0.4828 - mse: 0.3676 - val_loss: 0.4922 - val_mae: 0.1255 - val_mse: 0.0225 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 2.3527 - mae: 1.1451 - mse: 1.8830 - val_loss: 0.4923 - val_mae: 0.1262 - val_mse: 0.0227 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.2462 - mae: 0.7440 - mse: 0.7767 - val_loss: 0.4928 - val_mae: 0.1288 - val_mse: 0.0234 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 2.5391 - mae: 1.1272 - mse: 2.0697 - val_loss: 0.4932 - val_mae: 0.1308 - val_mse: 0.0239 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.5985 - mae: 0.8879 - mse: 1.1292 - val_loss: 0.4936 - val_mae: 0.1329 - val_mse: 0.0244 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 2.2901 - mae: 0.9845 - mse: 1.8209 - val_loss: 0.4939 - val_mae: 0.1341 - val_mse: 0.0248 - learning_rate: 1.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.9118 - mae: 0.5771 - mse: 0.4426 - val_loss: 0.4939 - val_mae: 0.1339 - val_mse: 0.0247 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 2.7897 - mae: 1.3426 - mse: 2.3205 - val_loss: 0.4937 - val_mae: 0.1331 - val_mse: 0.0245 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 2.0803 - mae: 1.1523 - mse: 1.6112 - val_loss: 0.4937 - val_mae: 0.1335 - val_mse: 0.0246 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 1.1584 - mae: 0.6421 - mse: 0.6892 - val_loss: 0.4932 - val_mae: 0.1318 - val_mse: 0.0241 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 1.6561 - mae: 0.9323 - mse: 1.1870 - val_loss: 0.4921 - val_mae: 0.1274 - val_mse: 0.0230 - learning_rate: 2.0000e-05\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 2.1085 - mae: 1.0308 - mse: 1.6394 - val_loss: 0.4913 - val_mae: 0.1242 - val_mse: 0.0222 - learning_rate: 2.0000e-05\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.9102 - mae: 0.5259 - mse: 0.4410 - val_loss: 0.4906 - val_mae: 0.1213 - val_mse: 0.0215 - learning_rate: 2.0000e-05\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 1.1106 - mae: 0.7384 - mse: 0.6415 - val_loss: 0.4902 - val_mae: 0.1201 - val_mse: 0.0211 - learning_rate: 2.0000e-05\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 1.1546 - mae: 0.7315 - mse: 0.6854 - val_loss: 0.4901 - val_mae: 0.1198 - val_mse: 0.0210 - learning_rate: 2.0000e-05\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 2.1917 - mae: 1.0940 - mse: 1.7226 - val_loss: 0.4898 - val_mae: 0.1191 - val_mse: 0.0207 - learning_rate: 2.0000e-05\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.1871 - mae: 0.6313 - mse: 0.7180 - val_loss: 0.4897 - val_mae: 0.1187 - val_mse: 0.0206 - learning_rate: 2.0000e-05\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.2787 - mae: 0.7047 - mse: 0.8096 - val_loss: 0.4895 - val_mae: 0.1183 - val_mse: 0.0204 - learning_rate: 2.0000e-05\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 2.6296 - mae: 1.1436 - mse: 2.1605 - val_loss: 0.4891 - val_mae: 0.1174 - val_mse: 0.0201 - learning_rate: 2.0000e-05\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 1.1207 - mae: 0.6672 - mse: 0.6516 - val_loss: 0.4888 - val_mae: 0.1163 - val_mse: 0.0197 - learning_rate: 2.0000e-05\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 2.2169 - mae: 0.9791 - mse: 1.7478 - val_loss: 0.4886 - val_mae: 0.1159 - val_mse: 0.0195 - learning_rate: 2.0000e-05\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.6378 - mae: 0.7140 - mse: 1.1687 - val_loss: 0.4880 - val_mae: 0.1142 - val_mse: 0.0189 - learning_rate: 2.0000e-05\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 2.8493 - mae: 1.3668 - mse: 2.3802 - val_loss: 0.4874 - val_mae: 0.1125 - val_mse: 0.0183 - learning_rate: 2.0000e-05\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.1145 - mae: 1.0841 - mse: 1.6454 - val_loss: 0.4876 - val_mae: 0.1131 - val_mse: 0.0185 - learning_rate: 2.0000e-05\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 2.9985 - mae: 1.2748 - mse: 2.5295 - val_loss: 0.4874 - val_mae: 0.1126 - val_mse: 0.0183 - learning_rate: 2.0000e-05\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 3.6943 - mae: 1.5219 - mse: 3.2252 - val_loss: 0.4869 - val_mae: 0.1111 - val_mse: 0.0178 - learning_rate: 2.0000e-05\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 0.7398 - mae: 0.4149 - mse: 0.2707 - val_loss: 0.4867 - val_mae: 0.1107 - val_mse: 0.0176 - learning_rate: 2.0000e-05\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.8827 - mae: 1.0807 - mse: 1.4137 - val_loss: 0.4866 - val_mae: 0.1105 - val_mse: 0.0176 - learning_rate: 2.0000e-05\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.1461 - mae: 0.6834 - mse: 0.6771 - val_loss: 0.4863 - val_mae: 0.1096 - val_mse: 0.0172 - learning_rate: 2.0000e-05\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 1.7734 - mae: 1.0114 - mse: 1.3044 - val_loss: 0.4859 - val_mae: 0.1086 - val_mse: 0.0169 - learning_rate: 2.0000e-05\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 2.5465 - mae: 1.0005 - mse: 2.0774 - val_loss: 0.4855 - val_mae: 0.1072 - val_mse: 0.0164 - learning_rate: 2.0000e-05\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.4923 - mae: 0.1281 - mse: 0.0232 - val_loss: 0.4851 - val_mae: 0.1059 - val_mse: 0.0160 - learning_rate: 2.0000e-05\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.2025 - mae: 0.7306 - mse: 0.7334 - val_loss: 0.4845 - val_mae: 0.1042 - val_mse: 0.0155 - learning_rate: 2.0000e-05\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.7549 - mae: 0.4077 - mse: 0.2858 - val_loss: 0.4840 - val_mae: 0.1026 - val_mse: 0.0150 - learning_rate: 2.0000e-05\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 1.9559 - mae: 1.1284 - mse: 1.4868 - val_loss: 0.4838 - val_mae: 0.1019 - val_mse: 0.0148 - learning_rate: 2.0000e-05\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.7708 - mae: 0.8471 - mse: 1.3018 - val_loss: 0.4831 - val_mae: 0.0996 - val_mse: 0.0141 - learning_rate: 2.0000e-05\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.3785 - mae: 0.8798 - mse: 0.9094 - val_loss: 0.4826 - val_mae: 0.0977 - val_mse: 0.0135 - learning_rate: 2.0000e-05\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 0.8677 - mae: 0.5250 - mse: 0.3986 - val_loss: 0.4823 - val_mae: 0.0969 - val_mse: 0.0133 - learning_rate: 2.0000e-05\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 1.5389 - mae: 0.9574 - mse: 1.0699 - val_loss: 0.4819 - val_mae: 0.0952 - val_mse: 0.0129 - learning_rate: 2.0000e-05\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 0.8424 - mae: 0.5621 - mse: 0.3734 - val_loss: 0.4814 - val_mae: 0.0932 - val_mse: 0.0123 - learning_rate: 2.0000e-05\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 4.3022 - mae: 1.4939 - mse: 3.8332 - val_loss: 0.4811 - val_mae: 0.0924 - val_mse: 0.0121 - learning_rate: 2.0000e-05\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 1.4451 - mae: 0.8469 - mse: 0.9761 - val_loss: 0.4809 - val_mae: 0.0915 - val_mse: 0.0119 - learning_rate: 2.0000e-05\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - loss: 2.2934 - mae: 0.9235 - mse: 1.8244 - val_loss: 0.4807 - val_mae: 0.0906 - val_mse: 0.0117 - learning_rate: 2.0000e-05\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 1.2779 - mae: 0.6487 - mse: 0.8089 - val_loss: 0.4802 - val_mae: 0.0884 - val_mse: 0.0112 - learning_rate: 2.0000e-05\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 3.2734 - mae: 1.4893 - mse: 2.8044 - val_loss: 0.4797 - val_mae: 0.0863 - val_mse: 0.0107 - learning_rate: 2.0000e-05\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 1.4870 - mae: 0.9262 - mse: 1.0180 - val_loss: 0.4794 - val_mae: 0.0845 - val_mse: 0.0104 - learning_rate: 2.0000e-05\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 2.7097 - mae: 1.2109 - mse: 2.2407 - val_loss: 0.4792 - val_mae: 0.0840 - val_mse: 0.0103 - learning_rate: 2.0000e-05\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 2.7945 - mae: 1.2658 - mse: 2.3256 - val_loss: 0.4791 - val_mae: 0.0831 - val_mse: 0.0101 - learning_rate: 2.0000e-05\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 2.8938 - mae: 1.3313 - mse: 2.4248 - val_loss: 0.4789 - val_mae: 0.0820 - val_mse: 0.0099 - learning_rate: 2.0000e-05\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.8729 - mae: 0.5507 - mse: 0.4039 - val_loss: 0.4788 - val_mae: 0.0817 - val_mse: 0.0098 - learning_rate: 2.0000e-05\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.9830 - mae: 1.1308 - mse: 1.5140 - val_loss: 0.4784 - val_mae: 0.0800 - val_mse: 0.0094 - learning_rate: 2.0000e-05\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 3.7570 - mae: 1.3148 - mse: 3.2880 - val_loss: 0.4783 - val_mae: 0.0800 - val_mse: 0.0094 - learning_rate: 2.0000e-05\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 2.5021 - mae: 1.2703 - mse: 2.0331 - val_loss: 0.4780 - val_mae: 0.0791 - val_mse: 0.0090 - learning_rate: 2.0000e-05\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 1.3841 - mae: 0.7783 - mse: 0.9152 - val_loss: 0.4777 - val_mae: 0.0785 - val_mse: 0.0087 - learning_rate: 2.0000e-05\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.0585 - mae: 1.0445 - mse: 1.5895 - val_loss: 0.4775 - val_mae: 0.0779 - val_mse: 0.0085 - learning_rate: 2.0000e-05\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 1.1941 - mae: 0.7360 - mse: 0.7252 - val_loss: 0.4771 - val_mae: 0.0769 - val_mse: 0.0081 - learning_rate: 2.0000e-05\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 1.1159 - mae: 0.7012 - mse: 0.6469 - val_loss: 0.4769 - val_mae: 0.0764 - val_mse: 0.0079 - learning_rate: 2.0000e-05\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 1.8245 - mae: 1.0610 - mse: 1.3556 - val_loss: 0.4768 - val_mae: 0.0762 - val_mse: 0.0078 - learning_rate: 2.0000e-05\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 3.2478 - mae: 1.2737 - mse: 2.7788 - val_loss: 0.4766 - val_mae: 0.0758 - val_mse: 0.0077 - learning_rate: 2.0000e-05\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.2216 - mae: 0.7571 - mse: 0.7526 - val_loss: 0.4767 - val_mae: 0.0760 - val_mse: 0.0077 - learning_rate: 2.0000e-05\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.2279 - mae: 0.7735 - mse: 0.7589 - val_loss: 0.4764 - val_mae: 0.0752 - val_mse: 0.0075 - learning_rate: 2.0000e-05\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 1.3962 - mae: 0.8956 - mse: 0.9272 - val_loss: 0.4763 - val_mae: 0.0747 - val_mse: 0.0073 - learning_rate: 2.0000e-05\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 2.1285 - mae: 1.0173 - mse: 1.6596 - val_loss: 0.4762 - val_mae: 0.0743 - val_mse: 0.0072 - learning_rate: 2.0000e-05\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 0.9268 - mae: 0.4590 - mse: 0.4578 - val_loss: 0.4759 - val_mae: 0.0733 - val_mse: 0.0070 - learning_rate: 2.0000e-05\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 1.1204 - mae: 0.5676 - mse: 0.6515 - val_loss: 0.4758 - val_mae: 0.0727 - val_mse: 0.0069 - learning_rate: 2.0000e-05\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.0580 - mae: 0.6109 - mse: 0.5890 - val_loss: 0.4757 - val_mae: 0.0720 - val_mse: 0.0068 - learning_rate: 2.0000e-05\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 2.1354 - mae: 1.2454 - mse: 1.6665 - val_loss: 0.4755 - val_mae: 0.0708 - val_mse: 0.0066 - learning_rate: 2.0000e-05\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 3.9314 - mae: 1.4730 - mse: 3.4625 - val_loss: 0.4754 - val_mae: 0.0700 - val_mse: 0.0065 - learning_rate: 2.0000e-05\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 2.2354 - mae: 0.9690 - mse: 1.7665 - val_loss: 0.4753 - val_mae: 0.0696 - val_mse: 0.0064 - learning_rate: 2.0000e-05\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.1766 - mae: 0.7414 - mse: 0.7076 - val_loss: 0.4753 - val_mae: 0.0688 - val_mse: 0.0063 - learning_rate: 2.0000e-05\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 2.8628 - mae: 1.3293 - mse: 2.3939 - val_loss: 0.4752 - val_mae: 0.0682 - val_mse: 0.0063 - learning_rate: 2.0000e-05\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.9165 - mae: 0.6400 - mse: 0.4476 - val_loss: 0.4752 - val_mae: 0.0673 - val_mse: 0.0063 - learning_rate: 2.0000e-05\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 0.8997 - mae: 0.5895 - mse: 0.4308 - val_loss: 0.4752 - val_mae: 0.0672 - val_mse: 0.0063 - learning_rate: 2.0000e-05\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 1.5728 - mae: 0.7728 - mse: 1.1039 - val_loss: 0.4752 - val_mae: 0.0676 - val_mse: 0.0063 - learning_rate: 2.0000e-05\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 1.7920 - mae: 0.8786 - mse: 1.3231 - val_loss: 0.4752 - val_mae: 0.0679 - val_mse: 0.0063 - learning_rate: 2.0000e-05\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 1.9207 - mae: 0.9989 - mse: 1.4518 - val_loss: 0.4753 - val_mae: 0.0686 - val_mse: 0.0064 - learning_rate: 1.0000e-05\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 2.5106 - mae: 1.1245 - mse: 2.0417 - val_loss: 0.4752 - val_mae: 0.0683 - val_mse: 0.0063 - learning_rate: 1.0000e-05\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 2.6752 - mae: 1.2173 - mse: 2.2063 - val_loss: 0.4753 - val_mae: 0.0690 - val_mse: 0.0064 - learning_rate: 1.0000e-05\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 2.6820 - mae: 1.2051 - mse: 2.2131 - val_loss: 0.4755 - val_mae: 0.0702 - val_mse: 0.0066 - learning_rate: 1.0000e-05\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.9806 - mae: 0.6024 - mse: 0.5117 - val_loss: 0.4756 - val_mae: 0.0703 - val_mse: 0.0067 - learning_rate: 1.0000e-05\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 2.2020 - mae: 1.1019 - mse: 1.7331 - val_loss: 0.4755 - val_mae: 0.0698 - val_mse: 0.0066 - learning_rate: 1.0000e-05\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 3.0152 - mae: 1.2907 - mse: 2.5463 - val_loss: 0.4758 - val_mae: 0.0710 - val_mse: 0.0069 - learning_rate: 1.0000e-05\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.9691 - mae: 0.5928 - mse: 0.5002 - val_loss: 0.4760 - val_mae: 0.0717 - val_mse: 0.0071 - learning_rate: 1.0000e-05\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.9198 - mae: 1.1358 - mse: 1.4510 - val_loss: 0.4763 - val_mae: 0.0724 - val_mse: 0.0074 - learning_rate: 1.0000e-05\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.1653 - mae: 0.7169 - mse: 0.6964 - val_loss: 0.4765 - val_mae: 0.0729 - val_mse: 0.0076 - learning_rate: 1.0000e-05\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 3.2867 - mae: 1.0461 - mse: 2.8178 - val_loss: 0.4766 - val_mae: 0.0731 - val_mse: 0.0077 - learning_rate: 1.0000e-05\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.4847 - mae: 0.8377 - mse: 1.0158 - val_loss: 0.4769 - val_mae: 0.0735 - val_mse: 0.0080 - learning_rate: 1.0000e-05\n",
            "Grupo 35 - RMSE: 0.000131, MAE: 0.000112, sMAPE: 3.71%\n",
            "\n",
            "Treinando modelo para grupo etário 40...\n",
            "Grupo 40: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 5.2430 - mae: 1.7474 - mse: 4.7722 - val_loss: 0.4882 - val_mae: 0.1086 - val_mse: 0.0179 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step - loss: 1.5256 - mae: 0.8374 - mse: 1.0552 - val_loss: 0.4868 - val_mae: 0.1049 - val_mse: 0.0166 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 1.5567 - mae: 0.8369 - mse: 1.0866 - val_loss: 0.4860 - val_mae: 0.1031 - val_mse: 0.0160 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 2.1637 - mae: 1.1042 - mse: 1.6938 - val_loss: 0.4853 - val_mae: 0.1011 - val_mse: 0.0154 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 2.3521 - mae: 1.1509 - mse: 1.8822 - val_loss: 0.4848 - val_mae: 0.0998 - val_mse: 0.0150 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 1.1844 - mae: 0.5428 - mse: 0.7146 - val_loss: 0.4841 - val_mae: 0.0978 - val_mse: 0.0144 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 1.6219 - mae: 0.9656 - mse: 1.1522 - val_loss: 0.4834 - val_mae: 0.0957 - val_mse: 0.0138 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.6036 - mae: 0.8670 - mse: 1.1339 - val_loss: 0.4828 - val_mae: 0.0937 - val_mse: 0.0132 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 4.0947 - mae: 1.5845 - mse: 3.6251 - val_loss: 0.4820 - val_mae: 0.0912 - val_mse: 0.0125 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.5698 - mae: 0.7946 - mse: 1.1003 - val_loss: 0.4817 - val_mae: 0.0900 - val_mse: 0.0122 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 1.5977 - mae: 0.8734 - mse: 1.1282 - val_loss: 0.4814 - val_mae: 0.0893 - val_mse: 0.0120 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.5902 - mae: 0.8265 - mse: 1.1208 - val_loss: 0.4808 - val_mae: 0.0871 - val_mse: 0.0115 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 3.9918 - mae: 1.3210 - mse: 3.5225 - val_loss: 0.4801 - val_mae: 0.0843 - val_mse: 0.0108 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.0047 - mae: 0.6581 - mse: 0.5354 - val_loss: 0.4799 - val_mae: 0.0837 - val_mse: 0.0107 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 1.3099 - mae: 0.7549 - mse: 0.8407 - val_loss: 0.4795 - val_mae: 0.0820 - val_mse: 0.0103 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 3.1247 - mae: 1.3388 - mse: 2.6555 - val_loss: 0.4790 - val_mae: 0.0804 - val_mse: 0.0099 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.2986 - mae: 1.6112 - mse: 2.8295 - val_loss: 0.4785 - val_mae: 0.0780 - val_mse: 0.0094 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 2.7902 - mae: 1.2457 - mse: 2.3212 - val_loss: 0.4785 - val_mae: 0.0779 - val_mse: 0.0095 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.9666 - mae: 0.9190 - mse: 1.4975 - val_loss: 0.4781 - val_mae: 0.0772 - val_mse: 0.0091 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 1.0095 - mae: 0.5848 - mse: 0.5405 - val_loss: 0.4778 - val_mae: 0.0768 - val_mse: 0.0089 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.2172 - mae: 0.7191 - mse: 0.7483 - val_loss: 0.4776 - val_mae: 0.0765 - val_mse: 0.0087 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 1.8575 - mae: 0.9358 - mse: 1.3886 - val_loss: 0.4773 - val_mae: 0.0762 - val_mse: 0.0084 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 2.2546 - mae: 1.0506 - mse: 1.7858 - val_loss: 0.4769 - val_mae: 0.0750 - val_mse: 0.0081 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.7939 - mae: 1.0540 - mse: 1.3251 - val_loss: 0.4766 - val_mae: 0.0744 - val_mse: 0.0078 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 2.0339 - mae: 1.1293 - mse: 1.5652 - val_loss: 0.4763 - val_mae: 0.0737 - val_mse: 0.0076 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 1.4756 - mae: 0.9642 - mse: 1.0068 - val_loss: 0.4761 - val_mae: 0.0734 - val_mse: 0.0074 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 2.8221 - mae: 1.3087 - mse: 2.3534 - val_loss: 0.4759 - val_mae: 0.0728 - val_mse: 0.0072 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.8051 - mae: 0.9149 - mse: 1.3364 - val_loss: 0.4758 - val_mae: 0.0726 - val_mse: 0.0071 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - loss: 1.0921 - mae: 0.6537 - mse: 0.6235 - val_loss: 0.4755 - val_mae: 0.0718 - val_mse: 0.0069 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 0.9696 - mae: 0.6529 - mse: 0.5010 - val_loss: 0.4753 - val_mae: 0.0712 - val_mse: 0.0068 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 1.4051 - mae: 0.7774 - mse: 0.9365 - val_loss: 0.4752 - val_mae: 0.0707 - val_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 2.2616 - mae: 0.8768 - mse: 1.7930 - val_loss: 0.4750 - val_mae: 0.0701 - val_mse: 0.0065 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 1.9743 - mae: 1.1166 - mse: 1.5058 - val_loss: 0.4749 - val_mae: 0.0696 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 2.3644 - mae: 1.1544 - mse: 1.8960 - val_loss: 0.4749 - val_mae: 0.0695 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.3102 - mae: 0.7732 - mse: 0.8418 - val_loss: 0.4748 - val_mae: 0.0693 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - loss: 1.1633 - mae: 0.6708 - mse: 0.6949 - val_loss: 0.4746 - val_mae: 0.0683 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 1.1893 - mae: 0.6727 - mse: 0.7209 - val_loss: 0.4746 - val_mae: 0.0681 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.9678 - mae: 0.5928 - mse: 0.4995 - val_loss: 0.4746 - val_mae: 0.0683 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 2.2836 - mae: 0.9041 - mse: 1.8153 - val_loss: 0.4745 - val_mae: 0.0679 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 2.0243 - mae: 1.0873 - mse: 1.5560 - val_loss: 0.4744 - val_mae: 0.0675 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.2271 - mae: 1.0804 - mse: 1.7588 - val_loss: 0.4744 - val_mae: 0.0668 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.9985 - mae: 0.5707 - mse: 0.5303 - val_loss: 0.4743 - val_mae: 0.0669 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.7336 - mae: 0.3845 - mse: 0.2654 - val_loss: 0.4743 - val_mae: 0.0670 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 1.5696 - mae: 0.7514 - mse: 1.1015 - val_loss: 0.4743 - val_mae: 0.0672 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 2.2290 - mae: 1.1034 - mse: 1.7608 - val_loss: 0.4743 - val_mae: 0.0673 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.8698 - mae: 0.9951 - mse: 1.4017 - val_loss: 0.4742 - val_mae: 0.0676 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.0080 - mae: 0.6866 - mse: 0.5399 - val_loss: 0.4742 - val_mae: 0.0680 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.5787 - mae: 0.8699 - mse: 1.1106 - val_loss: 0.4743 - val_mae: 0.0684 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.4591 - mae: 0.7851 - mse: 0.9911 - val_loss: 0.4743 - val_mae: 0.0690 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 2.8195 - mae: 1.1835 - mse: 2.3515 - val_loss: 0.4743 - val_mae: 0.0689 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 1.5012 - mae: 0.8666 - mse: 1.0332 - val_loss: 0.4743 - val_mae: 0.0692 - val_mse: 0.0063 - learning_rate: 1.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 2.0941 - mae: 1.0835 - mse: 1.6262 - val_loss: 0.4743 - val_mae: 0.0694 - val_mse: 0.0064 - learning_rate: 1.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 1.1205 - mae: 0.6891 - mse: 0.6525 - val_loss: 0.4743 - val_mae: 0.0696 - val_mse: 0.0064 - learning_rate: 1.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 1.4790 - mae: 0.9069 - mse: 1.0110 - val_loss: 0.4743 - val_mae: 0.0698 - val_mse: 0.0064 - learning_rate: 1.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 2.3302 - mae: 1.1871 - mse: 1.8623 - val_loss: 0.4743 - val_mae: 0.0697 - val_mse: 0.0064 - learning_rate: 1.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.8059 - mae: 0.4704 - mse: 0.3380 - val_loss: 0.4743 - val_mae: 0.0697 - val_mse: 0.0064 - learning_rate: 2.0000e-05\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 1.6313 - mae: 0.9244 - mse: 1.1634 - val_loss: 0.4743 - val_mae: 0.0693 - val_mse: 0.0064 - learning_rate: 2.0000e-05\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 1.3625 - mae: 0.7420 - mse: 0.8946 - val_loss: 0.4743 - val_mae: 0.0695 - val_mse: 0.0064 - learning_rate: 2.0000e-05\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.9383 - mae: 1.0345 - mse: 1.4704 - val_loss: 0.4743 - val_mae: 0.0687 - val_mse: 0.0063 - learning_rate: 2.0000e-05\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 2.6084 - mae: 1.1373 - mse: 2.1405 - val_loss: 0.4742 - val_mae: 0.0687 - val_mse: 0.0063 - learning_rate: 2.0000e-05\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.3204 - mae: 0.7579 - mse: 0.8525 - val_loss: 0.4742 - val_mae: 0.0686 - val_mse: 0.0063 - learning_rate: 1.0000e-05\n",
            "Grupo 40 - RMSE: 0.000169, MAE: 0.000145, sMAPE: 3.79%\n",
            "\n",
            "Treinando modelo para grupo etário 45...\n",
            "Grupo 45: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - loss: 3.0926 - mae: 1.4232 - mse: 2.6184 - val_loss: 0.4944 - val_mae: 0.1156 - val_mse: 0.0206 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 4.7168 - mae: 1.7843 - mse: 4.2429 - val_loss: 0.4931 - val_mae: 0.1124 - val_mse: 0.0194 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 5.2080 - mae: 1.9550 - mse: 4.7342 - val_loss: 0.4921 - val_mae: 0.1096 - val_mse: 0.0184 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 5.2753 - mae: 2.0845 - mse: 4.8016 - val_loss: 0.4909 - val_mae: 0.1065 - val_mse: 0.0174 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 5.2463 - mae: 2.0980 - mse: 4.7727 - val_loss: 0.4903 - val_mae: 0.1048 - val_mse: 0.0168 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 4.8299 - mae: 1.8061 - mse: 4.3564 - val_loss: 0.4895 - val_mae: 0.1023 - val_mse: 0.0160 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 4.3242 - mae: 1.9136 - mse: 3.8507 - val_loss: 0.4887 - val_mae: 0.1000 - val_mse: 0.0153 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 2.8973 - mae: 1.3843 - mse: 2.4238 - val_loss: 0.4881 - val_mae: 0.0984 - val_mse: 0.0147 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 3.9916 - mae: 1.7330 - mse: 3.5182 - val_loss: 0.4876 - val_mae: 0.0967 - val_mse: 0.0143 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 4.0943 - mae: 1.6306 - mse: 3.6209 - val_loss: 0.4870 - val_mae: 0.0946 - val_mse: 0.0137 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 4.8990 - mae: 1.9357 - mse: 4.4257 - val_loss: 0.4865 - val_mae: 0.0928 - val_mse: 0.0133 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 1.8332 - mae: 0.9232 - mse: 1.3599 - val_loss: 0.4862 - val_mae: 0.0914 - val_mse: 0.0129 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 3.5246 - mae: 1.4853 - mse: 3.0513 - val_loss: 0.4857 - val_mae: 0.0895 - val_mse: 0.0124 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 2.1164 - mae: 1.2036 - mse: 1.6431 - val_loss: 0.4851 - val_mae: 0.0872 - val_mse: 0.0119 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 2.8853 - mae: 1.2766 - mse: 2.4120 - val_loss: 0.4846 - val_mae: 0.0860 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 5.1924 - mae: 1.6980 - mse: 4.7192 - val_loss: 0.4844 - val_mae: 0.0858 - val_mse: 0.0113 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 1.9015 - mae: 1.0560 - mse: 1.4283 - val_loss: 0.4842 - val_mae: 0.0856 - val_mse: 0.0110 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 5.0712 - mae: 2.0621 - mse: 4.5981 - val_loss: 0.4837 - val_mae: 0.0851 - val_mse: 0.0106 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 3.1059 - mae: 1.4002 - mse: 2.6328 - val_loss: 0.4834 - val_mae: 0.0848 - val_mse: 0.0103 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 2.7818 - mae: 1.3506 - mse: 2.3087 - val_loss: 0.4830 - val_mae: 0.0843 - val_mse: 0.0100 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 2.4830 - mae: 1.3039 - mse: 2.0100 - val_loss: 0.4828 - val_mae: 0.0839 - val_mse: 0.0097 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 3.1865 - mae: 1.5652 - mse: 2.7134 - val_loss: 0.4824 - val_mae: 0.0833 - val_mse: 0.0094 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 3.0849 - mae: 1.4978 - mse: 2.6119 - val_loss: 0.4821 - val_mae: 0.0825 - val_mse: 0.0091 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 4.0469 - mae: 1.5216 - mse: 3.5739 - val_loss: 0.4818 - val_mae: 0.0818 - val_mse: 0.0088 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.4133 - mae: 0.9385 - mse: 0.9403 - val_loss: 0.4814 - val_mae: 0.0808 - val_mse: 0.0085 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 2.4944 - mae: 1.2353 - mse: 2.0214 - val_loss: 0.4812 - val_mae: 0.0800 - val_mse: 0.0083 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 3.2839 - mae: 1.3724 - mse: 2.8109 - val_loss: 0.4811 - val_mae: 0.0796 - val_mse: 0.0082 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 2.3770 - mae: 1.2948 - mse: 1.9040 - val_loss: 0.4810 - val_mae: 0.0788 - val_mse: 0.0080 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.6304 - mae: 0.8975 - mse: 1.1575 - val_loss: 0.4808 - val_mae: 0.0782 - val_mse: 0.0079 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 2.2951 - mae: 1.1117 - mse: 1.8223 - val_loss: 0.4807 - val_mae: 0.0774 - val_mse: 0.0078 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 2.4104 - mae: 1.1654 - mse: 1.9375 - val_loss: 0.4806 - val_mae: 0.0767 - val_mse: 0.0077 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 3.0184 - mae: 1.4627 - mse: 2.5456 - val_loss: 0.4805 - val_mae: 0.0757 - val_mse: 0.0077 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 2.0473 - mae: 0.9762 - mse: 1.5744 - val_loss: 0.4805 - val_mae: 0.0749 - val_mse: 0.0076 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 3.1150 - mae: 1.3213 - mse: 2.6422 - val_loss: 0.4805 - val_mae: 0.0751 - val_mse: 0.0077 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.0560 - mae: 1.1158 - mse: 1.5832 - val_loss: 0.4805 - val_mae: 0.0761 - val_mse: 0.0077 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 2.8345 - mae: 1.3874 - mse: 2.3616 - val_loss: 0.4806 - val_mae: 0.0768 - val_mse: 0.0078 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 0.9655 - mae: 0.4776 - mse: 0.4927 - val_loss: 0.4807 - val_mae: 0.0776 - val_mse: 0.0079 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 2.2865 - mae: 1.1223 - mse: 1.8137 - val_loss: 0.4808 - val_mae: 0.0784 - val_mse: 0.0080 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.4785 - mae: 0.9187 - mse: 1.0057 - val_loss: 0.4809 - val_mae: 0.0789 - val_mse: 0.0081 - learning_rate: 1.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 2.5774 - mae: 1.2612 - mse: 2.1047 - val_loss: 0.4809 - val_mae: 0.0790 - val_mse: 0.0082 - learning_rate: 1.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.1147 - mae: 0.7619 - mse: 0.6420 - val_loss: 0.4810 - val_mae: 0.0792 - val_mse: 0.0082 - learning_rate: 1.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 3.3435 - mae: 1.3882 - mse: 2.8707 - val_loss: 0.4810 - val_mae: 0.0792 - val_mse: 0.0082 - learning_rate: 1.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 3.4062 - mae: 1.5678 - mse: 2.9334 - val_loss: 0.4811 - val_mae: 0.0798 - val_mse: 0.0084 - learning_rate: 1.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 2.5849 - mae: 1.3014 - mse: 2.1122 - val_loss: 0.4811 - val_mae: 0.0799 - val_mse: 0.0084 - learning_rate: 2.0000e-05\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.1511 - mae: 1.3442 - mse: 2.6784 - val_loss: 0.4812 - val_mae: 0.0801 - val_mse: 0.0084 - learning_rate: 2.0000e-05\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 3.1912 - mae: 1.2778 - mse: 2.7185 - val_loss: 0.4813 - val_mae: 0.0804 - val_mse: 0.0085 - learning_rate: 2.0000e-05\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 1.2876 - mae: 0.7184 - mse: 0.8149 - val_loss: 0.4813 - val_mae: 0.0806 - val_mse: 0.0086 - learning_rate: 2.0000e-05\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 3.2409 - mae: 1.4281 - mse: 2.7681 - val_loss: 0.4813 - val_mae: 0.0805 - val_mse: 0.0085 - learning_rate: 2.0000e-05\n",
            "Grupo 45 - RMSE: 0.000242, MAE: 0.000207, sMAPE: 3.92%\n",
            "\n",
            "Treinando modelo para grupo etário 50...\n",
            "Grupo 50: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 2.7788 - mae: 1.3664 - mse: 2.3092 - val_loss: 0.4893 - val_mae: 0.1281 - val_mse: 0.0201 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 1.1725 - mae: 0.7860 - mse: 0.7033 - val_loss: 0.4891 - val_mae: 0.1282 - val_mse: 0.0201 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 3.2436 - mae: 1.2695 - mse: 2.7746 - val_loss: 0.4898 - val_mae: 0.1312 - val_mse: 0.0209 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 1.7128 - mae: 0.9639 - mse: 1.2439 - val_loss: 0.4905 - val_mae: 0.1342 - val_mse: 0.0217 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1.2145 - mae: 0.7199 - mse: 0.7456 - val_loss: 0.4909 - val_mae: 0.1358 - val_mse: 0.0221 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 2.9056 - mae: 1.5152 - mse: 2.4369 - val_loss: 0.4910 - val_mae: 0.1362 - val_mse: 0.0223 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 1.6047 - mae: 0.8362 - mse: 1.1360 - val_loss: 0.4909 - val_mae: 0.1358 - val_mse: 0.0223 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 1.6061 - mae: 1.0113 - mse: 1.1375 - val_loss: 0.4912 - val_mae: 0.1365 - val_mse: 0.0226 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 2.6252 - mae: 1.4294 - mse: 2.1566 - val_loss: 0.4920 - val_mae: 0.1390 - val_mse: 0.0234 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 2.0370 - mae: 1.0603 - mse: 1.5684 - val_loss: 0.4925 - val_mae: 0.1406 - val_mse: 0.0239 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.6563 - mae: 0.2836 - mse: 0.1877 - val_loss: 0.4930 - val_mae: 0.1425 - val_mse: 0.0245 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 2.9062 - mae: 1.3803 - mse: 2.4376 - val_loss: 0.4928 - val_mae: 0.1416 - val_mse: 0.0242 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.8642 - mae: 1.0304 - mse: 1.3956 - val_loss: 0.4933 - val_mae: 0.1433 - val_mse: 0.0247 - learning_rate: 2.0000e-05\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 1.1860 - mae: 0.8000 - mse: 0.7175 - val_loss: 0.4936 - val_mae: 0.1444 - val_mse: 0.0251 - learning_rate: 2.0000e-05\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 2.0180 - mae: 1.0586 - mse: 1.5494 - val_loss: 0.4937 - val_mae: 0.1444 - val_mse: 0.0251 - learning_rate: 2.0000e-05\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 2.9701 - mae: 1.4304 - mse: 2.5016 - val_loss: 0.4943 - val_mae: 0.1466 - val_mse: 0.0257 - learning_rate: 2.0000e-05\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.6989 - mae: 1.0434 - mse: 1.2304 - val_loss: 0.4943 - val_mae: 0.1467 - val_mse: 0.0258 - learning_rate: 2.0000e-05\n",
            "Grupo 50 - RMSE: 0.000527, MAE: 0.000477, sMAPE: 6.37%\n",
            "\n",
            "Treinando modelo para grupo etário 55...\n",
            "Grupo 55: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 2.0243 - mae: 0.9901 - mse: 1.5537 - val_loss: 0.4893 - val_mae: 0.1222 - val_mse: 0.0191 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 6.1701 - mae: 1.7535 - mse: 5.7000 - val_loss: 0.4880 - val_mae: 0.1175 - val_mse: 0.0180 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.8362 - mae: 1.0789 - mse: 1.3662 - val_loss: 0.4871 - val_mae: 0.1144 - val_mse: 0.0172 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 3.7269 - mae: 1.3948 - mse: 3.2570 - val_loss: 0.4867 - val_mae: 0.1128 - val_mse: 0.0169 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.6814 - mae: 0.9603 - mse: 1.2116 - val_loss: 0.4863 - val_mae: 0.1113 - val_mse: 0.0165 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 1.7432 - mae: 0.8362 - mse: 1.2735 - val_loss: 0.4859 - val_mae: 0.1099 - val_mse: 0.0163 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.6706 - mae: 0.8704 - mse: 1.2010 - val_loss: 0.4854 - val_mae: 0.1079 - val_mse: 0.0158 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 3.9711 - mae: 1.5626 - mse: 3.5016 - val_loss: 0.4848 - val_mae: 0.1055 - val_mse: 0.0153 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.8988 - mae: 0.8526 - mse: 1.4293 - val_loss: 0.4844 - val_mae: 0.1041 - val_mse: 0.0150 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 1.3204 - mae: 0.7276 - mse: 0.8510 - val_loss: 0.4840 - val_mae: 0.1023 - val_mse: 0.0147 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 1.0858 - mae: 0.6471 - mse: 0.6165 - val_loss: 0.4835 - val_mae: 0.1000 - val_mse: 0.0142 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.4696 - mae: 0.7189 - mse: 1.0004 - val_loss: 0.4826 - val_mae: 0.0960 - val_mse: 0.0134 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 2.7350 - mae: 1.2942 - mse: 2.2658 - val_loss: 0.4820 - val_mae: 0.0931 - val_mse: 0.0128 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 1.4326 - mae: 0.7950 - mse: 0.9634 - val_loss: 0.4815 - val_mae: 0.0908 - val_mse: 0.0124 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 2.4105 - mae: 1.0163 - mse: 1.9413 - val_loss: 0.4809 - val_mae: 0.0875 - val_mse: 0.0118 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.4300 - mae: 0.8011 - mse: 0.9609 - val_loss: 0.4805 - val_mae: 0.0856 - val_mse: 0.0115 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 4.0614 - mae: 1.4389 - mse: 3.5924 - val_loss: 0.4801 - val_mae: 0.0834 - val_mse: 0.0111 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 2.2350 - mae: 1.2243 - mse: 1.7660 - val_loss: 0.4798 - val_mae: 0.0819 - val_mse: 0.0108 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3557 - mae: 0.9097 - mse: 1.8868 - val_loss: 0.4793 - val_mae: 0.0793 - val_mse: 0.0103 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 3.3405 - mae: 1.3490 - mse: 2.8715 - val_loss: 0.4788 - val_mae: 0.0775 - val_mse: 0.0099 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 2.4045 - mae: 0.9972 - mse: 1.9356 - val_loss: 0.4785 - val_mae: 0.0764 - val_mse: 0.0096 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 3.1244 - mae: 1.5210 - mse: 2.6555 - val_loss: 0.4783 - val_mae: 0.0756 - val_mse: 0.0094 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.2659 - mae: 1.1223 - mse: 1.7970 - val_loss: 0.4778 - val_mae: 0.0737 - val_mse: 0.0090 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.2274 - mae: 0.7653 - mse: 0.7586 - val_loss: 0.4775 - val_mae: 0.0722 - val_mse: 0.0086 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.3852 - mae: 0.8716 - mse: 0.9164 - val_loss: 0.4774 - val_mae: 0.0720 - val_mse: 0.0086 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 2.3073 - mae: 1.2407 - mse: 1.8385 - val_loss: 0.4769 - val_mae: 0.0700 - val_mse: 0.0081 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 2.2868 - mae: 1.2371 - mse: 1.8180 - val_loss: 0.4766 - val_mae: 0.0686 - val_mse: 0.0079 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1.9385 - mae: 0.8460 - mse: 1.4697 - val_loss: 0.4762 - val_mae: 0.0667 - val_mse: 0.0075 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 2.6346 - mae: 1.2351 - mse: 2.1659 - val_loss: 0.4758 - val_mae: 0.0658 - val_mse: 0.0071 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 2.6979 - mae: 1.0869 - mse: 2.2292 - val_loss: 0.4754 - val_mae: 0.0651 - val_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 2.3666 - mae: 1.0346 - mse: 1.8979 - val_loss: 0.4751 - val_mae: 0.0646 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.7026 - mae: 0.4345 - mse: 0.2339 - val_loss: 0.4750 - val_mae: 0.0643 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 2.5819 - mae: 1.1608 - mse: 2.1133 - val_loss: 0.4747 - val_mae: 0.0638 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.8042 - mae: 0.4463 - mse: 0.3356 - val_loss: 0.4745 - val_mae: 0.0633 - val_mse: 0.0058 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 3.1757 - mae: 1.4066 - mse: 2.7071 - val_loss: 0.4742 - val_mae: 0.0626 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.2045 - mae: 0.7817 - mse: 0.7358 - val_loss: 0.4740 - val_mae: 0.0624 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 3.6882 - mae: 1.0878 - mse: 3.2196 - val_loss: 0.4739 - val_mae: 0.0620 - val_mse: 0.0053 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 2.6545 - mae: 1.3093 - mse: 2.1859 - val_loss: 0.4737 - val_mae: 0.0616 - val_mse: 0.0051 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 1.5640 - mae: 0.8296 - mse: 1.0954 - val_loss: 0.4735 - val_mae: 0.0611 - val_mse: 0.0050 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.8186 - mae: 0.5000 - mse: 0.3501 - val_loss: 0.4734 - val_mae: 0.0606 - val_mse: 0.0049 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 3.6854 - mae: 1.1346 - mse: 3.2169 - val_loss: 0.4732 - val_mae: 0.0599 - val_mse: 0.0047 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 1.0359 - mae: 0.5885 - mse: 0.5674 - val_loss: 0.4731 - val_mae: 0.0594 - val_mse: 0.0046 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 0.9033 - mae: 0.5981 - mse: 0.4349 - val_loss: 0.4730 - val_mae: 0.0588 - val_mse: 0.0045 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 2.9616 - mae: 1.3526 - mse: 2.4932 - val_loss: 0.4729 - val_mae: 0.0583 - val_mse: 0.0045 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.3845 - mae: 0.8230 - mse: 0.9160 - val_loss: 0.4728 - val_mae: 0.0578 - val_mse: 0.0044 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 1.4288 - mae: 0.6491 - mse: 0.9604 - val_loss: 0.4728 - val_mae: 0.0578 - val_mse: 0.0044 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 2.0297 - mae: 1.0580 - mse: 1.5613 - val_loss: 0.4727 - val_mae: 0.0573 - val_mse: 0.0044 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - loss: 1.8398 - mae: 0.9277 - mse: 1.3714 - val_loss: 0.4727 - val_mae: 0.0569 - val_mse: 0.0043 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.6399 - mae: 0.2794 - mse: 0.1716 - val_loss: 0.4726 - val_mae: 0.0563 - val_mse: 0.0043 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 1.7272 - mae: 0.9078 - mse: 1.2588 - val_loss: 0.4726 - val_mae: 0.0561 - val_mse: 0.0043 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 1.4590 - mae: 0.7678 - mse: 0.9907 - val_loss: 0.4726 - val_mae: 0.0566 - val_mse: 0.0043 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 1.1956 - mae: 0.6274 - mse: 0.7273 - val_loss: 0.4726 - val_mae: 0.0573 - val_mse: 0.0043 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 2.5330 - mae: 1.2117 - mse: 2.0647 - val_loss: 0.4726 - val_mae: 0.0578 - val_mse: 0.0044 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 1.4115 - mae: 0.8646 - mse: 0.9433 - val_loss: 0.4726 - val_mae: 0.0580 - val_mse: 0.0044 - learning_rate: 1.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 2.1017 - mae: 0.9670 - mse: 1.6335 - val_loss: 0.4727 - val_mae: 0.0582 - val_mse: 0.0044 - learning_rate: 1.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.2587 - mae: 0.7985 - mse: 0.7905 - val_loss: 0.4727 - val_mae: 0.0584 - val_mse: 0.0044 - learning_rate: 1.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 1.0542 - mae: 0.6593 - mse: 0.5859 - val_loss: 0.4727 - val_mae: 0.0584 - val_mse: 0.0044 - learning_rate: 1.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 0.7297 - mae: 0.4306 - mse: 0.2615 - val_loss: 0.4727 - val_mae: 0.0586 - val_mse: 0.0045 - learning_rate: 1.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 2.4813 - mae: 1.0469 - mse: 2.0131 - val_loss: 0.4727 - val_mae: 0.0589 - val_mse: 0.0045 - learning_rate: 2.0000e-05\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 1.5168 - mae: 0.8579 - mse: 1.0486 - val_loss: 0.4727 - val_mae: 0.0586 - val_mse: 0.0045 - learning_rate: 2.0000e-05\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 1.4419 - mae: 0.8657 - mse: 0.9736 - val_loss: 0.4727 - val_mae: 0.0585 - val_mse: 0.0045 - learning_rate: 2.0000e-05\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 3.2638 - mae: 1.3945 - mse: 2.7956 - val_loss: 0.4727 - val_mae: 0.0587 - val_mse: 0.0045 - learning_rate: 2.0000e-05\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 2.0001 - mae: 1.0963 - mse: 1.5319 - val_loss: 0.4727 - val_mae: 0.0584 - val_mse: 0.0045 - learning_rate: 2.0000e-05\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.6528 - mae: 1.0136 - mse: 1.1846 - val_loss: 0.4727 - val_mae: 0.0585 - val_mse: 0.0045 - learning_rate: 1.0000e-05\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.5840 - mae: 0.2537 - mse: 0.1158 - val_loss: 0.4727 - val_mae: 0.0584 - val_mse: 0.0045 - learning_rate: 1.0000e-05\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 2.2104 - mae: 1.1317 - mse: 1.7422 - val_loss: 0.4727 - val_mae: 0.0583 - val_mse: 0.0045 - learning_rate: 1.0000e-05\n",
            "Grupo 55 - RMSE: 0.000344, MAE: 0.000296, sMAPE: 2.67%\n",
            "\n",
            "Treinando modelo para grupo etário 60...\n",
            "Grupo 60: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - loss: 3.3140 - mae: 1.4504 - mse: 2.8410 - val_loss: 0.5048 - val_mae: 0.1740 - val_mse: 0.0322 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.7896 - mae: 0.7929 - mse: 1.3170 - val_loss: 0.5040 - val_mae: 0.1723 - val_mse: 0.0315 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 3.1639 - mae: 1.3384 - mse: 2.6915 - val_loss: 0.5040 - val_mae: 0.1726 - val_mse: 0.0317 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.3110 - mae: 0.7149 - mse: 0.8387 - val_loss: 0.5035 - val_mae: 0.1714 - val_mse: 0.0313 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 2.5897 - mae: 1.0014 - mse: 2.1175 - val_loss: 0.5024 - val_mae: 0.1688 - val_mse: 0.0303 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 1.5851 - mae: 0.9255 - mse: 1.1130 - val_loss: 0.5020 - val_mae: 0.1675 - val_mse: 0.0299 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 0.8159 - mae: 0.5504 - mse: 0.3438 - val_loss: 0.5016 - val_mae: 0.1665 - val_mse: 0.0296 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.7496 - mae: 0.4491 - mse: 0.2776 - val_loss: 0.5012 - val_mae: 0.1657 - val_mse: 0.0293 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.6417 - mae: 0.8191 - mse: 1.1698 - val_loss: 0.5009 - val_mae: 0.1649 - val_mse: 0.0290 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.9590 - mae: 0.4768 - mse: 0.4872 - val_loss: 0.5005 - val_mae: 0.1637 - val_mse: 0.0287 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 2.8237 - mae: 1.3601 - mse: 2.3519 - val_loss: 0.5007 - val_mae: 0.1646 - val_mse: 0.0289 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.3897 - mae: 0.6483 - mse: 0.9180 - val_loss: 0.5012 - val_mae: 0.1662 - val_mse: 0.0295 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 0.8788 - mae: 0.5438 - mse: 0.4070 - val_loss: 0.5009 - val_mae: 0.1656 - val_mse: 0.0293 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.4967 - mae: 0.9359 - mse: 1.0251 - val_loss: 0.5003 - val_mae: 0.1638 - val_mse: 0.0287 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.9903 - mae: 0.5330 - mse: 0.5187 - val_loss: 0.4997 - val_mae: 0.1620 - val_mse: 0.0281 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 1.5740 - mae: 0.9550 - mse: 1.1024 - val_loss: 0.4999 - val_mae: 0.1628 - val_mse: 0.0284 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 4.1679 - mae: 1.3956 - mse: 3.6964 - val_loss: 0.4999 - val_mae: 0.1630 - val_mse: 0.0285 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 1.5186 - mae: 0.7942 - mse: 1.0471 - val_loss: 0.4999 - val_mae: 0.1628 - val_mse: 0.0284 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 1.2131 - mae: 0.6683 - mse: 0.7416 - val_loss: 0.4998 - val_mae: 0.1628 - val_mse: 0.0284 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 2.6201 - mae: 1.2457 - mse: 2.1487 - val_loss: 0.4996 - val_mae: 0.1623 - val_mse: 0.0283 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 2.7474 - mae: 1.2533 - mse: 2.2761 - val_loss: 0.4996 - val_mae: 0.1623 - val_mse: 0.0283 - learning_rate: 1.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.9357 - mae: 0.9887 - mse: 1.4643 - val_loss: 0.5000 - val_mae: 0.1635 - val_mse: 0.0287 - learning_rate: 1.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 2.2885 - mae: 1.0614 - mse: 1.8171 - val_loss: 0.5001 - val_mae: 0.1637 - val_mse: 0.0287 - learning_rate: 1.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.8377 - mae: 0.4728 - mse: 0.3663 - val_loss: 0.5000 - val_mae: 0.1635 - val_mse: 0.0286 - learning_rate: 1.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 1.5205 - mae: 0.7562 - mse: 1.0492 - val_loss: 0.4997 - val_mae: 0.1629 - val_mse: 0.0284 - learning_rate: 1.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 1.8838 - mae: 1.0678 - mse: 1.4125 - val_loss: 0.4993 - val_mae: 0.1616 - val_mse: 0.0280 - learning_rate: 2.0000e-05\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 2.3973 - mae: 1.2926 - mse: 1.9260 - val_loss: 0.4993 - val_mae: 0.1614 - val_mse: 0.0279 - learning_rate: 2.0000e-05\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 2.0205 - mae: 1.1661 - mse: 1.5492 - val_loss: 0.4998 - val_mae: 0.1629 - val_mse: 0.0285 - learning_rate: 2.0000e-05\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 2.5678 - mae: 1.3285 - mse: 2.0965 - val_loss: 0.4998 - val_mae: 0.1628 - val_mse: 0.0285 - learning_rate: 2.0000e-05\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.0764 - mae: 1.1337 - mse: 1.6051 - val_loss: 0.4999 - val_mae: 0.1631 - val_mse: 0.0286 - learning_rate: 2.0000e-05\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.9915 - mae: 1.0678 - mse: 1.5202 - val_loss: 0.4997 - val_mae: 0.1625 - val_mse: 0.0284 - learning_rate: 2.0000e-05\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.7343 - mae: 0.4355 - mse: 0.2629 - val_loss: 0.4994 - val_mae: 0.1617 - val_mse: 0.0281 - learning_rate: 1.0000e-05\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 0.6724 - mae: 0.3603 - mse: 0.2011 - val_loss: 0.4991 - val_mae: 0.1607 - val_mse: 0.0278 - learning_rate: 1.0000e-05\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - loss: 1.6159 - mae: 0.9250 - mse: 1.1446 - val_loss: 0.4991 - val_mae: 0.1608 - val_mse: 0.0278 - learning_rate: 1.0000e-05\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.3312 - mae: 0.6888 - mse: 0.8599 - val_loss: 0.4992 - val_mae: 0.1610 - val_mse: 0.0279 - learning_rate: 1.0000e-05\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - loss: 1.2423 - mae: 0.5651 - mse: 0.7710 - val_loss: 0.4998 - val_mae: 0.1629 - val_mse: 0.0285 - learning_rate: 1.0000e-05\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.2396 - mae: 0.7291 - mse: 0.7683 - val_loss: 0.5002 - val_mae: 0.1641 - val_mse: 0.0289 - learning_rate: 1.0000e-05\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 1.7913 - mae: 0.9618 - mse: 1.3200 - val_loss: 0.5001 - val_mae: 0.1639 - val_mse: 0.0288 - learning_rate: 1.0000e-05\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.8813 - mae: 0.5562 - mse: 0.4100 - val_loss: 0.5001 - val_mae: 0.1640 - val_mse: 0.0288 - learning_rate: 1.0000e-05\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.8358 - mae: 1.0673 - mse: 1.3645 - val_loss: 0.5002 - val_mae: 0.1640 - val_mse: 0.0289 - learning_rate: 1.0000e-05\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.8435 - mae: 0.4844 - mse: 0.3722 - val_loss: 0.5000 - val_mae: 0.1636 - val_mse: 0.0287 - learning_rate: 1.0000e-05\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 1.5593 - mae: 0.9215 - mse: 1.0880 - val_loss: 0.4999 - val_mae: 0.1632 - val_mse: 0.0286 - learning_rate: 1.0000e-05\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.1573 - mae: 0.7072 - mse: 0.6860 - val_loss: 0.4997 - val_mae: 0.1627 - val_mse: 0.0284 - learning_rate: 1.0000e-05\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.4122 - mae: 0.8138 - mse: 0.9409 - val_loss: 0.5003 - val_mae: 0.1647 - val_mse: 0.0291 - learning_rate: 1.0000e-05\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 2.4887 - mae: 1.2144 - mse: 2.0174 - val_loss: 0.5004 - val_mae: 0.1650 - val_mse: 0.0291 - learning_rate: 1.0000e-05\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.7960 - mae: 0.4423 - mse: 0.3247 - val_loss: 0.5009 - val_mae: 0.1664 - val_mse: 0.0296 - learning_rate: 1.0000e-05\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 2.7152 - mae: 1.0614 - mse: 2.2439 - val_loss: 0.5012 - val_mae: 0.1674 - val_mse: 0.0299 - learning_rate: 1.0000e-05\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 1.7895 - mae: 1.0325 - mse: 1.3182 - val_loss: 0.5014 - val_mae: 0.1680 - val_mse: 0.0301 - learning_rate: 1.0000e-05\n",
            "Grupo 60 - RMSE: 0.001106, MAE: 0.001066, sMAPE: 6.72%\n",
            "\n",
            "Treinando modelo para grupo etário 65...\n",
            "Grupo 65: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 3.1842 - mae: 1.4440 - mse: 2.7115 - val_loss: 0.4804 - val_mae: 0.0818 - val_mse: 0.0080 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 2.5609 - mae: 1.2610 - mse: 2.0885 - val_loss: 0.4799 - val_mae: 0.0790 - val_mse: 0.0076 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.9972 - mae: 1.0060 - mse: 1.5249 - val_loss: 0.4792 - val_mae: 0.0752 - val_mse: 0.0070 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 1.4388 - mae: 0.7439 - mse: 0.9666 - val_loss: 0.4786 - val_mae: 0.0715 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1.8043 - mae: 0.8255 - mse: 1.3321 - val_loss: 0.4782 - val_mae: 0.0690 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.9141 - mae: 0.5930 - mse: 0.4420 - val_loss: 0.4777 - val_mae: 0.0652 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 3.6228 - mae: 1.5063 - mse: 3.1507 - val_loss: 0.4771 - val_mae: 0.0615 - val_mse: 0.0051 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.7817 - mae: 0.9009 - mse: 1.3096 - val_loss: 0.4768 - val_mae: 0.0590 - val_mse: 0.0048 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 2.8068 - mae: 1.2729 - mse: 2.3348 - val_loss: 0.4764 - val_mae: 0.0561 - val_mse: 0.0044 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5983 - mae: 1.3009 - mse: 2.1263 - val_loss: 0.4762 - val_mae: 0.0542 - val_mse: 0.0042 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.1218 - mae: 0.5585 - mse: 0.6499 - val_loss: 0.4758 - val_mae: 0.0504 - val_mse: 0.0038 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 2.1047 - mae: 1.0911 - mse: 1.6327 - val_loss: 0.4754 - val_mae: 0.0473 - val_mse: 0.0035 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.9123 - mae: 0.9315 - mse: 1.4404 - val_loss: 0.4752 - val_mae: 0.0452 - val_mse: 0.0033 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.4296 - mae: 0.7313 - mse: 0.9578 - val_loss: 0.4749 - val_mae: 0.0432 - val_mse: 0.0031 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.9309 - mae: 0.9774 - mse: 1.4590 - val_loss: 0.4747 - val_mae: 0.0418 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - loss: 2.6579 - mae: 1.4368 - mse: 2.1861 - val_loss: 0.4744 - val_mae: 0.0401 - val_mse: 0.0027 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 3.5425 - mae: 1.3536 - mse: 3.0708 - val_loss: 0.4741 - val_mae: 0.0387 - val_mse: 0.0024 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.4515 - mae: 0.8475 - mse: 0.9798 - val_loss: 0.4739 - val_mae: 0.0381 - val_mse: 0.0022 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.3675 - mae: 0.8271 - mse: 0.8958 - val_loss: 0.4737 - val_mae: 0.0375 - val_mse: 0.0021 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 3.1488 - mae: 1.4725 - mse: 2.6771 - val_loss: 0.4735 - val_mae: 0.0370 - val_mse: 0.0019 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.4417 - mae: 0.8647 - mse: 0.9701 - val_loss: 0.4733 - val_mae: 0.0360 - val_mse: 0.0017 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 2.6640 - mae: 1.3798 - mse: 2.1924 - val_loss: 0.4732 - val_mae: 0.0355 - val_mse: 0.0016 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.6143 - mae: 0.9908 - mse: 1.1427 - val_loss: 0.4730 - val_mae: 0.0347 - val_mse: 0.0015 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 1.6720 - mae: 0.8480 - mse: 1.2005 - val_loss: 0.4729 - val_mae: 0.0341 - val_mse: 0.0014 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 2.2722 - mae: 1.1189 - mse: 1.8007 - val_loss: 0.4728 - val_mae: 0.0333 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 2.7027 - mae: 1.3520 - mse: 2.2312 - val_loss: 0.4728 - val_mae: 0.0329 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.5018 - mae: 0.9623 - mse: 1.0303 - val_loss: 0.4727 - val_mae: 0.0323 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.9372 - mae: 0.5920 - mse: 0.4657 - val_loss: 0.4727 - val_mae: 0.0319 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 1.6802 - mae: 0.9597 - mse: 1.2088 - val_loss: 0.4727 - val_mae: 0.0325 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.9961 - mae: 0.5698 - mse: 0.5247 - val_loss: 0.4728 - val_mae: 0.0332 - val_mse: 0.0014 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 4.6422 - mae: 1.4980 - mse: 4.1708 - val_loss: 0.4728 - val_mae: 0.0341 - val_mse: 0.0015 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 2.8987 - mae: 1.2981 - mse: 2.4273 - val_loss: 0.4729 - val_mae: 0.0348 - val_mse: 0.0015 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 3.2122 - mae: 1.2570 - mse: 2.7409 - val_loss: 0.4729 - val_mae: 0.0355 - val_mse: 0.0016 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 1.3773 - mae: 0.5581 - mse: 0.9060 - val_loss: 0.4730 - val_mae: 0.0358 - val_mse: 0.0017 - learning_rate: 1.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.2969 - mae: 0.6120 - mse: 0.8256 - val_loss: 0.4729 - val_mae: 0.0354 - val_mse: 0.0016 - learning_rate: 1.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 2.4621 - mae: 1.2122 - mse: 1.9908 - val_loss: 0.4729 - val_mae: 0.0356 - val_mse: 0.0016 - learning_rate: 1.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 1.7025 - mae: 0.8357 - mse: 1.2312 - val_loss: 0.4729 - val_mae: 0.0355 - val_mse: 0.0016 - learning_rate: 1.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 1.2792 - mae: 0.7751 - mse: 0.8079 - val_loss: 0.4729 - val_mae: 0.0355 - val_mse: 0.0016 - learning_rate: 1.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 2.7699 - mae: 1.2606 - mse: 2.2986 - val_loss: 0.4729 - val_mae: 0.0358 - val_mse: 0.0017 - learning_rate: 2.0000e-05\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 2.8717 - mae: 1.1128 - mse: 2.4004 - val_loss: 0.4729 - val_mae: 0.0359 - val_mse: 0.0017 - learning_rate: 2.0000e-05\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 2.3399 - mae: 1.1509 - mse: 1.8686 - val_loss: 0.4729 - val_mae: 0.0358 - val_mse: 0.0017 - learning_rate: 2.0000e-05\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 2.0134 - mae: 1.1161 - mse: 1.5421 - val_loss: 0.4730 - val_mae: 0.0360 - val_mse: 0.0017 - learning_rate: 2.0000e-05\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.9782 - mae: 0.6189 - mse: 0.5069 - val_loss: 0.4730 - val_mae: 0.0362 - val_mse: 0.0017 - learning_rate: 2.0000e-05\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.5338 - mae: 0.6773 - mse: 1.0626 - val_loss: 0.4730 - val_mae: 0.0362 - val_mse: 0.0017 - learning_rate: 1.0000e-05\n",
            "Grupo 65 - RMSE: 0.000316, MAE: 0.000282, sMAPE: 1.19%\n",
            "\n",
            "Treinando modelo para grupo etário 70...\n",
            "Grupo 70: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - loss: 0.9187 - mae: 0.5746 - mse: 0.4475 - val_loss: 0.4981 - val_mae: 0.1542 - val_mse: 0.0274 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.4661 - mae: 0.9163 - mse: 0.9954 - val_loss: 0.4975 - val_mae: 0.1530 - val_mse: 0.0270 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - loss: 1.9112 - mae: 1.1220 - mse: 1.4408 - val_loss: 0.4968 - val_mae: 0.1513 - val_mse: 0.0265 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 1.0260 - mae: 0.6079 - mse: 0.5557 - val_loss: 0.4963 - val_mae: 0.1502 - val_mse: 0.0262 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 2.1840 - mae: 0.9779 - mse: 1.7138 - val_loss: 0.4956 - val_mae: 0.1481 - val_mse: 0.0256 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.9206 - mae: 1.0894 - mse: 1.4505 - val_loss: 0.4951 - val_mae: 0.1467 - val_mse: 0.0251 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 6.0744 - mae: 1.7812 - mse: 5.6045 - val_loss: 0.4943 - val_mae: 0.1443 - val_mse: 0.0244 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 1.6521 - mae: 0.8255 - mse: 1.1822 - val_loss: 0.4939 - val_mae: 0.1431 - val_mse: 0.0241 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 2.4480 - mae: 1.2869 - mse: 1.9782 - val_loss: 0.4933 - val_mae: 0.1411 - val_mse: 0.0235 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 1.1683 - mae: 0.7769 - mse: 0.6986 - val_loss: 0.4927 - val_mae: 0.1390 - val_mse: 0.0230 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 1.0682 - mae: 0.6811 - mse: 0.5986 - val_loss: 0.4921 - val_mae: 0.1371 - val_mse: 0.0225 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 2.4701 - mae: 1.0269 - mse: 2.0004 - val_loss: 0.4913 - val_mae: 0.1346 - val_mse: 0.0218 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 0.8663 - mae: 0.5377 - mse: 0.3967 - val_loss: 0.4908 - val_mae: 0.1325 - val_mse: 0.0213 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 2.4261 - mae: 1.0647 - mse: 1.9566 - val_loss: 0.4903 - val_mae: 0.1310 - val_mse: 0.0209 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 4.7117 - mae: 1.6278 - mse: 4.2422 - val_loss: 0.4898 - val_mae: 0.1293 - val_mse: 0.0204 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.8457 - mae: 0.5536 - mse: 0.3762 - val_loss: 0.4891 - val_mae: 0.1265 - val_mse: 0.0197 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.7327 - mae: 1.0011 - mse: 1.2633 - val_loss: 0.4886 - val_mae: 0.1250 - val_mse: 0.0193 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 2.1581 - mae: 1.0062 - mse: 1.6888 - val_loss: 0.4881 - val_mae: 0.1231 - val_mse: 0.0188 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.0509 - mae: 0.5384 - mse: 0.5817 - val_loss: 0.4875 - val_mae: 0.1208 - val_mse: 0.0183 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 1.2180 - mae: 0.7895 - mse: 0.7487 - val_loss: 0.4867 - val_mae: 0.1176 - val_mse: 0.0175 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.1959 - mae: 0.6732 - mse: 0.7267 - val_loss: 0.4863 - val_mae: 0.1159 - val_mse: 0.0171 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.6058 - mae: 1.0515 - mse: 1.1366 - val_loss: 0.4857 - val_mae: 0.1135 - val_mse: 0.0165 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.7827 - mae: 0.3520 - mse: 0.3135 - val_loss: 0.4856 - val_mae: 0.1137 - val_mse: 0.0166 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 1.4814 - mae: 0.7921 - mse: 1.0123 - val_loss: 0.4854 - val_mae: 0.1126 - val_mse: 0.0163 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 4.2712 - mae: 1.3562 - mse: 3.8022 - val_loss: 0.4849 - val_mae: 0.1106 - val_mse: 0.0159 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 2.2148 - mae: 1.1438 - mse: 1.7458 - val_loss: 0.4847 - val_mae: 0.1099 - val_mse: 0.0157 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.2911 - mae: 0.7086 - mse: 0.8222 - val_loss: 0.4845 - val_mae: 0.1090 - val_mse: 0.0155 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.0215 - mae: 0.6571 - mse: 0.5526 - val_loss: 0.4842 - val_mae: 0.1079 - val_mse: 0.0153 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 1.3474 - mae: 0.7928 - mse: 0.8785 - val_loss: 0.4841 - val_mae: 0.1074 - val_mse: 0.0152 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 1.6376 - mae: 0.7582 - mse: 1.1688 - val_loss: 0.4840 - val_mae: 0.1074 - val_mse: 0.0152 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.9276 - mae: 0.5502 - mse: 0.4588 - val_loss: 0.4835 - val_mae: 0.1048 - val_mse: 0.0147 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 1.5098 - mae: 0.7796 - mse: 1.0410 - val_loss: 0.4832 - val_mae: 0.1035 - val_mse: 0.0144 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.5549 - mae: 0.9089 - mse: 1.0861 - val_loss: 0.4827 - val_mae: 0.1016 - val_mse: 0.0140 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 1.1683 - mae: 0.5920 - mse: 0.6995 - val_loss: 0.4826 - val_mae: 0.1011 - val_mse: 0.0139 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 1.6423 - mae: 1.0380 - mse: 1.1736 - val_loss: 0.4822 - val_mae: 0.0995 - val_mse: 0.0136 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.7302 - mae: 0.4014 - mse: 0.2615 - val_loss: 0.4820 - val_mae: 0.0985 - val_mse: 0.0134 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.6556 - mae: 0.3481 - mse: 0.1869 - val_loss: 0.4817 - val_mae: 0.0969 - val_mse: 0.0130 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.7700 - mae: 0.4005 - mse: 0.3014 - val_loss: 0.4814 - val_mae: 0.0958 - val_mse: 0.0128 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 1.1720 - mae: 0.6296 - mse: 0.7034 - val_loss: 0.4810 - val_mae: 0.0940 - val_mse: 0.0125 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.7807 - mae: 0.4560 - mse: 0.3121 - val_loss: 0.4810 - val_mae: 0.0939 - val_mse: 0.0125 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.1442 - mae: 1.0944 - mse: 1.6756 - val_loss: 0.4807 - val_mae: 0.0925 - val_mse: 0.0122 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.9693 - mae: 1.1207 - mse: 1.5008 - val_loss: 0.4805 - val_mae: 0.0915 - val_mse: 0.0120 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 1.2876 - mae: 0.8008 - mse: 0.8191 - val_loss: 0.4803 - val_mae: 0.0906 - val_mse: 0.0118 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 0.8250 - mae: 0.5552 - mse: 0.3566 - val_loss: 0.4801 - val_mae: 0.0897 - val_mse: 0.0117 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.8792 - mae: 0.5352 - mse: 0.4108 - val_loss: 0.4798 - val_mae: 0.0884 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.6445 - mae: 0.8779 - mse: 1.1761 - val_loss: 0.4798 - val_mae: 0.0886 - val_mse: 0.0115 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1.0636 - mae: 0.6722 - mse: 0.5953 - val_loss: 0.4795 - val_mae: 0.0871 - val_mse: 0.0112 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.1240 - mae: 0.7275 - mse: 0.6557 - val_loss: 0.4795 - val_mae: 0.0871 - val_mse: 0.0112 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.0325 - mae: 0.7020 - mse: 0.5643 - val_loss: 0.4792 - val_mae: 0.0856 - val_mse: 0.0109 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 0.9262 - mae: 0.5938 - mse: 0.4580 - val_loss: 0.4794 - val_mae: 0.0869 - val_mse: 0.0112 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.8252 - mae: 0.5771 - mse: 0.3571 - val_loss: 0.4792 - val_mae: 0.0861 - val_mse: 0.0110 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.8228 - mae: 0.5169 - mse: 0.3547 - val_loss: 0.4791 - val_mae: 0.0858 - val_mse: 0.0110 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 1.0262 - mae: 0.6282 - mse: 0.5581 - val_loss: 0.4789 - val_mae: 0.0850 - val_mse: 0.0108 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.0083 - mae: 0.6258 - mse: 0.5402 - val_loss: 0.4789 - val_mae: 0.0852 - val_mse: 0.0109 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.7117 - mae: 0.7731 - mse: 1.2437 - val_loss: 0.4788 - val_mae: 0.0848 - val_mse: 0.0108 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1.1163 - mae: 0.7225 - mse: 0.6483 - val_loss: 0.4785 - val_mae: 0.0831 - val_mse: 0.0105 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - loss: 0.7359 - mae: 0.4901 - mse: 0.2679 - val_loss: 0.4782 - val_mae: 0.0815 - val_mse: 0.0103 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 1.4418 - mae: 0.8464 - mse: 0.9739 - val_loss: 0.4782 - val_mae: 0.0815 - val_mse: 0.0103 - learning_rate: 5.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.0449 - mae: 0.6852 - mse: 0.5770 - val_loss: 0.4781 - val_mae: 0.0814 - val_mse: 0.0103 - learning_rate: 5.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.3782 - mae: 0.8892 - mse: 0.9104 - val_loss: 0.4778 - val_mae: 0.0804 - val_mse: 0.0100 - learning_rate: 5.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.0213 - mae: 0.6756 - mse: 0.5535 - val_loss: 0.4776 - val_mae: 0.0797 - val_mse: 0.0098 - learning_rate: 5.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 1.6428 - mae: 0.7284 - mse: 1.1750 - val_loss: 0.4773 - val_mae: 0.0786 - val_mse: 0.0095 - learning_rate: 5.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.9624 - mae: 0.6103 - mse: 0.4947 - val_loss: 0.4774 - val_mae: 0.0791 - val_mse: 0.0097 - learning_rate: 5.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.9259 - mae: 0.6518 - mse: 0.4582 - val_loss: 0.4773 - val_mae: 0.0788 - val_mse: 0.0096 - learning_rate: 5.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 1.1696 - mae: 0.6352 - mse: 0.7019 - val_loss: 0.4770 - val_mae: 0.0777 - val_mse: 0.0093 - learning_rate: 5.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - loss: 0.8363 - mae: 0.5027 - mse: 0.3687 - val_loss: 0.4769 - val_mae: 0.0777 - val_mse: 0.0093 - learning_rate: 5.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 1.1148 - mae: 0.6846 - mse: 0.6472 - val_loss: 0.4769 - val_mae: 0.0776 - val_mse: 0.0093 - learning_rate: 5.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.2277 - mae: 0.6899 - mse: 0.7601 - val_loss: 0.4768 - val_mae: 0.0774 - val_mse: 0.0092 - learning_rate: 5.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 1.2391 - mae: 0.8412 - mse: 0.7716 - val_loss: 0.4767 - val_mae: 0.0772 - val_mse: 0.0092 - learning_rate: 5.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 0.6406 - mae: 0.3592 - mse: 0.1730 - val_loss: 0.4766 - val_mae: 0.0770 - val_mse: 0.0091 - learning_rate: 5.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.5141 - mae: 0.1740 - mse: 0.0466 - val_loss: 0.4768 - val_mae: 0.0777 - val_mse: 0.0093 - learning_rate: 5.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 1.4750 - mae: 0.5207 - mse: 1.0075 - val_loss: 0.4767 - val_mae: 0.0776 - val_mse: 0.0093 - learning_rate: 5.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 0.8067 - mae: 0.5478 - mse: 0.3393 - val_loss: 0.4764 - val_mae: 0.0765 - val_mse: 0.0090 - learning_rate: 5.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.6621 - mae: 0.4050 - mse: 0.1947 - val_loss: 0.4765 - val_mae: 0.0774 - val_mse: 0.0092 - learning_rate: 5.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 1.4475 - mae: 0.8452 - mse: 0.9802 - val_loss: 0.4766 - val_mae: 0.0777 - val_mse: 0.0093 - learning_rate: 5.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.0204 - mae: 0.5185 - mse: 0.5531 - val_loss: 0.4762 - val_mae: 0.0762 - val_mse: 0.0089 - learning_rate: 5.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.5745 - mae: 0.2534 - mse: 0.1072 - val_loss: 0.4760 - val_mae: 0.0756 - val_mse: 0.0088 - learning_rate: 5.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.7634 - mae: 0.3948 - mse: 0.2961 - val_loss: 0.4761 - val_mae: 0.0759 - val_mse: 0.0089 - learning_rate: 5.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 1.7076 - mae: 0.9227 - mse: 1.2404 - val_loss: 0.4762 - val_mae: 0.0763 - val_mse: 0.0090 - learning_rate: 5.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.8065 - mae: 0.5057 - mse: 0.3393 - val_loss: 0.4762 - val_mae: 0.0764 - val_mse: 0.0090 - learning_rate: 5.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 0.7445 - mae: 0.3765 - mse: 0.2774 - val_loss: 0.4763 - val_mae: 0.0770 - val_mse: 0.0092 - learning_rate: 5.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.6982 - mae: 0.4424 - mse: 0.2311 - val_loss: 0.4764 - val_mae: 0.0775 - val_mse: 0.0093 - learning_rate: 5.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.6532 - mae: 0.3389 - mse: 0.1861 - val_loss: 0.4764 - val_mae: 0.0778 - val_mse: 0.0094 - learning_rate: 1.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.9520 - mae: 0.5359 - mse: 0.4850 - val_loss: 0.4762 - val_mae: 0.0768 - val_mse: 0.0091 - learning_rate: 1.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 0.7933 - mae: 0.4705 - mse: 0.3263 - val_loss: 0.4763 - val_mae: 0.0774 - val_mse: 0.0093 - learning_rate: 1.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.7420 - mae: 0.3998 - mse: 0.2749 - val_loss: 0.4763 - val_mae: 0.0773 - val_mse: 0.0092 - learning_rate: 1.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.4479 - mae: 0.8489 - mse: 0.9808 - val_loss: 0.4761 - val_mae: 0.0766 - val_mse: 0.0091 - learning_rate: 1.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 1.1486 - mae: 0.6929 - mse: 0.6815 - val_loss: 0.4762 - val_mae: 0.0769 - val_mse: 0.0091 - learning_rate: 2.0000e-05\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.7440 - mae: 0.4148 - mse: 0.2770 - val_loss: 0.4760 - val_mae: 0.0762 - val_mse: 0.0089 - learning_rate: 2.0000e-05\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.1425 - mae: 0.6724 - mse: 0.6755 - val_loss: 0.4757 - val_mae: 0.0751 - val_mse: 0.0086 - learning_rate: 2.0000e-05\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.5702 - mae: 0.2823 - mse: 0.1031 - val_loss: 0.4755 - val_mae: 0.0745 - val_mse: 0.0085 - learning_rate: 2.0000e-05\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 0.9760 - mae: 0.6166 - mse: 0.5090 - val_loss: 0.4759 - val_mae: 0.0761 - val_mse: 0.0089 - learning_rate: 2.0000e-05\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.4787 - mae: 0.7985 - mse: 1.0116 - val_loss: 0.4761 - val_mae: 0.0770 - val_mse: 0.0091 - learning_rate: 2.0000e-05\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.7240 - mae: 0.4034 - mse: 0.2569 - val_loss: 0.4765 - val_mae: 0.0785 - val_mse: 0.0095 - learning_rate: 2.0000e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.5572 - mae: 0.7594 - mse: 1.0901 - val_loss: 0.4764 - val_mae: 0.0783 - val_mse: 0.0094 - learning_rate: 2.0000e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 1.1085 - mae: 0.6460 - mse: 0.6414 - val_loss: 0.4765 - val_mae: 0.0790 - val_mse: 0.0095 - learning_rate: 2.0000e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.6781 - mae: 0.3533 - mse: 0.2111 - val_loss: 0.4769 - val_mae: 0.0806 - val_mse: 0.0099 - learning_rate: 1.0000e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 1.2443 - mae: 0.7606 - mse: 0.7773 - val_loss: 0.4769 - val_mae: 0.0804 - val_mse: 0.0099 - learning_rate: 1.0000e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 0.9555 - mae: 0.5986 - mse: 0.4884 - val_loss: 0.4769 - val_mae: 0.0805 - val_mse: 0.0099 - learning_rate: 1.0000e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.2890 - mae: 0.7424 - mse: 0.8220 - val_loss: 0.4766 - val_mae: 0.0794 - val_mse: 0.0096 - learning_rate: 1.0000e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - loss: 0.8596 - mae: 0.5504 - mse: 0.3926 - val_loss: 0.4767 - val_mae: 0.0798 - val_mse: 0.0097 - learning_rate: 1.0000e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 1.1237 - mae: 0.6326 - mse: 0.6567 - val_loss: 0.4764 - val_mae: 0.0785 - val_mse: 0.0094 - learning_rate: 1.0000e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 0.7506 - mae: 0.3077 - mse: 0.2835 - val_loss: 0.4763 - val_mae: 0.0781 - val_mse: 0.0093 - learning_rate: 1.0000e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.2010 - mae: 0.6435 - mse: 0.7340 - val_loss: 0.4762 - val_mae: 0.0774 - val_mse: 0.0091 - learning_rate: 1.0000e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.6170 - mae: 0.3602 - mse: 0.1499 - val_loss: 0.4762 - val_mae: 0.0778 - val_mse: 0.0092 - learning_rate: 1.0000e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 1.8063 - mae: 0.9601 - mse: 1.3393 - val_loss: 0.4763 - val_mae: 0.0781 - val_mse: 0.0093 - learning_rate: 1.0000e-05\n",
            "Grupo 70 - RMSE: 0.001106, MAE: 0.000894, sMAPE: 2.64%\n",
            "\n",
            "Treinando modelo para grupo etário 75...\n",
            "Grupo 75: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - loss: 2.0992 - mae: 1.0595 - mse: 1.6284 - val_loss: 0.5143 - val_mae: 0.2010 - val_mse: 0.0439 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.8332 - mae: 0.9722 - mse: 1.3628 - val_loss: 0.5129 - val_mae: 0.1981 - val_mse: 0.0427 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 4.4865 - mae: 1.6252 - mse: 4.0163 - val_loss: 0.5126 - val_mae: 0.1978 - val_mse: 0.0426 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 1.4508 - mae: 0.7968 - mse: 0.9807 - val_loss: 0.5129 - val_mae: 0.1987 - val_mse: 0.0429 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 2.1516 - mae: 1.0065 - mse: 1.6816 - val_loss: 0.5119 - val_mae: 0.1965 - val_mse: 0.0421 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 1.5793 - mae: 0.9435 - mse: 1.1094 - val_loss: 0.5115 - val_mae: 0.1959 - val_mse: 0.0417 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1.2839 - mae: 0.6979 - mse: 0.8141 - val_loss: 0.5116 - val_mae: 0.1964 - val_mse: 0.0419 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.4940 - mae: 0.8203 - mse: 1.0244 - val_loss: 0.5114 - val_mae: 0.1961 - val_mse: 0.0418 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.6080 - mae: 0.2405 - mse: 0.1385 - val_loss: 0.5117 - val_mae: 0.1972 - val_mse: 0.0423 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.8149 - mae: 0.5231 - mse: 0.3454 - val_loss: 0.5117 - val_mae: 0.1973 - val_mse: 0.0423 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 2.2161 - mae: 1.0238 - mse: 1.7468 - val_loss: 0.5114 - val_mae: 0.1970 - val_mse: 0.0422 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.7216 - mae: 0.4107 - mse: 0.2523 - val_loss: 0.5122 - val_mae: 0.1991 - val_mse: 0.0430 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 1.8963 - mae: 0.8586 - mse: 1.4271 - val_loss: 0.5127 - val_mae: 0.2005 - val_mse: 0.0435 - learning_rate: 1.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.2423 - mae: 0.7348 - mse: 0.7731 - val_loss: 0.5129 - val_mae: 0.2009 - val_mse: 0.0437 - learning_rate: 1.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - loss: 2.4880 - mae: 1.2248 - mse: 2.0188 - val_loss: 0.5135 - val_mae: 0.2023 - val_mse: 0.0443 - learning_rate: 1.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 1.8201 - mae: 1.0035 - mse: 1.3509 - val_loss: 0.5138 - val_mae: 0.2030 - val_mse: 0.0447 - learning_rate: 1.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 1.2338 - mae: 0.7747 - mse: 0.7646 - val_loss: 0.5146 - val_mae: 0.2050 - val_mse: 0.0455 - learning_rate: 2.0000e-05\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 1.4300 - mae: 0.8563 - mse: 0.9609 - val_loss: 0.5155 - val_mae: 0.2068 - val_mse: 0.0464 - learning_rate: 2.0000e-05\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 1.2576 - mae: 0.7714 - mse: 0.7884 - val_loss: 0.5162 - val_mae: 0.2086 - val_mse: 0.0471 - learning_rate: 2.0000e-05\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.5940 - mae: 0.3105 - mse: 0.1249 - val_loss: 0.5169 - val_mae: 0.2101 - val_mse: 0.0478 - learning_rate: 2.0000e-05\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 1.0213 - mae: 0.6642 - mse: 0.5522 - val_loss: 0.5176 - val_mae: 0.2118 - val_mse: 0.0485 - learning_rate: 2.0000e-05\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 1.3166 - mae: 0.8955 - mse: 0.8475 - val_loss: 0.5177 - val_mae: 0.2119 - val_mse: 0.0486 - learning_rate: 1.0000e-05\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.6307 - mae: 0.9372 - mse: 1.1616 - val_loss: 0.5182 - val_mae: 0.2131 - val_mse: 0.0491 - learning_rate: 1.0000e-05\n",
            "Grupo 75 - RMSE: 0.003125, MAE: 0.002997, sMAPE: 5.80%\n",
            "\n",
            "Treinando modelo para grupo etário 80...\n",
            "Grupo 80: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 7.0166 - mae: 2.2688 - mse: 6.5467 - val_loss: 0.5215 - val_mae: 0.2224 - val_mse: 0.0522 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - loss: 5.8550 - mae: 2.1225 - mse: 5.3857 - val_loss: 0.5190 - val_mae: 0.2169 - val_mse: 0.0498 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 10.2853 - mae: 2.5952 - mse: 9.8161 - val_loss: 0.5171 - val_mae: 0.2129 - val_mse: 0.0480 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 4.0368 - mae: 1.4128 - mse: 3.5677 - val_loss: 0.5151 - val_mae: 0.2084 - val_mse: 0.0461 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - loss: 4.3922 - mae: 1.9746 - mse: 3.9232 - val_loss: 0.5138 - val_mae: 0.2055 - val_mse: 0.0448 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 3.4827 - mae: 1.4469 - mse: 3.0137 - val_loss: 0.5130 - val_mae: 0.2037 - val_mse: 0.0440 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - loss: 3.7020 - mae: 1.5770 - mse: 3.2330 - val_loss: 0.5121 - val_mae: 0.2018 - val_mse: 0.0433 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 5.3867 - mae: 1.7887 - mse: 4.9178 - val_loss: 0.5113 - val_mae: 0.1998 - val_mse: 0.0425 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 5.1605 - mae: 2.0204 - mse: 4.6917 - val_loss: 0.5107 - val_mae: 0.1983 - val_mse: 0.0419 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 6.0866 - mae: 1.9990 - mse: 5.6177 - val_loss: 0.5096 - val_mae: 0.1957 - val_mse: 0.0408 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 5.5347 - mae: 1.9303 - mse: 5.0658 - val_loss: 0.5091 - val_mae: 0.1944 - val_mse: 0.0403 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - loss: 5.6925 - mae: 2.1374 - mse: 5.2237 - val_loss: 0.5080 - val_mae: 0.1918 - val_mse: 0.0393 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 3.7085 - mae: 1.4097 - mse: 3.2398 - val_loss: 0.5079 - val_mae: 0.1914 - val_mse: 0.0391 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 8.7172 - mae: 2.4403 - mse: 8.2485 - val_loss: 0.5068 - val_mae: 0.1886 - val_mse: 0.0381 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 7.3765 - mae: 2.4815 - mse: 6.9078 - val_loss: 0.5057 - val_mae: 0.1859 - val_mse: 0.0370 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 5.3857 - mae: 1.8811 - mse: 4.9170 - val_loss: 0.5039 - val_mae: 0.1810 - val_mse: 0.0352 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 3.3835 - mae: 1.6339 - mse: 2.9148 - val_loss: 0.5035 - val_mae: 0.1800 - val_mse: 0.0348 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - loss: 4.6622 - mae: 1.5329 - mse: 4.1936 - val_loss: 0.5022 - val_mae: 0.1763 - val_mse: 0.0336 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 2.4749 - mae: 1.1703 - mse: 2.0063 - val_loss: 0.5011 - val_mae: 0.1732 - val_mse: 0.0324 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 8.3581 - mae: 2.3633 - mse: 7.8895 - val_loss: 0.5006 - val_mae: 0.1720 - val_mse: 0.0320 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.6319 - mae: 1.7660 - mse: 4.1632 - val_loss: 0.5000 - val_mae: 0.1701 - val_mse: 0.0314 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 4.3896 - mae: 1.6362 - mse: 3.9211 - val_loss: 0.4982 - val_mae: 0.1649 - val_mse: 0.0296 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 3.9740 - mae: 1.7098 - mse: 3.5054 - val_loss: 0.4971 - val_mae: 0.1615 - val_mse: 0.0285 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 3.7105 - mae: 1.4462 - mse: 3.2419 - val_loss: 0.4963 - val_mae: 0.1592 - val_mse: 0.0278 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 3.4443 - mae: 1.5554 - mse: 2.9757 - val_loss: 0.4957 - val_mae: 0.1574 - val_mse: 0.0272 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 2.9921 - mae: 1.2387 - mse: 2.5236 - val_loss: 0.4950 - val_mae: 0.1553 - val_mse: 0.0265 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.4946 - mae: 0.8387 - mse: 1.0261 - val_loss: 0.4944 - val_mae: 0.1534 - val_mse: 0.0259 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 4.8767 - mae: 1.8212 - mse: 4.4082 - val_loss: 0.4933 - val_mae: 0.1499 - val_mse: 0.0249 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 7.2126 - mae: 2.3203 - mse: 6.7441 - val_loss: 0.4924 - val_mae: 0.1469 - val_mse: 0.0240 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 2.9225 - mae: 1.2295 - mse: 2.4540 - val_loss: 0.4921 - val_mae: 0.1457 - val_mse: 0.0236 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 4.2370 - mae: 1.8608 - mse: 3.7686 - val_loss: 0.4913 - val_mae: 0.1432 - val_mse: 0.0229 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 5.2297 - mae: 1.7580 - mse: 4.7612 - val_loss: 0.4911 - val_mae: 0.1425 - val_mse: 0.0227 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 4.3750 - mae: 1.8510 - mse: 3.9066 - val_loss: 0.4907 - val_mae: 0.1412 - val_mse: 0.0223 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 4.6084 - mae: 1.8898 - mse: 4.1400 - val_loss: 0.4904 - val_mae: 0.1404 - val_mse: 0.0221 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.7243 - mae: 0.8222 - mse: 1.2560 - val_loss: 0.4901 - val_mae: 0.1394 - val_mse: 0.0218 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 2.0225 - mae: 1.1766 - mse: 1.5542 - val_loss: 0.4890 - val_mae: 0.1354 - val_mse: 0.0207 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 4.9163 - mae: 1.9774 - mse: 4.4480 - val_loss: 0.4888 - val_mae: 0.1347 - val_mse: 0.0205 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - loss: 2.7229 - mae: 1.2087 - mse: 2.2546 - val_loss: 0.4884 - val_mae: 0.1332 - val_mse: 0.0201 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 2.7157 - mae: 1.3431 - mse: 2.2474 - val_loss: 0.4879 - val_mae: 0.1316 - val_mse: 0.0196 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 3.2705 - mae: 1.5556 - mse: 2.8022 - val_loss: 0.4868 - val_mae: 0.1275 - val_mse: 0.0185 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 3.5473 - mae: 1.7010 - mse: 3.0791 - val_loss: 0.4858 - val_mae: 0.1237 - val_mse: 0.0176 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 4.9561 - mae: 1.2210 - mse: 4.4878 - val_loss: 0.4859 - val_mae: 0.1242 - val_mse: 0.0177 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - loss: 3.3688 - mae: 1.6737 - mse: 2.9006 - val_loss: 0.4854 - val_mae: 0.1224 - val_mse: 0.0172 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 3.1342 - mae: 1.3709 - mse: 2.6660 - val_loss: 0.4855 - val_mae: 0.1227 - val_mse: 0.0173 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 4.6113 - mae: 1.8140 - mse: 4.1431 - val_loss: 0.4847 - val_mae: 0.1196 - val_mse: 0.0166 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 3.0899 - mae: 1.4820 - mse: 2.6218 - val_loss: 0.4843 - val_mae: 0.1177 - val_mse: 0.0161 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.2984 - mae: 1.1310 - mse: 1.8303 - val_loss: 0.4836 - val_mae: 0.1148 - val_mse: 0.0154 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 2.5390 - mae: 1.3343 - mse: 2.0708 - val_loss: 0.4835 - val_mae: 0.1146 - val_mse: 0.0154 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 2.7485 - mae: 1.2855 - mse: 2.2803 - val_loss: 0.4832 - val_mae: 0.1134 - val_mse: 0.0151 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 2.7536 - mae: 1.3345 - mse: 2.2855 - val_loss: 0.4825 - val_mae: 0.1103 - val_mse: 0.0145 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 3.6472 - mae: 1.5233 - mse: 3.1791 - val_loss: 0.4821 - val_mae: 0.1083 - val_mse: 0.0140 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 2.2720 - mae: 1.1135 - mse: 1.8039 - val_loss: 0.4813 - val_mae: 0.1045 - val_mse: 0.0132 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 4.4407 - mae: 1.7008 - mse: 3.9726 - val_loss: 0.4804 - val_mae: 0.1004 - val_mse: 0.0124 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 2.7893 - mae: 1.2450 - mse: 2.3213 - val_loss: 0.4800 - val_mae: 0.0984 - val_mse: 0.0120 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 2.2758 - mae: 1.0739 - mse: 1.8079 - val_loss: 0.4797 - val_mae: 0.0968 - val_mse: 0.0117 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.9043 - mae: 0.9057 - mse: 1.4364 - val_loss: 0.4793 - val_mae: 0.0950 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.8829 - mae: 1.0763 - mse: 1.4150 - val_loss: 0.4792 - val_mae: 0.0943 - val_mse: 0.0112 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 2.9335 - mae: 1.2231 - mse: 2.4656 - val_loss: 0.4789 - val_mae: 0.0928 - val_mse: 0.0109 - learning_rate: 5.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.9957 - mae: 1.1944 - mse: 2.5278 - val_loss: 0.4784 - val_mae: 0.0903 - val_mse: 0.0105 - learning_rate: 5.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 3.7985 - mae: 1.4187 - mse: 3.3306 - val_loss: 0.4779 - val_mae: 0.0875 - val_mse: 0.0100 - learning_rate: 5.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 1.9122 - mae: 0.9713 - mse: 1.4443 - val_loss: 0.4773 - val_mae: 0.0844 - val_mse: 0.0095 - learning_rate: 5.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 3.4847 - mae: 1.5764 - mse: 3.0168 - val_loss: 0.4771 - val_mae: 0.0830 - val_mse: 0.0092 - learning_rate: 5.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 2.1234 - mae: 1.1742 - mse: 1.6556 - val_loss: 0.4767 - val_mae: 0.0810 - val_mse: 0.0089 - learning_rate: 5.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.9904 - mae: 1.4165 - mse: 2.5226 - val_loss: 0.4767 - val_mae: 0.0808 - val_mse: 0.0089 - learning_rate: 5.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 2.7909 - mae: 1.2990 - mse: 2.3231 - val_loss: 0.4765 - val_mae: 0.0797 - val_mse: 0.0087 - learning_rate: 5.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.3442 - mae: 1.1653 - mse: 1.8764 - val_loss: 0.4762 - val_mae: 0.0783 - val_mse: 0.0085 - learning_rate: 5.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 2.7189 - mae: 1.3017 - mse: 2.2511 - val_loss: 0.4761 - val_mae: 0.0774 - val_mse: 0.0084 - learning_rate: 5.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 3.3927 - mae: 1.2640 - mse: 2.9249 - val_loss: 0.4757 - val_mae: 0.0747 - val_mse: 0.0079 - learning_rate: 5.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 3.4191 - mae: 1.4379 - mse: 2.9513 - val_loss: 0.4755 - val_mae: 0.0740 - val_mse: 0.0078 - learning_rate: 5.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 2.7034 - mae: 1.3489 - mse: 2.2357 - val_loss: 0.4752 - val_mae: 0.0718 - val_mse: 0.0075 - learning_rate: 5.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 1.4278 - mae: 0.7435 - mse: 0.9601 - val_loss: 0.4752 - val_mae: 0.0718 - val_mse: 0.0075 - learning_rate: 5.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 2.7507 - mae: 1.4930 - mse: 2.2830 - val_loss: 0.4749 - val_mae: 0.0702 - val_mse: 0.0073 - learning_rate: 5.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 2.6803 - mae: 1.2045 - mse: 2.2126 - val_loss: 0.4748 - val_mae: 0.0694 - val_mse: 0.0072 - learning_rate: 5.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 3.8257 - mae: 1.6284 - mse: 3.3580 - val_loss: 0.4745 - val_mae: 0.0673 - val_mse: 0.0069 - learning_rate: 5.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.8955 - mae: 0.9610 - mse: 1.4279 - val_loss: 0.4743 - val_mae: 0.0661 - val_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1.7385 - mae: 1.0818 - mse: 1.2709 - val_loss: 0.4742 - val_mae: 0.0654 - val_mse: 0.0066 - learning_rate: 5.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.6155 - mae: 0.8661 - mse: 1.1479 - val_loss: 0.4740 - val_mae: 0.0648 - val_mse: 0.0065 - learning_rate: 5.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 3.3194 - mae: 1.4648 - mse: 2.8518 - val_loss: 0.4740 - val_mae: 0.0645 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 2.2511 - mae: 1.0200 - mse: 1.7835 - val_loss: 0.4739 - val_mae: 0.0645 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 2.6071 - mae: 1.3306 - mse: 2.1396 - val_loss: 0.4738 - val_mae: 0.0639 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 4.0297 - mae: 1.7828 - mse: 3.5621 - val_loss: 0.4738 - val_mae: 0.0640 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1.9496 - mae: 0.9980 - mse: 1.4821 - val_loss: 0.4733 - val_mae: 0.0616 - val_mse: 0.0058 - learning_rate: 5.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 2.1462 - mae: 1.0201 - mse: 1.6787 - val_loss: 0.4732 - val_mae: 0.0610 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 3.0931 - mae: 1.4578 - mse: 2.6257 - val_loss: 0.4731 - val_mae: 0.0607 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.5846 - mae: 0.8201 - mse: 1.1171 - val_loss: 0.4728 - val_mae: 0.0594 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - loss: 2.6903 - mae: 1.4638 - mse: 2.2229 - val_loss: 0.4726 - val_mae: 0.0585 - val_mse: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 2.3193 - mae: 1.3154 - mse: 1.8519 - val_loss: 0.4725 - val_mae: 0.0576 - val_mse: 0.0051 - learning_rate: 5.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.6922 - mae: 0.8932 - mse: 1.2248 - val_loss: 0.4724 - val_mae: 0.0573 - val_mse: 0.0050 - learning_rate: 5.0000e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 1.8104 - mae: 1.1101 - mse: 1.3430 - val_loss: 0.4724 - val_mae: 0.0575 - val_mse: 0.0051 - learning_rate: 5.0000e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.9069 - mae: 0.5696 - mse: 0.4395 - val_loss: 0.4725 - val_mae: 0.0578 - val_mse: 0.0051 - learning_rate: 5.0000e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 1.1709 - mae: 0.6996 - mse: 0.7035 - val_loss: 0.4726 - val_mae: 0.0584 - val_mse: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 1.6136 - mae: 0.8787 - mse: 1.1462 - val_loss: 0.4724 - val_mae: 0.0574 - val_mse: 0.0050 - learning_rate: 5.0000e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - loss: 1.2639 - mae: 0.7184 - mse: 0.7966 - val_loss: 0.4727 - val_mae: 0.0590 - val_mse: 0.0053 - learning_rate: 1.0000e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - loss: 1.7694 - mae: 0.9865 - mse: 1.3020 - val_loss: 0.4727 - val_mae: 0.0592 - val_mse: 0.0054 - learning_rate: 1.0000e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 1.5055 - mae: 0.8645 - mse: 1.0381 - val_loss: 0.4725 - val_mae: 0.0581 - val_mse: 0.0052 - learning_rate: 1.0000e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 1.0318 - mae: 0.6745 - mse: 0.5644 - val_loss: 0.4729 - val_mae: 0.0601 - val_mse: 0.0056 - learning_rate: 1.0000e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 1.7999 - mae: 1.0626 - mse: 1.3326 - val_loss: 0.4733 - val_mae: 0.0631 - val_mse: 0.0059 - learning_rate: 1.0000e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 2.0978 - mae: 1.1158 - mse: 1.6305 - val_loss: 0.4735 - val_mae: 0.0648 - val_mse: 0.0061 - learning_rate: 2.0000e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - loss: 2.5756 - mae: 1.3762 - mse: 2.1083 - val_loss: 0.4736 - val_mae: 0.0657 - val_mse: 0.0063 - learning_rate: 2.0000e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.8991 - mae: 0.5431 - mse: 0.4318 - val_loss: 0.4737 - val_mae: 0.0671 - val_mse: 0.0064 - learning_rate: 2.0000e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 2.4009 - mae: 1.0364 - mse: 1.9336 - val_loss: 0.4740 - val_mae: 0.0691 - val_mse: 0.0066 - learning_rate: 2.0000e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 3.5843 - mae: 1.4371 - mse: 3.1170 - val_loss: 0.4740 - val_mae: 0.0695 - val_mse: 0.0067 - learning_rate: 2.0000e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.5607 - mae: 1.0106 - mse: 1.0933 - val_loss: 0.4743 - val_mae: 0.0711 - val_mse: 0.0069 - learning_rate: 1.0000e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1.4463 - mae: 0.7785 - mse: 0.9790 - val_loss: 0.4743 - val_mae: 0.0717 - val_mse: 0.0070 - learning_rate: 1.0000e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.3051 - mae: 0.8107 - mse: 0.8378 - val_loss: 0.4746 - val_mae: 0.0737 - val_mse: 0.0073 - learning_rate: 1.0000e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 3.0342 - mae: 1.3485 - mse: 2.5669 - val_loss: 0.4749 - val_mae: 0.0757 - val_mse: 0.0076 - learning_rate: 1.0000e-05\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 1.1664 - mae: 0.7204 - mse: 0.6991 - val_loss: 0.4757 - val_mae: 0.0806 - val_mse: 0.0084 - learning_rate: 1.0000e-05\n",
            "Grupo 80 - RMSE: 0.001466, MAE: 0.001185, sMAPE: 1.42%\n",
            "\n",
            "Treinando modelo para grupo etário 85...\n",
            "Grupo 85: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - loss: 3.8554 - mae: 1.3956 - mse: 3.3841 - val_loss: 0.4990 - val_mae: 0.1489 - val_mse: 0.0282 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 2.3414 - mae: 0.9015 - mse: 1.8706 - val_loss: 0.4972 - val_mae: 0.1433 - val_mse: 0.0265 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 2.5458 - mae: 1.2578 - mse: 2.0752 - val_loss: 0.4961 - val_mae: 0.1397 - val_mse: 0.0255 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 1.0198 - mae: 0.6117 - mse: 0.5492 - val_loss: 0.4952 - val_mae: 0.1369 - val_mse: 0.0247 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 2.0347 - mae: 0.9180 - mse: 1.5642 - val_loss: 0.4945 - val_mae: 0.1347 - val_mse: 0.0241 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.9218 - mae: 0.6307 - mse: 0.4515 - val_loss: 0.4932 - val_mae: 0.1301 - val_mse: 0.0229 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 3.5230 - mae: 1.5211 - mse: 3.0527 - val_loss: 0.4923 - val_mae: 0.1269 - val_mse: 0.0220 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.8071 - mae: 0.4144 - mse: 0.3369 - val_loss: 0.4916 - val_mae: 0.1248 - val_mse: 0.0215 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.0225 - mae: 0.5861 - mse: 0.5524 - val_loss: 0.4907 - val_mae: 0.1213 - val_mse: 0.0206 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 1.6999 - mae: 0.8194 - mse: 1.2299 - val_loss: 0.4900 - val_mae: 0.1190 - val_mse: 0.0201 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 3.0588 - mae: 1.3931 - mse: 2.5889 - val_loss: 0.4893 - val_mae: 0.1163 - val_mse: 0.0194 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 3.3907 - mae: 1.3332 - mse: 2.9209 - val_loss: 0.4887 - val_mae: 0.1140 - val_mse: 0.0189 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 2.1508 - mae: 1.0817 - mse: 1.6810 - val_loss: 0.4881 - val_mae: 0.1116 - val_mse: 0.0184 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 1.4635 - mae: 0.7885 - mse: 0.9938 - val_loss: 0.4875 - val_mae: 0.1091 - val_mse: 0.0178 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.7965 - mae: 0.8125 - mse: 1.3268 - val_loss: 0.4868 - val_mae: 0.1060 - val_mse: 0.0172 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.5624 - mae: 0.9401 - mse: 1.0927 - val_loss: 0.4861 - val_mae: 0.1029 - val_mse: 0.0165 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 2.1202 - mae: 1.1144 - mse: 1.6506 - val_loss: 0.4854 - val_mae: 0.0996 - val_mse: 0.0158 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1.7572 - mae: 0.8574 - mse: 1.2876 - val_loss: 0.4849 - val_mae: 0.0975 - val_mse: 0.0154 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 1.0144 - mae: 0.5969 - mse: 0.5449 - val_loss: 0.4844 - val_mae: 0.0947 - val_mse: 0.0149 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 2.9513 - mae: 1.1778 - mse: 2.4818 - val_loss: 0.4837 - val_mae: 0.0915 - val_mse: 0.0143 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.9920 - mae: 0.8341 - mse: 1.5226 - val_loss: 0.4831 - val_mae: 0.0884 - val_mse: 0.0137 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 1.2857 - mae: 0.6838 - mse: 0.8164 - val_loss: 0.4825 - val_mae: 0.0862 - val_mse: 0.0132 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.1705 - mae: 0.6972 - mse: 0.7012 - val_loss: 0.4823 - val_mae: 0.0855 - val_mse: 0.0130 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - loss: 0.9254 - mae: 0.5873 - mse: 0.4562 - val_loss: 0.4819 - val_mae: 0.0841 - val_mse: 0.0127 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.2974 - mae: 0.6105 - mse: 0.8282 - val_loss: 0.4813 - val_mae: 0.0823 - val_mse: 0.0122 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.5542 - mae: 0.8727 - mse: 1.0850 - val_loss: 0.4810 - val_mae: 0.0813 - val_mse: 0.0119 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.6369 - mae: 0.9007 - mse: 1.1678 - val_loss: 0.4807 - val_mae: 0.0801 - val_mse: 0.0116 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.4114 - mae: 0.8026 - mse: 0.9424 - val_loss: 0.4804 - val_mae: 0.0793 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 2.2880 - mae: 1.0041 - mse: 1.8190 - val_loss: 0.4801 - val_mae: 0.0782 - val_mse: 0.0111 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 2.2013 - mae: 1.0845 - mse: 1.7323 - val_loss: 0.4796 - val_mae: 0.0762 - val_mse: 0.0107 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.5216 - mae: 0.8653 - mse: 1.0527 - val_loss: 0.4792 - val_mae: 0.0747 - val_mse: 0.0103 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1.2073 - mae: 0.6855 - mse: 0.7385 - val_loss: 0.4788 - val_mae: 0.0735 - val_mse: 0.0100 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.9626 - mae: 0.6155 - mse: 0.4938 - val_loss: 0.4783 - val_mae: 0.0728 - val_mse: 0.0096 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 1.3209 - mae: 0.8733 - mse: 0.8522 - val_loss: 0.4781 - val_mae: 0.0725 - val_mse: 0.0094 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.1562 - mae: 0.8005 - mse: 0.6876 - val_loss: 0.4777 - val_mae: 0.0719 - val_mse: 0.0090 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.7598 - mae: 0.4255 - mse: 0.2912 - val_loss: 0.4774 - val_mae: 0.0715 - val_mse: 0.0088 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 2.7029 - mae: 1.1408 - mse: 2.2343 - val_loss: 0.4771 - val_mae: 0.0711 - val_mse: 0.0086 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.8110 - mae: 1.1122 - mse: 1.3425 - val_loss: 0.4770 - val_mae: 0.0709 - val_mse: 0.0085 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.7492 - mae: 0.8284 - mse: 1.2807 - val_loss: 0.4769 - val_mae: 0.0708 - val_mse: 0.0085 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - loss: 0.8469 - mae: 0.5673 - mse: 0.3785 - val_loss: 0.4767 - val_mae: 0.0705 - val_mse: 0.0083 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.6918 - mae: 0.7587 - mse: 1.2234 - val_loss: 0.4765 - val_mae: 0.0703 - val_mse: 0.0082 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 1.2846 - mae: 0.8854 - mse: 0.8163 - val_loss: 0.4763 - val_mae: 0.0700 - val_mse: 0.0081 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.9620 - mae: 0.5430 - mse: 0.4937 - val_loss: 0.4763 - val_mae: 0.0700 - val_mse: 0.0081 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 0.5614 - mae: 0.2705 - mse: 0.0932 - val_loss: 0.4761 - val_mae: 0.0698 - val_mse: 0.0080 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.6990 - mae: 0.3488 - mse: 0.2308 - val_loss: 0.4759 - val_mae: 0.0693 - val_mse: 0.0078 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1.9875 - mae: 1.0157 - mse: 1.5194 - val_loss: 0.4757 - val_mae: 0.0691 - val_mse: 0.0077 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 1.1564 - mae: 0.7193 - mse: 0.6883 - val_loss: 0.4757 - val_mae: 0.0690 - val_mse: 0.0076 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 0.9422 - mae: 0.6064 - mse: 0.4742 - val_loss: 0.4755 - val_mae: 0.0688 - val_mse: 0.0076 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.8702 - mae: 0.5734 - mse: 0.4023 - val_loss: 0.4754 - val_mae: 0.0686 - val_mse: 0.0075 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 0.6841 - mae: 0.3493 - mse: 0.2161 - val_loss: 0.4752 - val_mae: 0.0684 - val_mse: 0.0074 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.3746 - mae: 0.8129 - mse: 0.9067 - val_loss: 0.4752 - val_mae: 0.0683 - val_mse: 0.0073 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.1714 - mae: 0.7287 - mse: 0.7036 - val_loss: 0.4750 - val_mae: 0.0680 - val_mse: 0.0072 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.0594 - mae: 0.6527 - mse: 0.5916 - val_loss: 0.4749 - val_mae: 0.0678 - val_mse: 0.0072 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 0.7145 - mae: 0.4599 - mse: 0.2467 - val_loss: 0.4748 - val_mae: 0.0677 - val_mse: 0.0071 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 1.7549 - mae: 0.9078 - mse: 1.2873 - val_loss: 0.4747 - val_mae: 0.0676 - val_mse: 0.0071 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 2.1737 - mae: 1.1272 - mse: 1.7061 - val_loss: 0.4746 - val_mae: 0.0673 - val_mse: 0.0070 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - loss: 0.9736 - mae: 0.6319 - mse: 0.5060 - val_loss: 0.4745 - val_mae: 0.0672 - val_mse: 0.0070 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.7798 - mae: 0.8871 - mse: 1.3123 - val_loss: 0.4745 - val_mae: 0.0671 - val_mse: 0.0070 - learning_rate: 5.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.9714 - mae: 0.6196 - mse: 0.5039 - val_loss: 0.4744 - val_mae: 0.0671 - val_mse: 0.0069 - learning_rate: 5.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - loss: 0.7756 - mae: 0.5351 - mse: 0.3081 - val_loss: 0.4742 - val_mae: 0.0667 - val_mse: 0.0068 - learning_rate: 5.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 1.9824 - mae: 1.0522 - mse: 1.5150 - val_loss: 0.4742 - val_mae: 0.0666 - val_mse: 0.0068 - learning_rate: 5.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 1.2369 - mae: 0.7854 - mse: 0.7696 - val_loss: 0.4740 - val_mae: 0.0661 - val_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.8251 - mae: 0.9352 - mse: 1.3578 - val_loss: 0.4740 - val_mae: 0.0663 - val_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step - loss: 1.0736 - mae: 0.7141 - mse: 0.6063 - val_loss: 0.4739 - val_mae: 0.0660 - val_mse: 0.0066 - learning_rate: 5.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 1.0803 - mae: 0.6255 - mse: 0.6130 - val_loss: 0.4738 - val_mae: 0.0658 - val_mse: 0.0066 - learning_rate: 5.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7568 - mae: 0.4318 - mse: 0.2895 - val_loss: 0.4737 - val_mae: 0.0657 - val_mse: 0.0065 - learning_rate: 5.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 1.4947 - mae: 0.6284 - mse: 1.0276 - val_loss: 0.4737 - val_mae: 0.0656 - val_mse: 0.0065 - learning_rate: 5.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.6930 - mae: 0.4073 - mse: 0.2259 - val_loss: 0.4735 - val_mae: 0.0657 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.3262 - mae: 0.7380 - mse: 0.8591 - val_loss: 0.4735 - val_mae: 0.0660 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - loss: 0.7181 - mae: 0.4636 - mse: 0.2510 - val_loss: 0.4734 - val_mae: 0.0662 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.3811 - mae: 0.7992 - mse: 0.9140 - val_loss: 0.4733 - val_mae: 0.0665 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.4946 - mae: 0.9542 - mse: 1.0276 - val_loss: 0.4732 - val_mae: 0.0670 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.8362 - mae: 0.5644 - mse: 0.3692 - val_loss: 0.4732 - val_mae: 0.0672 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.6432 - mae: 0.3971 - mse: 0.1762 - val_loss: 0.4731 - val_mae: 0.0674 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.6180 - mae: 0.3283 - mse: 0.1511 - val_loss: 0.4730 - val_mae: 0.0678 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 1.0680 - mae: 0.5878 - mse: 0.6012 - val_loss: 0.4730 - val_mae: 0.0680 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 0.5025 - mae: 0.1668 - mse: 0.0357 - val_loss: 0.4729 - val_mae: 0.0685 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.9332 - mae: 0.5395 - mse: 0.4665 - val_loss: 0.4728 - val_mae: 0.0690 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.4381 - mae: 0.9230 - mse: 0.9714 - val_loss: 0.4727 - val_mae: 0.0694 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 1.2313 - mae: 0.8403 - mse: 0.7647 - val_loss: 0.4726 - val_mae: 0.0698 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 0.8155 - mae: 0.4093 - mse: 0.3489 - val_loss: 0.4726 - val_mae: 0.0699 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - loss: 0.8800 - mae: 0.4107 - mse: 0.4134 - val_loss: 0.4726 - val_mae: 0.0704 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 0.6312 - mae: 0.3077 - mse: 0.1646 - val_loss: 0.4725 - val_mae: 0.0705 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.1336 - mae: 0.6827 - mse: 0.6671 - val_loss: 0.4725 - val_mae: 0.0704 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 1.6924 - mae: 0.8717 - mse: 1.2259 - val_loss: 0.4724 - val_mae: 0.0709 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 0.9946 - mae: 0.6356 - mse: 0.5281 - val_loss: 0.4724 - val_mae: 0.0712 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 1.1031 - mae: 0.6280 - mse: 0.6367 - val_loss: 0.4724 - val_mae: 0.0717 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.2648 - mae: 0.8020 - mse: 0.7984 - val_loss: 0.4723 - val_mae: 0.0717 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 0.9113 - mae: 0.5484 - mse: 0.4450 - val_loss: 0.4723 - val_mae: 0.0721 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 2.5510 - mae: 1.1633 - mse: 2.0847 - val_loss: 0.4723 - val_mae: 0.0721 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 0.6370 - mae: 0.3630 - mse: 0.1707 - val_loss: 0.4722 - val_mae: 0.0722 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 0.7827 - mae: 0.4881 - mse: 0.3165 - val_loss: 0.4722 - val_mae: 0.0722 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - loss: 1.0241 - mae: 0.5895 - mse: 0.5580 - val_loss: 0.4722 - val_mae: 0.0722 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.7651 - mae: 0.4106 - mse: 0.2989 - val_loss: 0.4721 - val_mae: 0.0722 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.9009 - mae: 0.5391 - mse: 0.4348 - val_loss: 0.4720 - val_mae: 0.0720 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.6881 - mae: 0.3100 - mse: 0.2220 - val_loss: 0.4720 - val_mae: 0.0721 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.2881 - mae: 0.6999 - mse: 0.8221 - val_loss: 0.4720 - val_mae: 0.0720 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1.0345 - mae: 0.6738 - mse: 0.5685 - val_loss: 0.4719 - val_mae: 0.0719 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 1.0912 - mae: 0.7371 - mse: 0.6252 - val_loss: 0.4719 - val_mae: 0.0720 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 1.1763 - mae: 0.6424 - mse: 0.7104 - val_loss: 0.4719 - val_mae: 0.0720 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 0.8026 - mae: 0.4955 - mse: 0.3368 - val_loss: 0.4718 - val_mae: 0.0723 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 0.6068 - mae: 0.2974 - mse: 0.1409 - val_loss: 0.4718 - val_mae: 0.0721 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 0.8864 - mae: 0.5262 - mse: 0.4206 - val_loss: 0.4718 - val_mae: 0.0723 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 1.2767 - mae: 0.7054 - mse: 0.8110 - val_loss: 0.4718 - val_mae: 0.0723 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 1.0258 - mae: 0.6171 - mse: 0.5601 - val_loss: 0.4718 - val_mae: 0.0726 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.0891 - mae: 0.6789 - mse: 0.6234 - val_loss: 0.4717 - val_mae: 0.0726 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.8231 - mae: 0.4517 - mse: 0.3574 - val_loss: 0.4717 - val_mae: 0.0725 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 1.2552 - mae: 0.7523 - mse: 0.7896 - val_loss: 0.4717 - val_mae: 0.0725 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.6281 - mae: 0.3733 - mse: 0.1625 - val_loss: 0.4716 - val_mae: 0.0724 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 0.8397 - mae: 0.5376 - mse: 0.3742 - val_loss: 0.4716 - val_mae: 0.0723 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 0.5988 - mae: 0.3080 - mse: 0.1333 - val_loss: 0.4715 - val_mae: 0.0722 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.5267 - mae: 0.2200 - mse: 0.0613 - val_loss: 0.4715 - val_mae: 0.0727 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.6728 - mae: 0.3986 - mse: 0.2074 - val_loss: 0.4715 - val_mae: 0.0729 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 0.7272 - mae: 0.4112 - mse: 0.2618 - val_loss: 0.4715 - val_mae: 0.0730 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 1.2074 - mae: 0.6894 - mse: 0.7420 - val_loss: 0.4715 - val_mae: 0.0733 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 1.0918 - mae: 0.7294 - mse: 0.6265 - val_loss: 0.4716 - val_mae: 0.0738 - val_mse: 0.0063 - learning_rate: 1.0000e-04\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 1.0230 - mae: 0.5977 - mse: 0.5577 - val_loss: 0.4715 - val_mae: 0.0734 - val_mse: 0.0062 - learning_rate: 1.0000e-04\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.6961 - mae: 0.4211 - mse: 0.2308 - val_loss: 0.4714 - val_mae: 0.0731 - val_mse: 0.0061 - learning_rate: 1.0000e-04\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 0.7373 - mae: 0.4898 - mse: 0.2720 - val_loss: 0.4715 - val_mae: 0.0732 - val_mse: 0.0062 - learning_rate: 1.0000e-04\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.5883 - mae: 0.3086 - mse: 0.1230 - val_loss: 0.4715 - val_mae: 0.0735 - val_mse: 0.0062 - learning_rate: 1.0000e-04\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.7550 - mae: 0.4437 - mse: 0.2897 - val_loss: 0.4714 - val_mae: 0.0732 - val_mse: 0.0062 - learning_rate: 1.0000e-04\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.5829 - mae: 0.9669 - mse: 1.1176 - val_loss: 0.4715 - val_mae: 0.0733 - val_mse: 0.0062 - learning_rate: 1.0000e-04\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1.2875 - mae: 0.6293 - mse: 0.8222 - val_loss: 0.4715 - val_mae: 0.0734 - val_mse: 0.0062 - learning_rate: 1.0000e-04\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - loss: 0.7974 - mae: 0.4800 - mse: 0.3321 - val_loss: 0.4716 - val_mae: 0.0740 - val_mse: 0.0064 - learning_rate: 2.0000e-05\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 0.6052 - mae: 0.3371 - mse: 0.1400 - val_loss: 0.4717 - val_mae: 0.0743 - val_mse: 0.0064 - learning_rate: 2.0000e-05\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.8608 - mae: 0.4572 - mse: 0.3955 - val_loss: 0.4717 - val_mae: 0.0741 - val_mse: 0.0064 - learning_rate: 2.0000e-05\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.7861 - mae: 0.5140 - mse: 0.3209 - val_loss: 0.4718 - val_mae: 0.0745 - val_mse: 0.0065 - learning_rate: 2.0000e-05\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.7248 - mae: 0.4554 - mse: 0.2595 - val_loss: 0.4717 - val_mae: 0.0741 - val_mse: 0.0064 - learning_rate: 2.0000e-05\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - loss: 0.8699 - mae: 0.4591 - mse: 0.4047 - val_loss: 0.4718 - val_mae: 0.0744 - val_mse: 0.0065 - learning_rate: 1.0000e-05\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 0.8338 - mae: 0.5868 - mse: 0.3685 - val_loss: 0.4718 - val_mae: 0.0744 - val_mse: 0.0065 - learning_rate: 1.0000e-05\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.7481 - mae: 0.4838 - mse: 0.2828 - val_loss: 0.4717 - val_mae: 0.0742 - val_mse: 0.0065 - learning_rate: 1.0000e-05\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.3687 - mae: 0.8559 - mse: 0.9034 - val_loss: 0.4718 - val_mae: 0.0743 - val_mse: 0.0065 - learning_rate: 1.0000e-05\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.7545 - mae: 0.4567 - mse: 0.2892 - val_loss: 0.4716 - val_mae: 0.0739 - val_mse: 0.0064 - learning_rate: 1.0000e-05\n",
            "Grupo 85 - RMSE: 0.001926, MAE: 0.001797, sMAPE: 1.33%\n",
            "\n",
            "Treinando modelo para grupo etário 90...\n",
            "Grupo 90: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 0.9630 - mae: 0.5211 - mse: 0.4946 - val_loss: 0.5391 - val_mae: 0.2623 - val_mse: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - loss: 3.8321 - mae: 1.3497 - mse: 3.3640 - val_loss: 0.5391 - val_mae: 0.2623 - val_mse: 0.0709 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 4.8995 - mae: 1.6215 - mse: 4.4314 - val_loss: 0.5396 - val_mae: 0.2634 - val_mse: 0.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.0747 - mae: 0.6316 - mse: 0.6066 - val_loss: 0.5404 - val_mae: 0.2648 - val_mse: 0.0723 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 1.8370 - mae: 0.6999 - mse: 1.3689 - val_loss: 0.5418 - val_mae: 0.2675 - val_mse: 0.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 2.0180 - mae: 1.1602 - mse: 1.5499 - val_loss: 0.5434 - val_mae: 0.2705 - val_mse: 0.0753 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.1722 - mae: 0.5538 - mse: 0.7041 - val_loss: 0.5427 - val_mae: 0.2693 - val_mse: 0.0746 - learning_rate: 1.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.5001 - mae: 0.8330 - mse: 1.0320 - val_loss: 0.5418 - val_mae: 0.2674 - val_mse: 0.0737 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - loss: 1.5255 - mae: 0.8512 - mse: 1.0575 - val_loss: 0.5405 - val_mae: 0.2652 - val_mse: 0.0725 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 0.8180 - mae: 0.4283 - mse: 0.3499 - val_loss: 0.5390 - val_mae: 0.2623 - val_mse: 0.0709 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 2.6472 - mae: 1.2466 - mse: 2.1791 - val_loss: 0.5373 - val_mae: 0.2589 - val_mse: 0.0692 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 1.1051 - mae: 0.6212 - mse: 0.6370 - val_loss: 0.5352 - val_mae: 0.2550 - val_mse: 0.0672 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.6194 - mae: 0.3098 - mse: 0.1513 - val_loss: 0.5335 - val_mae: 0.2516 - val_mse: 0.0655 - learning_rate: 1.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 1.8777 - mae: 0.8745 - mse: 1.4096 - val_loss: 0.5323 - val_mae: 0.2491 - val_mse: 0.0642 - learning_rate: 1.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.5341 - mae: 0.8899 - mse: 1.0660 - val_loss: 0.5318 - val_mae: 0.2482 - val_mse: 0.0638 - learning_rate: 1.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 3.0202 - mae: 1.2846 - mse: 2.5521 - val_loss: 0.5295 - val_mae: 0.2436 - val_mse: 0.0615 - learning_rate: 1.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.9137 - mae: 0.5711 - mse: 0.4457 - val_loss: 0.5286 - val_mae: 0.2416 - val_mse: 0.0606 - learning_rate: 1.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 1.7032 - mae: 0.9875 - mse: 1.2352 - val_loss: 0.5281 - val_mae: 0.2406 - val_mse: 0.0600 - learning_rate: 1.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 1.8774 - mae: 1.1349 - mse: 1.4094 - val_loss: 0.5268 - val_mae: 0.2379 - val_mse: 0.0588 - learning_rate: 1.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 2.6660 - mae: 1.0840 - mse: 2.1980 - val_loss: 0.5259 - val_mae: 0.2361 - val_mse: 0.0579 - learning_rate: 1.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.5054 - mae: 0.8287 - mse: 1.0373 - val_loss: 0.5250 - val_mae: 0.2340 - val_mse: 0.0569 - learning_rate: 1.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 1.3799 - mae: 0.7329 - mse: 0.9118 - val_loss: 0.5235 - val_mae: 0.2310 - val_mse: 0.0555 - learning_rate: 1.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 0.7923 - mae: 0.5274 - mse: 0.3242 - val_loss: 0.5234 - val_mae: 0.2307 - val_mse: 0.0553 - learning_rate: 1.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 1.0010 - mae: 0.6740 - mse: 0.5330 - val_loss: 0.5223 - val_mae: 0.2284 - val_mse: 0.0543 - learning_rate: 1.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 1.3290 - mae: 0.8096 - mse: 0.8610 - val_loss: 0.5216 - val_mae: 0.2269 - val_mse: 0.0536 - learning_rate: 1.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 0.7884 - mae: 0.5170 - mse: 0.3204 - val_loss: 0.5205 - val_mae: 0.2244 - val_mse: 0.0525 - learning_rate: 1.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.6826 - mae: 0.3367 - mse: 0.2145 - val_loss: 0.5198 - val_mae: 0.2229 - val_mse: 0.0518 - learning_rate: 1.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.8175 - mae: 0.9307 - mse: 1.3494 - val_loss: 0.5188 - val_mae: 0.2206 - val_mse: 0.0508 - learning_rate: 1.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 2.8284 - mae: 1.2151 - mse: 2.3604 - val_loss: 0.5177 - val_mae: 0.2180 - val_mse: 0.0497 - learning_rate: 1.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 2.6720 - mae: 1.2303 - mse: 2.2040 - val_loss: 0.5177 - val_mae: 0.2181 - val_mse: 0.0497 - learning_rate: 1.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.4915 - mae: 0.7035 - mse: 1.0235 - val_loss: 0.5166 - val_mae: 0.2155 - val_mse: 0.0486 - learning_rate: 1.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 3.5600 - mae: 1.6100 - mse: 3.0920 - val_loss: 0.5155 - val_mae: 0.2130 - val_mse: 0.0475 - learning_rate: 1.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 1.1308 - mae: 0.6298 - mse: 0.6628 - val_loss: 0.5153 - val_mae: 0.2125 - val_mse: 0.0473 - learning_rate: 1.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 2.0743 - mae: 1.1463 - mse: 1.6063 - val_loss: 0.5143 - val_mae: 0.2103 - val_mse: 0.0463 - learning_rate: 1.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 2.9274 - mae: 1.4745 - mse: 2.4594 - val_loss: 0.5135 - val_mae: 0.2082 - val_mse: 0.0455 - learning_rate: 1.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.7795 - mae: 0.9227 - mse: 1.3115 - val_loss: 0.5130 - val_mae: 0.2071 - val_mse: 0.0450 - learning_rate: 1.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.4763 - mae: 0.8433 - mse: 1.0083 - val_loss: 0.5121 - val_mae: 0.2048 - val_mse: 0.0441 - learning_rate: 1.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 1.1691 - mae: 0.7796 - mse: 0.7012 - val_loss: 0.5115 - val_mae: 0.2036 - val_mse: 0.0436 - learning_rate: 1.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.9064 - mae: 0.4983 - mse: 0.4385 - val_loss: 0.5113 - val_mae: 0.2030 - val_mse: 0.0433 - learning_rate: 1.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 3.5151 - mae: 1.2955 - mse: 3.0471 - val_loss: 0.5100 - val_mae: 0.1997 - val_mse: 0.0420 - learning_rate: 1.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 2.7037 - mae: 1.2297 - mse: 2.2357 - val_loss: 0.5096 - val_mae: 0.1989 - val_mse: 0.0417 - learning_rate: 1.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 0.8974 - mae: 0.5065 - mse: 0.4295 - val_loss: 0.5095 - val_mae: 0.1986 - val_mse: 0.0415 - learning_rate: 1.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 2.2379 - mae: 1.1266 - mse: 1.7699 - val_loss: 0.5094 - val_mae: 0.1982 - val_mse: 0.0414 - learning_rate: 1.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.2998 - mae: 0.7413 - mse: 0.8318 - val_loss: 0.5081 - val_mae: 0.1951 - val_mse: 0.0402 - learning_rate: 1.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.0564 - mae: 0.6898 - mse: 0.5884 - val_loss: 0.5079 - val_mae: 0.1944 - val_mse: 0.0399 - learning_rate: 1.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.2732 - mae: 0.7495 - mse: 0.8053 - val_loss: 0.5075 - val_mae: 0.1937 - val_mse: 0.0396 - learning_rate: 1.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.3321 - mae: 0.6328 - mse: 0.8642 - val_loss: 0.5070 - val_mae: 0.1922 - val_mse: 0.0391 - learning_rate: 1.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.1919 - mae: 0.7523 - mse: 0.7240 - val_loss: 0.5059 - val_mae: 0.1894 - val_mse: 0.0380 - learning_rate: 1.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.1111 - mae: 0.7266 - mse: 0.6432 - val_loss: 0.5046 - val_mae: 0.1858 - val_mse: 0.0366 - learning_rate: 1.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 2.2889 - mae: 0.9364 - mse: 1.8210 - val_loss: 0.5035 - val_mae: 0.1829 - val_mse: 0.0356 - learning_rate: 1.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 1.4410 - mae: 0.8946 - mse: 0.9730 - val_loss: 0.5026 - val_mae: 0.1805 - val_mse: 0.0347 - learning_rate: 1.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.3429 - mae: 0.7045 - mse: 0.8750 - val_loss: 0.5023 - val_mae: 0.1796 - val_mse: 0.0344 - learning_rate: 1.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 1.7112 - mae: 0.9213 - mse: 1.2433 - val_loss: 0.5015 - val_mae: 0.1773 - val_mse: 0.0335 - learning_rate: 1.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 2.1704 - mae: 1.1417 - mse: 1.7024 - val_loss: 0.5008 - val_mae: 0.1755 - val_mse: 0.0329 - learning_rate: 1.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 2.7627 - mae: 1.0147 - mse: 2.2947 - val_loss: 0.5005 - val_mae: 0.1746 - val_mse: 0.0326 - learning_rate: 1.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 2.5157 - mae: 1.1018 - mse: 2.0478 - val_loss: 0.5002 - val_mae: 0.1739 - val_mse: 0.0323 - learning_rate: 1.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 2.7578 - mae: 1.1595 - mse: 2.2899 - val_loss: 0.5001 - val_mae: 0.1735 - val_mse: 0.0322 - learning_rate: 1.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 1.4491 - mae: 0.7771 - mse: 0.9812 - val_loss: 0.4997 - val_mae: 0.1725 - val_mse: 0.0318 - learning_rate: 1.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.8076 - mae: 0.9099 - mse: 1.3397 - val_loss: 0.4996 - val_mae: 0.1721 - val_mse: 0.0317 - learning_rate: 1.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 2.3323 - mae: 1.0280 - mse: 1.8644 - val_loss: 0.4990 - val_mae: 0.1705 - val_mse: 0.0311 - learning_rate: 1.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1.3063 - mae: 0.8421 - mse: 0.8384 - val_loss: 0.4978 - val_mae: 0.1667 - val_mse: 0.0299 - learning_rate: 1.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 2.3335 - mae: 0.9434 - mse: 1.8656 - val_loss: 0.4972 - val_mae: 0.1651 - val_mse: 0.0293 - learning_rate: 1.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 2.4235 - mae: 1.1620 - mse: 1.9556 - val_loss: 0.4965 - val_mae: 0.1628 - val_mse: 0.0286 - learning_rate: 1.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 1.8296 - mae: 0.8739 - mse: 1.3617 - val_loss: 0.4962 - val_mae: 0.1621 - val_mse: 0.0283 - learning_rate: 1.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 2.4369 - mae: 0.9064 - mse: 1.9690 - val_loss: 0.4951 - val_mae: 0.1586 - val_mse: 0.0272 - learning_rate: 1.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 1.5262 - mae: 0.8611 - mse: 1.0584 - val_loss: 0.4950 - val_mae: 0.1582 - val_mse: 0.0271 - learning_rate: 1.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 2.7794 - mae: 1.3571 - mse: 2.3115 - val_loss: 0.4947 - val_mae: 0.1573 - val_mse: 0.0268 - learning_rate: 1.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.8573 - mae: 0.5372 - mse: 0.3894 - val_loss: 0.4945 - val_mae: 0.1569 - val_mse: 0.0267 - learning_rate: 1.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - loss: 1.5257 - mae: 0.9363 - mse: 1.0578 - val_loss: 0.4940 - val_mae: 0.1553 - val_mse: 0.0262 - learning_rate: 1.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - loss: 1.4689 - mae: 0.8015 - mse: 1.0010 - val_loss: 0.4931 - val_mae: 0.1522 - val_mse: 0.0252 - learning_rate: 1.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.9608 - mae: 0.6575 - mse: 0.4929 - val_loss: 0.4927 - val_mae: 0.1510 - val_mse: 0.0249 - learning_rate: 1.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 1.7521 - mae: 0.9083 - mse: 1.2842 - val_loss: 0.4920 - val_mae: 0.1485 - val_mse: 0.0241 - learning_rate: 1.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 1.8322 - mae: 0.8988 - mse: 1.3643 - val_loss: 0.4927 - val_mae: 0.1508 - val_mse: 0.0248 - learning_rate: 1.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.7842 - mae: 0.4870 - mse: 0.3163 - val_loss: 0.4914 - val_mae: 0.1467 - val_mse: 0.0236 - learning_rate: 1.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 1.3047 - mae: 0.7049 - mse: 0.8368 - val_loss: 0.4910 - val_mae: 0.1451 - val_mse: 0.0231 - learning_rate: 1.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 1.0692 - mae: 0.6090 - mse: 0.6013 - val_loss: 0.4907 - val_mae: 0.1443 - val_mse: 0.0229 - learning_rate: 1.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - loss: 1.0489 - mae: 0.7084 - mse: 0.5810 - val_loss: 0.4905 - val_mae: 0.1434 - val_mse: 0.0226 - learning_rate: 1.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 2.2704 - mae: 0.9262 - mse: 1.8025 - val_loss: 0.4898 - val_mae: 0.1412 - val_mse: 0.0220 - learning_rate: 1.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 2.3409 - mae: 1.1320 - mse: 1.8731 - val_loss: 0.4885 - val_mae: 0.1362 - val_mse: 0.0206 - learning_rate: 1.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.5435 - mae: 0.2572 - mse: 0.0756 - val_loss: 0.4886 - val_mae: 0.1369 - val_mse: 0.0208 - learning_rate: 1.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - loss: 2.9140 - mae: 1.2780 - mse: 2.4462 - val_loss: 0.4884 - val_mae: 0.1359 - val_mse: 0.0205 - learning_rate: 1.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 2.0589 - mae: 1.1451 - mse: 1.5910 - val_loss: 0.4879 - val_mae: 0.1340 - val_mse: 0.0200 - learning_rate: 1.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 3.4843 - mae: 1.2670 - mse: 3.0164 - val_loss: 0.4876 - val_mae: 0.1332 - val_mse: 0.0198 - learning_rate: 1.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 1.8183 - mae: 1.0514 - mse: 1.3504 - val_loss: 0.4875 - val_mae: 0.1327 - val_mse: 0.0196 - learning_rate: 1.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.9190 - mae: 0.5306 - mse: 0.4511 - val_loss: 0.4876 - val_mae: 0.1330 - val_mse: 0.0197 - learning_rate: 1.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.4681 - mae: 0.7875 - mse: 1.0003 - val_loss: 0.4869 - val_mae: 0.1304 - val_mse: 0.0190 - learning_rate: 1.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.5284 - mae: 0.8173 - mse: 1.0606 - val_loss: 0.4863 - val_mae: 0.1283 - val_mse: 0.0185 - learning_rate: 1.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.7478 - mae: 0.4795 - mse: 0.2800 - val_loss: 0.4856 - val_mae: 0.1253 - val_mse: 0.0177 - learning_rate: 1.0000e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 1.6960 - mae: 0.8924 - mse: 1.2281 - val_loss: 0.4857 - val_mae: 0.1258 - val_mse: 0.0179 - learning_rate: 1.0000e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 2.0952 - mae: 0.9795 - mse: 1.6273 - val_loss: 0.4851 - val_mae: 0.1234 - val_mse: 0.0173 - learning_rate: 1.0000e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 1.2658 - mae: 0.6881 - mse: 0.7980 - val_loss: 0.4844 - val_mae: 0.1204 - val_mse: 0.0165 - learning_rate: 1.0000e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.4982 - mae: 0.9469 - mse: 1.0304 - val_loss: 0.4841 - val_mae: 0.1192 - val_mse: 0.0162 - learning_rate: 1.0000e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.8940 - mae: 0.4721 - mse: 0.4262 - val_loss: 0.4838 - val_mae: 0.1179 - val_mse: 0.0159 - learning_rate: 1.0000e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.8939 - mae: 0.5758 - mse: 0.4260 - val_loss: 0.4833 - val_mae: 0.1159 - val_mse: 0.0155 - learning_rate: 1.0000e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 1.7389 - mae: 0.7843 - mse: 1.2711 - val_loss: 0.4829 - val_mae: 0.1140 - val_mse: 0.0150 - learning_rate: 1.0000e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 2.8196 - mae: 1.1776 - mse: 2.3517 - val_loss: 0.4828 - val_mae: 0.1137 - val_mse: 0.0150 - learning_rate: 1.0000e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 1.2431 - mae: 0.7107 - mse: 0.7753 - val_loss: 0.4821 - val_mae: 0.1104 - val_mse: 0.0143 - learning_rate: 1.0000e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.5344 - mae: 0.9523 - mse: 1.0666 - val_loss: 0.4821 - val_mae: 0.1105 - val_mse: 0.0143 - learning_rate: 1.0000e-04\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 2.2168 - mae: 1.2040 - mse: 1.7490 - val_loss: 0.4815 - val_mae: 0.1079 - val_mse: 0.0137 - learning_rate: 1.0000e-04\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 1.7631 - mae: 0.9082 - mse: 1.2953 - val_loss: 0.4810 - val_mae: 0.1053 - val_mse: 0.0132 - learning_rate: 1.0000e-04\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.5226 - mae: 0.7691 - mse: 1.0548 - val_loss: 0.4809 - val_mae: 0.1051 - val_mse: 0.0131 - learning_rate: 1.0000e-04\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 1.3316 - mae: 0.7586 - mse: 0.8638 - val_loss: 0.4804 - val_mae: 0.1027 - val_mse: 0.0126 - learning_rate: 1.0000e-04\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 2.6679 - mae: 1.1358 - mse: 2.2001 - val_loss: 0.4802 - val_mae: 0.1017 - val_mse: 0.0124 - learning_rate: 1.0000e-04\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.2811 - mae: 0.8964 - mse: 1.8133 - val_loss: 0.4804 - val_mae: 0.1027 - val_mse: 0.0126 - learning_rate: 1.0000e-04\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.6199 - mae: 0.9010 - mse: 1.1521 - val_loss: 0.4799 - val_mae: 0.1001 - val_mse: 0.0121 - learning_rate: 1.0000e-04\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 1.1751 - mae: 0.7020 - mse: 0.7073 - val_loss: 0.4797 - val_mae: 0.0990 - val_mse: 0.0119 - learning_rate: 1.0000e-04\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.3267 - mae: 0.7400 - mse: 0.8589 - val_loss: 0.4795 - val_mae: 0.0982 - val_mse: 0.0117 - learning_rate: 1.0000e-04\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - loss: 1.9777 - mae: 1.1300 - mse: 1.5099 - val_loss: 0.4795 - val_mae: 0.0982 - val_mse: 0.0117 - learning_rate: 1.0000e-04\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 1.8031 - mae: 1.0438 - mse: 1.3353 - val_loss: 0.4794 - val_mae: 0.0978 - val_mse: 0.0116 - learning_rate: 1.0000e-04\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 2.5706 - mae: 0.9692 - mse: 2.1028 - val_loss: 0.4792 - val_mae: 0.0968 - val_mse: 0.0114 - learning_rate: 1.0000e-04\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1.0206 - mae: 0.6437 - mse: 0.5528 - val_loss: 0.4790 - val_mae: 0.0957 - val_mse: 0.0112 - learning_rate: 1.0000e-04\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 2.1552 - mae: 1.1289 - mse: 1.6874 - val_loss: 0.4790 - val_mae: 0.0962 - val_mse: 0.0113 - learning_rate: 1.0000e-04\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.8749 - mae: 0.6244 - mse: 0.4071 - val_loss: 0.4791 - val_mae: 0.0965 - val_mse: 0.0113 - learning_rate: 1.0000e-04\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 1.2915 - mae: 0.7256 - mse: 0.8238 - val_loss: 0.4791 - val_mae: 0.0966 - val_mse: 0.0114 - learning_rate: 1.0000e-04\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.1993 - mae: 0.7069 - mse: 0.7315 - val_loss: 0.4790 - val_mae: 0.0959 - val_mse: 0.0112 - learning_rate: 1.0000e-04\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.7483 - mae: 0.4483 - mse: 0.2805 - val_loss: 0.4783 - val_mae: 0.0923 - val_mse: 0.0105 - learning_rate: 1.0000e-04\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 2.1906 - mae: 1.1112 - mse: 1.7229 - val_loss: 0.4781 - val_mae: 0.0908 - val_mse: 0.0103 - learning_rate: 1.0000e-04\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 2.7497 - mae: 1.0924 - mse: 2.2819 - val_loss: 0.4780 - val_mae: 0.0905 - val_mse: 0.0103 - learning_rate: 1.0000e-04\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 2.1902 - mae: 0.9329 - mse: 1.7224 - val_loss: 0.4782 - val_mae: 0.0914 - val_mse: 0.0104 - learning_rate: 1.0000e-04\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.6835 - mae: 1.0125 - mse: 1.2157 - val_loss: 0.4777 - val_mae: 0.0890 - val_mse: 0.0100 - learning_rate: 1.0000e-04\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 1.6009 - mae: 0.9778 - mse: 1.1332 - val_loss: 0.4775 - val_mae: 0.0875 - val_mse: 0.0097 - learning_rate: 1.0000e-04\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.1521 - mae: 0.7764 - mse: 0.6843 - val_loss: 0.4770 - val_mae: 0.0842 - val_mse: 0.0092 - learning_rate: 1.0000e-04\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - loss: 1.7872 - mae: 1.0129 - mse: 1.3195 - val_loss: 0.4769 - val_mae: 0.0838 - val_mse: 0.0091 - learning_rate: 1.0000e-04\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 3.2458 - mae: 1.4774 - mse: 2.7780 - val_loss: 0.4764 - val_mae: 0.0812 - val_mse: 0.0087 - learning_rate: 1.0000e-04\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 2.0125 - mae: 0.9504 - mse: 1.5447 - val_loss: 0.4760 - val_mae: 0.0786 - val_mse: 0.0083 - learning_rate: 1.0000e-04\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 1.7457 - mae: 0.8143 - mse: 1.2779 - val_loss: 0.4756 - val_mae: 0.0762 - val_mse: 0.0079 - learning_rate: 1.0000e-04\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 2.0668 - mae: 1.0906 - mse: 1.5991 - val_loss: 0.4757 - val_mae: 0.0768 - val_mse: 0.0080 - learning_rate: 1.0000e-04\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - loss: 1.9772 - mae: 1.0498 - mse: 1.5095 - val_loss: 0.4758 - val_mae: 0.0769 - val_mse: 0.0080 - learning_rate: 1.0000e-04\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.8903 - mae: 0.5633 - mse: 0.4225 - val_loss: 0.4751 - val_mae: 0.0744 - val_mse: 0.0074 - learning_rate: 1.0000e-04\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 0.8884 - mae: 0.5628 - mse: 0.4207 - val_loss: 0.4751 - val_mae: 0.0742 - val_mse: 0.0074 - learning_rate: 1.0000e-04\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.2565 - mae: 0.6863 - mse: 0.7887 - val_loss: 0.4748 - val_mae: 0.0728 - val_mse: 0.0070 - learning_rate: 1.0000e-04\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.5781 - mae: 0.2593 - mse: 0.1104 - val_loss: 0.4745 - val_mae: 0.0716 - val_mse: 0.0068 - learning_rate: 1.0000e-04\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.1408 - mae: 0.7374 - mse: 0.6731 - val_loss: 0.4739 - val_mae: 0.0688 - val_mse: 0.0061 - learning_rate: 1.0000e-04\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.8438 - mae: 0.5326 - mse: 0.3761 - val_loss: 0.4736 - val_mae: 0.0673 - val_mse: 0.0058 - learning_rate: 1.0000e-04\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 1.1489 - mae: 0.6498 - mse: 0.6811 - val_loss: 0.4732 - val_mae: 0.0656 - val_mse: 0.0055 - learning_rate: 1.0000e-04\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 2.1024 - mae: 1.0006 - mse: 1.6347 - val_loss: 0.4726 - val_mae: 0.0621 - val_mse: 0.0049 - learning_rate: 1.0000e-04\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 2.1615 - mae: 1.1145 - mse: 1.6938 - val_loss: 0.4725 - val_mae: 0.0614 - val_mse: 0.0047 - learning_rate: 1.0000e-04\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.9726 - mae: 0.6008 - mse: 0.5049 - val_loss: 0.4726 - val_mae: 0.0621 - val_mse: 0.0049 - learning_rate: 1.0000e-04\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 2.1777 - mae: 1.1557 - mse: 1.7100 - val_loss: 0.4724 - val_mae: 0.0612 - val_mse: 0.0047 - learning_rate: 1.0000e-04\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 0.8855 - mae: 0.5759 - mse: 0.4178 - val_loss: 0.4722 - val_mae: 0.0601 - val_mse: 0.0045 - learning_rate: 1.0000e-04\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 2.5489 - mae: 1.2689 - mse: 2.0811 - val_loss: 0.4721 - val_mae: 0.0594 - val_mse: 0.0044 - learning_rate: 1.0000e-04\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 2.1892 - mae: 1.0527 - mse: 1.7215 - val_loss: 0.4724 - val_mae: 0.0612 - val_mse: 0.0047 - learning_rate: 1.0000e-04\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.1061 - mae: 0.7729 - mse: 0.6384 - val_loss: 0.4722 - val_mae: 0.0598 - val_mse: 0.0045 - learning_rate: 1.0000e-04\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.2086 - mae: 0.6085 - mse: 0.7409 - val_loss: 0.4719 - val_mae: 0.0578 - val_mse: 0.0042 - learning_rate: 1.0000e-04\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.0430 - mae: 0.6487 - mse: 0.5753 - val_loss: 0.4720 - val_mae: 0.0590 - val_mse: 0.0043 - learning_rate: 1.0000e-04\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 1.0805 - mae: 0.7102 - mse: 0.6128 - val_loss: 0.4718 - val_mae: 0.0573 - val_mse: 0.0041 - learning_rate: 1.0000e-04\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.3227 - mae: 0.7452 - mse: 0.8550 - val_loss: 0.4716 - val_mae: 0.0561 - val_mse: 0.0039 - learning_rate: 1.0000e-04\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 1.6090 - mae: 0.7433 - mse: 1.1413 - val_loss: 0.4716 - val_mae: 0.0558 - val_mse: 0.0039 - learning_rate: 1.0000e-04\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.8684 - mae: 0.5638 - mse: 0.4007 - val_loss: 0.4714 - val_mae: 0.0542 - val_mse: 0.0037 - learning_rate: 1.0000e-04\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.6777 - mae: 0.8493 - mse: 1.2100 - val_loss: 0.4713 - val_mae: 0.0540 - val_mse: 0.0037 - learning_rate: 1.0000e-04\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.7580 - mae: 0.2834 - mse: 0.2903 - val_loss: 0.4713 - val_mae: 0.0533 - val_mse: 0.0036 - learning_rate: 1.0000e-04\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 1.5417 - mae: 0.9067 - mse: 1.0740 - val_loss: 0.4710 - val_mae: 0.0505 - val_mse: 0.0033 - learning_rate: 1.0000e-04\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 2.0314 - mae: 1.0995 - mse: 1.5638 - val_loss: 0.4711 - val_mae: 0.0516 - val_mse: 0.0034 - learning_rate: 1.0000e-04\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 0.7043 - mae: 0.4468 - mse: 0.2366 - val_loss: 0.4710 - val_mae: 0.0509 - val_mse: 0.0033 - learning_rate: 1.0000e-04\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.8267 - mae: 0.5404 - mse: 0.3590 - val_loss: 0.4710 - val_mae: 0.0508 - val_mse: 0.0033 - learning_rate: 1.0000e-04\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.9590 - mae: 0.5786 - mse: 0.4913 - val_loss: 0.4708 - val_mae: 0.0493 - val_mse: 0.0031 - learning_rate: 1.0000e-04\n",
            "Epoch 157/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 1.0755 - mae: 0.6226 - mse: 0.6079 - val_loss: 0.4707 - val_mae: 0.0478 - val_mse: 0.0030 - learning_rate: 1.0000e-04\n",
            "Epoch 158/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.8366 - mae: 0.8222 - mse: 1.3689 - val_loss: 0.4706 - val_mae: 0.0468 - val_mse: 0.0029 - learning_rate: 1.0000e-04\n",
            "Epoch 159/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.5629 - mae: 0.8858 - mse: 1.0952 - val_loss: 0.4705 - val_mae: 0.0455 - val_mse: 0.0028 - learning_rate: 1.0000e-04\n",
            "Epoch 160/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.0879 - mae: 0.6310 - mse: 0.6203 - val_loss: 0.4703 - val_mae: 0.0440 - val_mse: 0.0027 - learning_rate: 1.0000e-04\n",
            "Epoch 161/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 1.8244 - mae: 0.9576 - mse: 1.3567 - val_loss: 0.4703 - val_mae: 0.0445 - val_mse: 0.0027 - learning_rate: 1.0000e-04\n",
            "Epoch 162/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 3.1098 - mae: 1.2357 - mse: 2.6421 - val_loss: 0.4702 - val_mae: 0.0430 - val_mse: 0.0025 - learning_rate: 1.0000e-04\n",
            "Epoch 163/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 0.9746 - mae: 0.6210 - mse: 0.5070 - val_loss: 0.4702 - val_mae: 0.0428 - val_mse: 0.0025 - learning_rate: 1.0000e-04\n",
            "Epoch 164/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.3666 - mae: 0.8324 - mse: 0.8990 - val_loss: 0.4703 - val_mae: 0.0434 - val_mse: 0.0026 - learning_rate: 1.0000e-04\n",
            "Epoch 165/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - loss: 1.0443 - mae: 0.6510 - mse: 0.5767 - val_loss: 0.4701 - val_mae: 0.0425 - val_mse: 0.0024 - learning_rate: 1.0000e-04\n",
            "Epoch 166/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 2.0022 - mae: 1.0821 - mse: 1.5346 - val_loss: 0.4700 - val_mae: 0.0421 - val_mse: 0.0024 - learning_rate: 1.0000e-04\n",
            "Epoch 167/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.8517 - mae: 0.4211 - mse: 0.3840 - val_loss: 0.4699 - val_mae: 0.0414 - val_mse: 0.0023 - learning_rate: 1.0000e-04\n",
            "Epoch 168/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.6653 - mae: 0.9557 - mse: 1.1976 - val_loss: 0.4699 - val_mae: 0.0414 - val_mse: 0.0023 - learning_rate: 1.0000e-04\n",
            "Epoch 169/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 1.2092 - mae: 0.7900 - mse: 0.7416 - val_loss: 0.4699 - val_mae: 0.0412 - val_mse: 0.0022 - learning_rate: 1.0000e-04\n",
            "Epoch 170/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.7788 - mae: 0.4449 - mse: 0.3112 - val_loss: 0.4699 - val_mae: 0.0410 - val_mse: 0.0022 - learning_rate: 1.0000e-04\n",
            "Epoch 171/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.7356 - mae: 0.4748 - mse: 0.2680 - val_loss: 0.4698 - val_mae: 0.0409 - val_mse: 0.0022 - learning_rate: 1.0000e-04\n",
            "Epoch 172/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.9519 - mae: 0.6226 - mse: 0.4843 - val_loss: 0.4698 - val_mae: 0.0409 - val_mse: 0.0022 - learning_rate: 1.0000e-04\n",
            "Epoch 173/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.6471 - mae: 0.8249 - mse: 1.1795 - val_loss: 0.4698 - val_mae: 0.0402 - val_mse: 0.0021 - learning_rate: 1.0000e-04\n",
            "Epoch 174/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1.2095 - mae: 0.7938 - mse: 0.7419 - val_loss: 0.4698 - val_mae: 0.0401 - val_mse: 0.0021 - learning_rate: 1.0000e-04\n",
            "Epoch 175/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.9701 - mae: 0.6029 - mse: 0.5024 - val_loss: 0.4697 - val_mae: 0.0394 - val_mse: 0.0021 - learning_rate: 1.0000e-04\n",
            "Epoch 176/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 2.5628 - mae: 1.2180 - mse: 2.0952 - val_loss: 0.4697 - val_mae: 0.0396 - val_mse: 0.0021 - learning_rate: 1.0000e-04\n",
            "Epoch 177/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.6305 - mae: 0.3093 - mse: 0.1628 - val_loss: 0.4697 - val_mae: 0.0390 - val_mse: 0.0021 - learning_rate: 1.0000e-04\n",
            "Epoch 178/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - loss: 1.6599 - mae: 0.9589 - mse: 1.1923 - val_loss: 0.4697 - val_mae: 0.0388 - val_mse: 0.0021 - learning_rate: 1.0000e-04\n",
            "Epoch 179/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 2.8351 - mae: 1.2936 - mse: 2.3675 - val_loss: 0.4697 - val_mae: 0.0380 - val_mse: 0.0021 - learning_rate: 2.0000e-05\n",
            "Epoch 180/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 0.7447 - mae: 0.4185 - mse: 0.2771 - val_loss: 0.4697 - val_mae: 0.0370 - val_mse: 0.0021 - learning_rate: 2.0000e-05\n",
            "Epoch 181/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.4264 - mae: 0.8986 - mse: 0.9588 - val_loss: 0.4698 - val_mae: 0.0375 - val_mse: 0.0022 - learning_rate: 2.0000e-05\n",
            "Epoch 182/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.0686 - mae: 0.6569 - mse: 0.6010 - val_loss: 0.4698 - val_mae: 0.0375 - val_mse: 0.0022 - learning_rate: 2.0000e-05\n",
            "Epoch 183/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 2.1961 - mae: 1.1343 - mse: 1.7285 - val_loss: 0.4698 - val_mae: 0.0380 - val_mse: 0.0022 - learning_rate: 2.0000e-05\n",
            "Epoch 184/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.7924 - mae: 0.4794 - mse: 0.3248 - val_loss: 0.4698 - val_mae: 0.0377 - val_mse: 0.0022 - learning_rate: 1.0000e-05\n",
            "Epoch 185/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.5627 - mae: 0.2708 - mse: 0.0951 - val_loss: 0.4698 - val_mae: 0.0383 - val_mse: 0.0022 - learning_rate: 1.0000e-05\n",
            "Epoch 186/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.9143 - mae: 0.5216 - mse: 0.4467 - val_loss: 0.4699 - val_mae: 0.0385 - val_mse: 0.0023 - learning_rate: 1.0000e-05\n",
            "Epoch 187/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - loss: 2.1937 - mae: 1.0152 - mse: 1.7261 - val_loss: 0.4699 - val_mae: 0.0385 - val_mse: 0.0023 - learning_rate: 1.0000e-05\n",
            "Epoch 188/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 1.1943 - mae: 0.7414 - mse: 0.7267 - val_loss: 0.4698 - val_mae: 0.0379 - val_mse: 0.0022 - learning_rate: 1.0000e-05\n",
            "Epoch 189/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 0.9581 - mae: 0.5126 - mse: 0.4906 - val_loss: 0.4699 - val_mae: 0.0379 - val_mse: 0.0023 - learning_rate: 1.0000e-05\n",
            "Epoch 190/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.7573 - mae: 0.5049 - mse: 0.2897 - val_loss: 0.4698 - val_mae: 0.0378 - val_mse: 0.0022 - learning_rate: 1.0000e-05\n",
            "Epoch 191/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.4322 - mae: 0.8432 - mse: 0.9646 - val_loss: 0.4700 - val_mae: 0.0385 - val_mse: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 192/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.4792 - mae: 0.9180 - mse: 1.0116 - val_loss: 0.4700 - val_mae: 0.0388 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 193/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.2798 - mae: 0.7890 - mse: 0.8122 - val_loss: 0.4700 - val_mae: 0.0385 - val_mse: 0.0024 - learning_rate: 1.0000e-05\n",
            "Grupo 90 - RMSE: 0.002576, MAE: 0.002188, sMAPE: 1.02%\n",
            "\n",
            "=== TREINANDO MODELOS PARA MULHERES ===\n",
            "\n",
            "=== TREINANDO MODELOS PARA MULHERES ===\n",
            "\n",
            "Treinando modelo para grupo etário 0...\n",
            "Grupo 0: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 2.1784 - mae: 1.1256 - mse: 1.7072 - val_loss: 0.4755 - val_mae: 0.0655 - val_mse: 0.0047 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - loss: 0.8192 - mae: 0.4199 - mse: 0.3484 - val_loss: 0.4753 - val_mae: 0.0666 - val_mse: 0.0048 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 3.1013 - mae: 1.3257 - mse: 2.6308 - val_loss: 0.4751 - val_mae: 0.0663 - val_mse: 0.0048 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 2.2745 - mae: 1.0837 - mse: 1.8042 - val_loss: 0.4747 - val_mae: 0.0644 - val_mse: 0.0045 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 1.2013 - mae: 0.8278 - mse: 0.7311 - val_loss: 0.4745 - val_mae: 0.0639 - val_mse: 0.0045 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 1.0958 - mae: 0.7717 - mse: 0.6257 - val_loss: 0.4741 - val_mae: 0.0611 - val_mse: 0.0041 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 1.0817 - mae: 0.5677 - mse: 0.6117 - val_loss: 0.4738 - val_mae: 0.0595 - val_mse: 0.0039 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 1.4263 - mae: 0.8552 - mse: 0.9565 - val_loss: 0.4734 - val_mae: 0.0577 - val_mse: 0.0037 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.9903 - mae: 0.6352 - mse: 0.5205 - val_loss: 0.4731 - val_mae: 0.0557 - val_mse: 0.0035 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.4271 - mae: 0.7690 - mse: 0.9575 - val_loss: 0.4728 - val_mae: 0.0542 - val_mse: 0.0033 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.2547 - mae: 0.6726 - mse: 0.7852 - val_loss: 0.4725 - val_mae: 0.0520 - val_mse: 0.0031 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1.5759 - mae: 0.8421 - mse: 1.1065 - val_loss: 0.4724 - val_mae: 0.0514 - val_mse: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1.4828 - mae: 0.7388 - mse: 1.0135 - val_loss: 0.4720 - val_mae: 0.0491 - val_mse: 0.0028 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 1.1936 - mae: 0.6419 - mse: 0.7244 - val_loss: 0.4717 - val_mae: 0.0468 - val_mse: 0.0026 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.8904 - mae: 0.5667 - mse: 0.4212 - val_loss: 0.4713 - val_mae: 0.0436 - val_mse: 0.0023 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1.4512 - mae: 0.7639 - mse: 0.9822 - val_loss: 0.4711 - val_mae: 0.0419 - val_mse: 0.0021 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 1.1327 - mae: 0.6415 - mse: 0.6638 - val_loss: 0.4708 - val_mae: 0.0395 - val_mse: 0.0019 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.6674 - mae: 0.9023 - mse: 1.1986 - val_loss: 0.4706 - val_mae: 0.0381 - val_mse: 0.0018 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 1.2772 - mae: 0.6865 - mse: 0.8084 - val_loss: 0.4704 - val_mae: 0.0367 - val_mse: 0.0017 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 1.6336 - mae: 0.9234 - mse: 1.1649 - val_loss: 0.4702 - val_mae: 0.0350 - val_mse: 0.0016 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.6285 - mae: 0.9580 - mse: 1.1599 - val_loss: 0.4700 - val_mae: 0.0331 - val_mse: 0.0015 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 1.5634 - mae: 0.5332 - mse: 1.0948 - val_loss: 0.4697 - val_mae: 0.0295 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 1.2848 - mae: 0.6650 - mse: 0.8163 - val_loss: 0.4696 - val_mae: 0.0282 - val_mse: 0.0012 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - loss: 0.9846 - mae: 0.6628 - mse: 0.5162 - val_loss: 0.4693 - val_mae: 0.0261 - val_mse: 0.0010 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.7204 - mae: 0.4606 - mse: 0.2520 - val_loss: 0.4692 - val_mae: 0.0254 - val_mse: 9.6458e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.0104 - mae: 0.5629 - mse: 0.5421 - val_loss: 0.4690 - val_mae: 0.0240 - val_mse: 8.5934e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.8221 - mae: 0.4778 - mse: 0.3539 - val_loss: 0.4689 - val_mae: 0.0228 - val_mse: 7.7185e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 1.8050 - mae: 0.9978 - mse: 1.3369 - val_loss: 0.4688 - val_mae: 0.0222 - val_mse: 7.3426e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.9338 - mae: 0.6586 - mse: 0.4657 - val_loss: 0.4687 - val_mae: 0.0219 - val_mse: 7.1230e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 1.4832 - mae: 0.7791 - mse: 1.0152 - val_loss: 0.4686 - val_mae: 0.0213 - val_mse: 6.4314e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - loss: 1.6621 - mae: 0.9839 - mse: 1.1942 - val_loss: 0.4685 - val_mae: 0.0212 - val_mse: 6.3399e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 1.2584 - mae: 0.8319 - mse: 0.7906 - val_loss: 0.4683 - val_mae: 0.0208 - val_mse: 5.6746e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 1.1856 - mae: 0.7722 - mse: 0.7179 - val_loss: 0.4683 - val_mae: 0.0207 - val_mse: 5.5781e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.7006 - mae: 0.9904 - mse: 1.2329 - val_loss: 0.4681 - val_mae: 0.0204 - val_mse: 5.1876e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.6636 - mae: 0.3549 - mse: 0.1959 - val_loss: 0.4680 - val_mae: 0.0197 - val_mse: 4.5127e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 2.7244 - mae: 1.0498 - mse: 2.2568 - val_loss: 0.4679 - val_mae: 0.0192 - val_mse: 4.2337e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 0.7621 - mae: 0.4924 - mse: 0.2946 - val_loss: 0.4678 - val_mae: 0.0187 - val_mse: 4.0333e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.7956 - mae: 0.4756 - mse: 0.3281 - val_loss: 0.4678 - val_mae: 0.0184 - val_mse: 3.9810e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.0214 - mae: 0.4960 - mse: 0.5541 - val_loss: 0.4677 - val_mae: 0.0181 - val_mse: 3.9833e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.5395 - mae: 0.8585 - mse: 1.0722 - val_loss: 0.4676 - val_mae: 0.0177 - val_mse: 4.0266e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 0.6199 - mae: 0.2749 - mse: 0.1527 - val_loss: 0.4676 - val_mae: 0.0174 - val_mse: 4.2136e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 1.2092 - mae: 0.7143 - mse: 0.7421 - val_loss: 0.4675 - val_mae: 0.0174 - val_mse: 4.1946e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.9989 - mae: 0.6859 - mse: 0.5318 - val_loss: 0.4675 - val_mae: 0.0179 - val_mse: 4.4643e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 0.9031 - mae: 0.5590 - mse: 0.4361 - val_loss: 0.4675 - val_mae: 0.0183 - val_mse: 4.7756e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - loss: 0.7814 - mae: 0.4941 - mse: 0.3144 - val_loss: 0.4675 - val_mae: 0.0188 - val_mse: 5.3094e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.0942 - mae: 0.6905 - mse: 0.6272 - val_loss: 0.4675 - val_mae: 0.0194 - val_mse: 5.9926e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.0115 - mae: 0.6580 - mse: 0.5446 - val_loss: 0.4675 - val_mae: 0.0199 - val_mse: 6.7628e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 0.8666 - mae: 0.5618 - mse: 0.3998 - val_loss: 0.4675 - val_mae: 0.0215 - val_mse: 7.9282e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - loss: 0.9108 - mae: 0.5589 - mse: 0.4440 - val_loss: 0.4675 - val_mae: 0.0215 - val_mse: 7.8728e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.8951 - mae: 0.4935 - mse: 0.4284 - val_loss: 0.4675 - val_mae: 0.0216 - val_mse: 7.9384e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 0.9033 - mae: 0.5360 - mse: 0.4366 - val_loss: 0.4675 - val_mae: 0.0222 - val_mse: 8.3570e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 0.7551 - mae: 0.4599 - mse: 0.2884 - val_loss: 0.4676 - val_mae: 0.0227 - val_mse: 8.7544e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.6219 - mae: 0.7461 - mse: 1.1552 - val_loss: 0.4676 - val_mae: 0.0229 - val_mse: 8.8817e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 1.1737 - mae: 0.7269 - mse: 0.7071 - val_loss: 0.4676 - val_mae: 0.0233 - val_mse: 9.1977e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.3636 - mae: 0.7837 - mse: 0.8969 - val_loss: 0.4677 - val_mae: 0.0251 - val_mse: 0.0010 - learning_rate: 2.0000e-05\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.9550 - mae: 0.6494 - mse: 0.4883 - val_loss: 0.4678 - val_mae: 0.0266 - val_mse: 0.0011 - learning_rate: 2.0000e-05\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 1.0429 - mae: 0.5880 - mse: 0.5762 - val_loss: 0.4678 - val_mae: 0.0272 - val_mse: 0.0011 - learning_rate: 2.0000e-05\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - loss: 1.0286 - mae: 0.6672 - mse: 0.5619 - val_loss: 0.4678 - val_mae: 0.0275 - val_mse: 0.0012 - learning_rate: 2.0000e-05\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.5762 - mae: 0.7696 - mse: 1.1096 - val_loss: 0.4679 - val_mae: 0.0285 - val_mse: 0.0012 - learning_rate: 1.0000e-05\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.2405 - mae: 0.8293 - mse: 0.7739 - val_loss: 0.4679 - val_mae: 0.0294 - val_mse: 0.0013 - learning_rate: 1.0000e-05\n",
            "Grupo 0 - RMSE: 0.000330, MAE: 0.000270, sMAPE: 2.35%\n",
            "\n",
            "Treinando modelo para grupo etário 1...\n",
            "Grupo 1: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 1.3912 - mae: 0.8796 - mse: 0.9198 - val_loss: 0.4949 - val_mae: 0.1530 - val_mse: 0.0239 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 3.3290 - mae: 1.4128 - mse: 2.8581 - val_loss: 0.4940 - val_mae: 0.1506 - val_mse: 0.0232 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 2.3676 - mae: 1.2088 - mse: 1.8969 - val_loss: 0.4928 - val_mae: 0.1469 - val_mse: 0.0221 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 1.9864 - mae: 0.9574 - mse: 1.5158 - val_loss: 0.4910 - val_mae: 0.1412 - val_mse: 0.0205 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 3.2076 - mae: 1.2510 - mse: 2.7371 - val_loss: 0.4896 - val_mae: 0.1365 - val_mse: 0.0192 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 1.6460 - mae: 0.9558 - mse: 1.1756 - val_loss: 0.4888 - val_mae: 0.1338 - val_mse: 0.0184 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.8001 - mae: 1.0128 - mse: 1.3297 - val_loss: 0.4878 - val_mae: 0.1305 - val_mse: 0.0176 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 3.2675 - mae: 1.3394 - mse: 2.7972 - val_loss: 0.4866 - val_mae: 0.1261 - val_mse: 0.0165 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 2.8805 - mae: 1.4325 - mse: 2.4103 - val_loss: 0.4854 - val_mae: 0.1214 - val_mse: 0.0153 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 2.2585 - mae: 1.2329 - mse: 1.7884 - val_loss: 0.4845 - val_mae: 0.1178 - val_mse: 0.0144 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.3006 - mae: 0.8866 - mse: 0.8305 - val_loss: 0.4831 - val_mae: 0.1120 - val_mse: 0.0131 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 3.1843 - mae: 1.4166 - mse: 2.7143 - val_loss: 0.4824 - val_mae: 0.1090 - val_mse: 0.0124 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 1.9403 - mae: 1.1177 - mse: 1.4703 - val_loss: 0.4812 - val_mae: 0.1040 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.9390 - mae: 0.6636 - mse: 0.4691 - val_loss: 0.4802 - val_mae: 0.0990 - val_mse: 0.0103 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.5187 - mae: 0.9125 - mse: 1.0489 - val_loss: 0.4791 - val_mae: 0.0939 - val_mse: 0.0094 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 2.3876 - mae: 1.1720 - mse: 1.9178 - val_loss: 0.4784 - val_mae: 0.0900 - val_mse: 0.0086 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.5274 - mae: 0.8276 - mse: 1.0576 - val_loss: 0.4775 - val_mae: 0.0854 - val_mse: 0.0078 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 3.0067 - mae: 1.3695 - mse: 2.5371 - val_loss: 0.4770 - val_mae: 0.0826 - val_mse: 0.0073 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 1.6937 - mae: 0.8581 - mse: 1.2241 - val_loss: 0.4764 - val_mae: 0.0793 - val_mse: 0.0068 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 3.1222 - mae: 1.2981 - mse: 2.6526 - val_loss: 0.4759 - val_mae: 0.0763 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 1.3478 - mae: 0.8315 - mse: 0.8782 - val_loss: 0.4753 - val_mae: 0.0727 - val_mse: 0.0058 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.6459 - mae: 0.9781 - mse: 1.1764 - val_loss: 0.4748 - val_mae: 0.0695 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 2.0219 - mae: 1.1943 - mse: 1.5525 - val_loss: 0.4743 - val_mae: 0.0655 - val_mse: 0.0048 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 2.6279 - mae: 1.2641 - mse: 2.1585 - val_loss: 0.4738 - val_mae: 0.0621 - val_mse: 0.0044 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 2.5734 - mae: 1.1189 - mse: 2.1040 - val_loss: 0.4732 - val_mae: 0.0576 - val_mse: 0.0039 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 2.3158 - mae: 1.1715 - mse: 1.8464 - val_loss: 0.4730 - val_mae: 0.0561 - val_mse: 0.0037 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 2.4585 - mae: 1.0680 - mse: 1.9892 - val_loss: 0.4726 - val_mae: 0.0527 - val_mse: 0.0033 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - loss: 2.7809 - mae: 1.1354 - mse: 2.3116 - val_loss: 0.4723 - val_mae: 0.0501 - val_mse: 0.0031 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 2.1205 - mae: 1.1774 - mse: 1.6512 - val_loss: 0.4719 - val_mae: 0.0459 - val_mse: 0.0027 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 1.0856 - mae: 0.6807 - mse: 0.6164 - val_loss: 0.4713 - val_mae: 0.0401 - val_mse: 0.0021 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 3.4424 - mae: 1.4444 - mse: 2.9732 - val_loss: 0.4710 - val_mae: 0.0377 - val_mse: 0.0018 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 2.2178 - mae: 1.0656 - mse: 1.7486 - val_loss: 0.4707 - val_mae: 0.0354 - val_mse: 0.0016 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 2.4305 - mae: 1.1825 - mse: 1.9614 - val_loss: 0.4704 - val_mae: 0.0326 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 1.1271 - mae: 0.6070 - mse: 0.6580 - val_loss: 0.4701 - val_mae: 0.0291 - val_mse: 0.0010 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1.5169 - mae: 0.8953 - mse: 1.0479 - val_loss: 0.4699 - val_mae: 0.0264 - val_mse: 8.4486e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.5499 - mae: 0.8824 - mse: 1.0809 - val_loss: 0.4697 - val_mae: 0.0243 - val_mse: 7.3629e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.7180 - mae: 0.8493 - mse: 1.2490 - val_loss: 0.4696 - val_mae: 0.0220 - val_mse: 6.4765e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.7383 - mae: 1.0249 - mse: 1.2693 - val_loss: 0.4695 - val_mae: 0.0209 - val_mse: 6.0033e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.4902 - mae: 0.8852 - mse: 1.0213 - val_loss: 0.4694 - val_mae: 0.0203 - val_mse: 5.6627e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 1.8521 - mae: 1.0639 - mse: 1.3833 - val_loss: 0.4694 - val_mae: 0.0196 - val_mse: 5.4776e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 2.3497 - mae: 1.0155 - mse: 1.8809 - val_loss: 0.4694 - val_mae: 0.0193 - val_mse: 5.4518e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.9365 - mae: 0.5812 - mse: 0.4677 - val_loss: 0.4693 - val_mae: 0.0185 - val_mse: 5.5585e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 1.7437 - mae: 0.8408 - mse: 1.2749 - val_loss: 0.4693 - val_mae: 0.0190 - val_mse: 6.0183e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.4341 - mae: 0.9344 - mse: 0.9654 - val_loss: 0.4694 - val_mae: 0.0198 - val_mse: 6.7606e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - loss: 1.5531 - mae: 0.8220 - mse: 1.0844 - val_loss: 0.4695 - val_mae: 0.0206 - val_mse: 7.8506e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - loss: 2.1188 - mae: 1.0804 - mse: 1.6501 - val_loss: 0.4695 - val_mae: 0.0212 - val_mse: 8.2776e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - loss: 1.3666 - mae: 0.7852 - mse: 0.8980 - val_loss: 0.4695 - val_mae: 0.0227 - val_mse: 9.1858e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 1.3048 - mae: 0.7640 - mse: 0.8362 - val_loss: 0.4696 - val_mae: 0.0237 - val_mse: 9.8557e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 2.4845 - mae: 1.0094 - mse: 2.0159 - val_loss: 0.4696 - val_mae: 0.0246 - val_mse: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - loss: 2.1365 - mae: 1.0994 - mse: 1.6679 - val_loss: 0.4697 - val_mae: 0.0250 - val_mse: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 2.0804 - mae: 1.1527 - mse: 1.6118 - val_loss: 0.4697 - val_mae: 0.0249 - val_mse: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - loss: 1.4342 - mae: 0.8709 - mse: 0.9656 - val_loss: 0.4697 - val_mae: 0.0260 - val_mse: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 1.1071 - mae: 0.6397 - mse: 0.6385 - val_loss: 0.4698 - val_mae: 0.0266 - val_mse: 0.0012 - learning_rate: 2.0000e-05\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 1.9441 - mae: 0.9889 - mse: 1.4756 - val_loss: 0.4698 - val_mae: 0.0273 - val_mse: 0.0013 - learning_rate: 2.0000e-05\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 1.4044 - mae: 0.8466 - mse: 0.9358 - val_loss: 0.4698 - val_mae: 0.0268 - val_mse: 0.0012 - learning_rate: 2.0000e-05\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 1.3823 - mae: 0.7154 - mse: 0.9137 - val_loss: 0.4698 - val_mae: 0.0272 - val_mse: 0.0012 - learning_rate: 2.0000e-05\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.8338 - mae: 0.4560 - mse: 0.3652 - val_loss: 0.4698 - val_mae: 0.0268 - val_mse: 0.0012 - learning_rate: 2.0000e-05\n",
            "Grupo 1 - RMSE: 0.000016, MAE: 0.000012, sMAPE: 2.60%\n",
            "\n",
            "Treinando modelo para grupo etário 5...\n",
            "Grupo 5: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - loss: 1.3928 - mae: 0.7000 - mse: 0.9216 - val_loss: 0.5576 - val_mae: 0.2929 - val_mse: 0.0868 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - loss: 1.0798 - mae: 0.6637 - mse: 0.6090 - val_loss: 0.5565 - val_mae: 0.2915 - val_mse: 0.0860 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - loss: 1.4629 - mae: 0.8703 - mse: 0.9924 - val_loss: 0.5558 - val_mae: 0.2908 - val_mse: 0.0856 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - loss: 1.1784 - mae: 0.7668 - mse: 0.7081 - val_loss: 0.5548 - val_mae: 0.2895 - val_mse: 0.0848 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 1.8996 - mae: 1.0311 - mse: 1.4296 - val_loss: 0.5541 - val_mae: 0.2886 - val_mse: 0.0843 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 1.3025 - mae: 0.6028 - mse: 0.8327 - val_loss: 0.5530 - val_mae: 0.2868 - val_mse: 0.0833 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.3604 - mae: 0.5541 - mse: 0.8907 - val_loss: 0.5519 - val_mae: 0.2852 - val_mse: 0.0824 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - loss: 1.0169 - mae: 0.6477 - mse: 0.5473 - val_loss: 0.5504 - val_mae: 0.2828 - val_mse: 0.0810 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 0.8844 - mae: 0.4975 - mse: 0.4150 - val_loss: 0.5485 - val_mae: 0.2798 - val_mse: 0.0793 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.8885 - mae: 0.5983 - mse: 0.4193 - val_loss: 0.5474 - val_mae: 0.2780 - val_mse: 0.0783 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.6431 - mae: 0.3186 - mse: 0.1740 - val_loss: 0.5459 - val_mae: 0.2754 - val_mse: 0.0769 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 1.3201 - mae: 0.7251 - mse: 0.8512 - val_loss: 0.5446 - val_mae: 0.2735 - val_mse: 0.0758 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.9864 - mae: 0.5068 - mse: 0.5176 - val_loss: 0.5433 - val_mae: 0.2713 - val_mse: 0.0746 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.4039 - mae: 0.9037 - mse: 0.9352 - val_loss: 0.5418 - val_mae: 0.2688 - val_mse: 0.0733 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.9376 - mae: 0.8547 - mse: 1.4691 - val_loss: 0.5410 - val_mae: 0.2676 - val_mse: 0.0726 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.8798 - mae: 0.4224 - mse: 0.4114 - val_loss: 0.5398 - val_mae: 0.2655 - val_mse: 0.0715 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.2434 - mae: 0.7894 - mse: 0.7752 - val_loss: 0.5394 - val_mae: 0.2650 - val_mse: 0.0712 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.0848 - mae: 0.7033 - mse: 0.6166 - val_loss: 0.5386 - val_mae: 0.2637 - val_mse: 0.0705 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.8579 - mae: 0.5822 - mse: 0.3898 - val_loss: 0.5373 - val_mae: 0.2614 - val_mse: 0.0694 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 1.4595 - mae: 0.9039 - mse: 0.9916 - val_loss: 0.5366 - val_mae: 0.2604 - val_mse: 0.0688 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.4331 - mae: 0.6598 - mse: 0.9653 - val_loss: 0.5353 - val_mae: 0.2580 - val_mse: 0.0676 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 1.1945 - mae: 0.6624 - mse: 0.7267 - val_loss: 0.5345 - val_mae: 0.2566 - val_mse: 0.0669 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.7698 - mae: 0.4144 - mse: 0.3021 - val_loss: 0.5334 - val_mae: 0.2547 - val_mse: 0.0659 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - loss: 1.9811 - mae: 0.9325 - mse: 1.5135 - val_loss: 0.5331 - val_mae: 0.2541 - val_mse: 0.0656 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.8884 - mae: 0.5978 - mse: 0.4210 - val_loss: 0.5325 - val_mae: 0.2531 - val_mse: 0.0651 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.4937 - mae: 0.8865 - mse: 1.0264 - val_loss: 0.5322 - val_mae: 0.2528 - val_mse: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.7634 - mae: 0.4330 - mse: 0.2961 - val_loss: 0.5319 - val_mae: 0.2522 - val_mse: 0.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.2922 - mae: 0.5476 - mse: 0.8251 - val_loss: 0.5309 - val_mae: 0.2505 - val_mse: 0.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 2.0179 - mae: 1.1432 - mse: 1.5508 - val_loss: 0.5301 - val_mae: 0.2491 - val_mse: 0.0631 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 1.5168 - mae: 0.9402 - mse: 1.0498 - val_loss: 0.5296 - val_mae: 0.2481 - val_mse: 0.0626 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.7920 - mae: 0.4275 - mse: 0.3251 - val_loss: 0.5290 - val_mae: 0.2471 - val_mse: 0.0621 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 1.0968 - mae: 0.6898 - mse: 0.6300 - val_loss: 0.5282 - val_mae: 0.2456 - val_mse: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.2516 - mae: 0.5350 - mse: 0.7848 - val_loss: 0.5284 - val_mae: 0.2462 - val_mse: 0.0617 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.3380 - mae: 0.7604 - mse: 0.8712 - val_loss: 0.5283 - val_mae: 0.2461 - val_mse: 0.0616 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 2.1170 - mae: 1.2446 - mse: 1.6503 - val_loss: 0.5280 - val_mae: 0.2456 - val_mse: 0.0614 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.6306 - mae: 1.0008 - mse: 1.1640 - val_loss: 0.5268 - val_mae: 0.2432 - val_mse: 0.0602 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.7337 - mae: 0.4458 - mse: 0.2672 - val_loss: 0.5257 - val_mae: 0.2411 - val_mse: 0.0592 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 0.9073 - mae: 0.5298 - mse: 0.4408 - val_loss: 0.5245 - val_mae: 0.2388 - val_mse: 0.0581 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 1.7975 - mae: 0.9742 - mse: 1.3311 - val_loss: 0.5240 - val_mae: 0.2378 - val_mse: 0.0576 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.2259 - mae: 0.7695 - mse: 0.7595 - val_loss: 0.5229 - val_mae: 0.2355 - val_mse: 0.0565 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 0.7451 - mae: 0.4483 - mse: 0.2788 - val_loss: 0.5230 - val_mae: 0.2359 - val_mse: 0.0567 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 1.5912 - mae: 0.8796 - mse: 1.1249 - val_loss: 0.5226 - val_mae: 0.2352 - val_mse: 0.0564 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.2260 - mae: 0.6963 - mse: 0.7598 - val_loss: 0.5226 - val_mae: 0.2353 - val_mse: 0.0564 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.8557 - mae: 0.5257 - mse: 0.3895 - val_loss: 0.5222 - val_mae: 0.2345 - val_mse: 0.0560 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.2807 - mae: 0.7760 - mse: 0.8146 - val_loss: 0.5213 - val_mae: 0.2328 - val_mse: 0.0553 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.5789 - mae: 0.2763 - mse: 0.1128 - val_loss: 0.5212 - val_mae: 0.2326 - val_mse: 0.0552 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.6999 - mae: 0.3927 - mse: 0.2339 - val_loss: 0.5212 - val_mae: 0.2327 - val_mse: 0.0552 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 1.3808 - mae: 0.6923 - mse: 0.9148 - val_loss: 0.5200 - val_mae: 0.2304 - val_mse: 0.0542 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.9037 - mae: 0.5941 - mse: 0.4378 - val_loss: 0.5194 - val_mae: 0.2290 - val_mse: 0.0535 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.9040 - mae: 0.6472 - mse: 0.4381 - val_loss: 0.5185 - val_mae: 0.2272 - val_mse: 0.0527 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 1.4547 - mae: 0.8638 - mse: 0.9889 - val_loss: 0.5179 - val_mae: 0.2261 - val_mse: 0.0522 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - loss: 1.1576 - mae: 0.7055 - mse: 0.6918 - val_loss: 0.5170 - val_mae: 0.2241 - val_mse: 0.0513 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.9942 - mae: 0.6188 - mse: 0.5285 - val_loss: 0.5155 - val_mae: 0.2210 - val_mse: 0.0499 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - loss: 0.9819 - mae: 0.6426 - mse: 0.5162 - val_loss: 0.5152 - val_mae: 0.2203 - val_mse: 0.0496 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.8068 - mae: 0.4787 - mse: 0.3412 - val_loss: 0.5143 - val_mae: 0.2183 - val_mse: 0.0488 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 0.8440 - mae: 0.4671 - mse: 0.3785 - val_loss: 0.5140 - val_mae: 0.2178 - val_mse: 0.0486 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - loss: 0.9620 - mae: 0.5820 - mse: 0.4965 - val_loss: 0.5129 - val_mae: 0.2155 - val_mse: 0.0476 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step - loss: 0.6481 - mae: 0.3837 - mse: 0.1827 - val_loss: 0.5125 - val_mae: 0.2146 - val_mse: 0.0472 - learning_rate: 5.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 0.7041 - mae: 0.3989 - mse: 0.2387 - val_loss: 0.5120 - val_mae: 0.2134 - val_mse: 0.0467 - learning_rate: 5.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 1.0875 - mae: 0.6823 - mse: 0.6222 - val_loss: 0.5111 - val_mae: 0.2115 - val_mse: 0.0458 - learning_rate: 5.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - loss: 1.0978 - mae: 0.6835 - mse: 0.6325 - val_loss: 0.5106 - val_mae: 0.2104 - val_mse: 0.0454 - learning_rate: 5.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.6430 - mae: 0.3200 - mse: 0.1778 - val_loss: 0.5099 - val_mae: 0.2090 - val_mse: 0.0448 - learning_rate: 5.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 0.9907 - mae: 0.6930 - mse: 0.5256 - val_loss: 0.5091 - val_mae: 0.2073 - val_mse: 0.0441 - learning_rate: 5.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.7310 - mae: 0.3878 - mse: 0.2660 - val_loss: 0.5089 - val_mae: 0.2069 - val_mse: 0.0439 - learning_rate: 5.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 0.6655 - mae: 0.3846 - mse: 0.2005 - val_loss: 0.5081 - val_mae: 0.2049 - val_mse: 0.0431 - learning_rate: 5.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.0016 - mae: 0.6898 - mse: 0.5367 - val_loss: 0.5074 - val_mae: 0.2034 - val_mse: 0.0425 - learning_rate: 5.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.8016 - mae: 0.4420 - mse: 0.3368 - val_loss: 0.5063 - val_mae: 0.2008 - val_mse: 0.0414 - learning_rate: 5.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 0.7033 - mae: 0.4546 - mse: 0.2385 - val_loss: 0.5059 - val_mae: 0.1999 - val_mse: 0.0411 - learning_rate: 5.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.9148 - mae: 0.5204 - mse: 0.4501 - val_loss: 0.5053 - val_mae: 0.1987 - val_mse: 0.0406 - learning_rate: 5.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.6567 - mae: 0.3350 - mse: 0.1920 - val_loss: 0.5053 - val_mae: 0.1988 - val_mse: 0.0407 - learning_rate: 5.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.7759 - mae: 0.4470 - mse: 0.3112 - val_loss: 0.5052 - val_mae: 0.1986 - val_mse: 0.0406 - learning_rate: 5.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 1.0579 - mae: 0.7077 - mse: 0.5933 - val_loss: 0.5038 - val_mae: 0.1954 - val_mse: 0.0393 - learning_rate: 5.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 1.1576 - mae: 0.7638 - mse: 0.6930 - val_loss: 0.5029 - val_mae: 0.1933 - val_mse: 0.0385 - learning_rate: 5.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.6735 - mae: 0.3330 - mse: 0.2091 - val_loss: 0.5028 - val_mae: 0.1930 - val_mse: 0.0384 - learning_rate: 5.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.2756 - mae: 0.6989 - mse: 0.8112 - val_loss: 0.5029 - val_mae: 0.1934 - val_mse: 0.0385 - learning_rate: 5.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.5772 - mae: 0.2673 - mse: 0.1129 - val_loss: 0.5025 - val_mae: 0.1927 - val_mse: 0.0382 - learning_rate: 5.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 0.7670 - mae: 0.4153 - mse: 0.3027 - val_loss: 0.5021 - val_mae: 0.1918 - val_mse: 0.0379 - learning_rate: 5.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.0342 - mae: 0.6019 - mse: 0.5699 - val_loss: 0.5018 - val_mae: 0.1910 - val_mse: 0.0376 - learning_rate: 5.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 0.8792 - mae: 0.5335 - mse: 0.4150 - val_loss: 0.5020 - val_mae: 0.1917 - val_mse: 0.0379 - learning_rate: 5.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.8703 - mae: 0.4847 - mse: 0.4062 - val_loss: 0.5019 - val_mae: 0.1916 - val_mse: 0.0378 - learning_rate: 5.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.7368 - mae: 0.4956 - mse: 0.2727 - val_loss: 0.5017 - val_mae: 0.1914 - val_mse: 0.0377 - learning_rate: 5.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.9972 - mae: 0.5579 - mse: 0.5332 - val_loss: 0.5011 - val_mae: 0.1900 - val_mse: 0.0372 - learning_rate: 5.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.5482 - mae: 0.2346 - mse: 0.0842 - val_loss: 0.5007 - val_mae: 0.1891 - val_mse: 0.0368 - learning_rate: 5.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.8512 - mae: 0.5303 - mse: 0.3873 - val_loss: 0.5004 - val_mae: 0.1885 - val_mse: 0.0366 - learning_rate: 5.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.6563 - mae: 0.3589 - mse: 0.1925 - val_loss: 0.5003 - val_mae: 0.1883 - val_mse: 0.0366 - learning_rate: 5.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 1.0910 - mae: 0.7329 - mse: 0.6273 - val_loss: 0.5002 - val_mae: 0.1881 - val_mse: 0.0365 - learning_rate: 5.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 0.7810 - mae: 0.4723 - mse: 0.3174 - val_loss: 0.5007 - val_mae: 0.1896 - val_mse: 0.0370 - learning_rate: 5.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.5069 - mae: 0.1855 - mse: 0.0433 - val_loss: 0.5008 - val_mae: 0.1901 - val_mse: 0.0372 - learning_rate: 5.0000e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 0.6549 - mae: 0.3930 - mse: 0.1914 - val_loss: 0.5011 - val_mae: 0.1910 - val_mse: 0.0376 - learning_rate: 5.0000e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 0.6868 - mae: 0.4168 - mse: 0.2233 - val_loss: 0.5007 - val_mae: 0.1902 - val_mse: 0.0373 - learning_rate: 5.0000e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 1.1176 - mae: 0.6066 - mse: 0.6542 - val_loss: 0.5009 - val_mae: 0.1910 - val_mse: 0.0375 - learning_rate: 5.0000e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 0.9661 - mae: 0.6196 - mse: 0.5027 - val_loss: 0.5004 - val_mae: 0.1896 - val_mse: 0.0370 - learning_rate: 1.0000e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.6379 - mae: 0.2913 - mse: 0.1745 - val_loss: 0.5010 - val_mae: 0.1911 - val_mse: 0.0376 - learning_rate: 1.0000e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.9183 - mae: 0.6230 - mse: 0.4549 - val_loss: 0.5011 - val_mae: 0.1914 - val_mse: 0.0377 - learning_rate: 1.0000e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 1.1114 - mae: 0.7830 - mse: 0.6480 - val_loss: 0.5007 - val_mae: 0.1906 - val_mse: 0.0374 - learning_rate: 1.0000e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.8369 - mae: 0.4671 - mse: 0.3736 - val_loss: 0.5015 - val_mae: 0.1927 - val_mse: 0.0382 - learning_rate: 1.0000e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.6567 - mae: 0.3535 - mse: 0.1933 - val_loss: 0.5013 - val_mae: 0.1921 - val_mse: 0.0380 - learning_rate: 2.0000e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.5537 - mae: 0.2760 - mse: 0.0903 - val_loss: 0.4999 - val_mae: 0.1885 - val_mse: 0.0366 - learning_rate: 2.0000e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.7861 - mae: 0.4607 - mse: 0.3228 - val_loss: 0.4998 - val_mae: 0.1882 - val_mse: 0.0365 - learning_rate: 2.0000e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.6070 - mae: 0.3013 - mse: 0.1436 - val_loss: 0.5000 - val_mae: 0.1888 - val_mse: 0.0367 - learning_rate: 2.0000e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.1211 - mae: 0.6903 - mse: 0.6578 - val_loss: 0.5000 - val_mae: 0.1887 - val_mse: 0.0366 - learning_rate: 2.0000e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.4430 - mae: 0.6573 - mse: 0.9797 - val_loss: 0.4994 - val_mae: 0.1872 - val_mse: 0.0361 - learning_rate: 2.0000e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 0.8873 - mae: 0.6297 - mse: 0.4239 - val_loss: 0.4991 - val_mae: 0.1863 - val_mse: 0.0358 - learning_rate: 2.0000e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.8865 - mae: 0.5582 - mse: 0.4232 - val_loss: 0.4992 - val_mae: 0.1866 - val_mse: 0.0359 - learning_rate: 2.0000e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 0.9661 - mae: 0.5637 - mse: 0.5027 - val_loss: 0.4986 - val_mae: 0.1850 - val_mse: 0.0353 - learning_rate: 2.0000e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.9332 - mae: 0.5632 - mse: 0.4698 - val_loss: 0.4982 - val_mae: 0.1839 - val_mse: 0.0349 - learning_rate: 2.0000e-05\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 1.3834 - mae: 0.8169 - mse: 0.9200 - val_loss: 0.4985 - val_mae: 0.1847 - val_mse: 0.0352 - learning_rate: 2.0000e-05\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 1.3196 - mae: 0.6957 - mse: 0.8563 - val_loss: 0.4983 - val_mae: 0.1843 - val_mse: 0.0350 - learning_rate: 2.0000e-05\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.5895 - mae: 0.2415 - mse: 0.1262 - val_loss: 0.4980 - val_mae: 0.1834 - val_mse: 0.0347 - learning_rate: 2.0000e-05\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 0.9017 - mae: 0.6312 - mse: 0.4384 - val_loss: 0.4982 - val_mae: 0.1839 - val_mse: 0.0348 - learning_rate: 2.0000e-05\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 0.7684 - mae: 0.4961 - mse: 0.3051 - val_loss: 0.4982 - val_mae: 0.1841 - val_mse: 0.0349 - learning_rate: 2.0000e-05\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.7086 - mae: 0.3997 - mse: 0.2453 - val_loss: 0.4979 - val_mae: 0.1832 - val_mse: 0.0346 - learning_rate: 2.0000e-05\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 0.8375 - mae: 0.4903 - mse: 0.3742 - val_loss: 0.4974 - val_mae: 0.1818 - val_mse: 0.0341 - learning_rate: 2.0000e-05\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.6808 - mae: 0.3427 - mse: 0.2175 - val_loss: 0.4974 - val_mae: 0.1819 - val_mse: 0.0341 - learning_rate: 2.0000e-05\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 1.1269 - mae: 0.5652 - mse: 0.6636 - val_loss: 0.4972 - val_mae: 0.1814 - val_mse: 0.0339 - learning_rate: 2.0000e-05\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.6898 - mae: 0.4125 - mse: 0.2265 - val_loss: 0.4972 - val_mae: 0.1813 - val_mse: 0.0339 - learning_rate: 2.0000e-05\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.7013 - mae: 0.4235 - mse: 0.2380 - val_loss: 0.4971 - val_mae: 0.1811 - val_mse: 0.0338 - learning_rate: 2.0000e-05\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - loss: 1.2585 - mae: 0.5421 - mse: 0.7952 - val_loss: 0.4970 - val_mae: 0.1809 - val_mse: 0.0337 - learning_rate: 2.0000e-05\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.7003 - mae: 0.4204 - mse: 0.2370 - val_loss: 0.4965 - val_mae: 0.1796 - val_mse: 0.0332 - learning_rate: 2.0000e-05\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - loss: 1.4168 - mae: 0.8228 - mse: 0.9535 - val_loss: 0.4959 - val_mae: 0.1777 - val_mse: 0.0326 - learning_rate: 2.0000e-05\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.5391 - mae: 0.2343 - mse: 0.0758 - val_loss: 0.4953 - val_mae: 0.1763 - val_mse: 0.0320 - learning_rate: 2.0000e-05\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 0.8131 - mae: 0.5546 - mse: 0.3498 - val_loss: 0.4950 - val_mae: 0.1753 - val_mse: 0.0317 - learning_rate: 2.0000e-05\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - loss: 0.9252 - mae: 0.5227 - mse: 0.4619 - val_loss: 0.4954 - val_mae: 0.1765 - val_mse: 0.0321 - learning_rate: 2.0000e-05\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.0716 - mae: 0.6348 - mse: 0.6083 - val_loss: 0.4953 - val_mae: 0.1763 - val_mse: 0.0320 - learning_rate: 2.0000e-05\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.6936 - mae: 0.4372 - mse: 0.2303 - val_loss: 0.4949 - val_mae: 0.1753 - val_mse: 0.0317 - learning_rate: 2.0000e-05\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.6277 - mae: 0.3405 - mse: 0.1645 - val_loss: 0.4947 - val_mae: 0.1746 - val_mse: 0.0314 - learning_rate: 2.0000e-05\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.8317 - mae: 0.5113 - mse: 0.3685 - val_loss: 0.4936 - val_mae: 0.1716 - val_mse: 0.0303 - learning_rate: 2.0000e-05\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.1033 - mae: 0.6902 - mse: 0.6400 - val_loss: 0.4939 - val_mae: 0.1725 - val_mse: 0.0306 - learning_rate: 2.0000e-05\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.7987 - mae: 0.3500 - mse: 0.3354 - val_loss: 0.4940 - val_mae: 0.1726 - val_mse: 0.0307 - learning_rate: 2.0000e-05\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.9798 - mae: 0.5484 - mse: 0.5165 - val_loss: 0.4940 - val_mae: 0.1727 - val_mse: 0.0307 - learning_rate: 2.0000e-05\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.7450 - mae: 0.5038 - mse: 0.2817 - val_loss: 0.4948 - val_mae: 0.1750 - val_mse: 0.0315 - learning_rate: 2.0000e-05\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.6594 - mae: 0.4066 - mse: 0.1962 - val_loss: 0.4950 - val_mae: 0.1756 - val_mse: 0.0318 - learning_rate: 2.0000e-05\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.6220 - mae: 0.3541 - mse: 0.1588 - val_loss: 0.4947 - val_mae: 0.1747 - val_mse: 0.0314 - learning_rate: 1.0000e-05\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.6948 - mae: 0.4099 - mse: 0.2316 - val_loss: 0.4942 - val_mae: 0.1735 - val_mse: 0.0310 - learning_rate: 1.0000e-05\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.4329 - mae: 0.7694 - mse: 0.9696 - val_loss: 0.4943 - val_mae: 0.1736 - val_mse: 0.0310 - learning_rate: 1.0000e-05\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.1291 - mae: 0.7251 - mse: 0.6658 - val_loss: 0.4932 - val_mae: 0.1705 - val_mse: 0.0300 - learning_rate: 1.0000e-05\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.4938 - mae: 0.1591 - mse: 0.0305 - val_loss: 0.4940 - val_mae: 0.1728 - val_mse: 0.0307 - learning_rate: 1.0000e-05\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.2220 - mae: 0.6973 - mse: 0.7587 - val_loss: 0.4945 - val_mae: 0.1742 - val_mse: 0.0312 - learning_rate: 1.0000e-05\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.7300 - mae: 0.4629 - mse: 0.2667 - val_loss: 0.4933 - val_mae: 0.1708 - val_mse: 0.0300 - learning_rate: 1.0000e-05\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.5623 - mae: 0.2276 - mse: 0.0990 - val_loss: 0.4931 - val_mae: 0.1703 - val_mse: 0.0299 - learning_rate: 1.0000e-05\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 0.6332 - mae: 0.3219 - mse: 0.1700 - val_loss: 0.4944 - val_mae: 0.1740 - val_mse: 0.0311 - learning_rate: 1.0000e-05\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 0.8381 - mae: 0.4851 - mse: 0.3749 - val_loss: 0.4946 - val_mae: 0.1745 - val_mse: 0.0313 - learning_rate: 1.0000e-05\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 0.6652 - mae: 0.4204 - mse: 0.2020 - val_loss: 0.4952 - val_mae: 0.1763 - val_mse: 0.0319 - learning_rate: 1.0000e-05\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.7484 - mae: 0.4806 - mse: 0.2851 - val_loss: 0.4947 - val_mae: 0.1749 - val_mse: 0.0314 - learning_rate: 1.0000e-05\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.5753 - mae: 0.2974 - mse: 0.1121 - val_loss: 0.4940 - val_mae: 0.1728 - val_mse: 0.0307 - learning_rate: 1.0000e-05\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.9202 - mae: 0.5314 - mse: 0.4569 - val_loss: 0.4938 - val_mae: 0.1723 - val_mse: 0.0305 - learning_rate: 1.0000e-05\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 0.6439 - mae: 0.3648 - mse: 0.1806 - val_loss: 0.4928 - val_mae: 0.1694 - val_mse: 0.0295 - learning_rate: 1.0000e-05\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.6429 - mae: 0.3856 - mse: 0.1796 - val_loss: 0.4932 - val_mae: 0.1705 - val_mse: 0.0299 - learning_rate: 1.0000e-05\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 0.9908 - mae: 0.6253 - mse: 0.5276 - val_loss: 0.4923 - val_mae: 0.1681 - val_mse: 0.0291 - learning_rate: 1.0000e-05\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.2848 - mae: 0.6248 - mse: 0.8216 - val_loss: 0.4918 - val_mae: 0.1666 - val_mse: 0.0286 - learning_rate: 1.0000e-05\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 0.6519 - mae: 0.3461 - mse: 0.1887 - val_loss: 0.4922 - val_mae: 0.1678 - val_mse: 0.0290 - learning_rate: 1.0000e-05\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.6054 - mae: 0.2667 - mse: 0.1421 - val_loss: 0.4920 - val_mae: 0.1672 - val_mse: 0.0288 - learning_rate: 1.0000e-05\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.3710 - mae: 0.9182 - mse: 0.9078 - val_loss: 0.4922 - val_mae: 0.1677 - val_mse: 0.0289 - learning_rate: 1.0000e-05\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.7390 - mae: 0.3690 - mse: 0.2758 - val_loss: 0.4917 - val_mae: 0.1664 - val_mse: 0.0285 - learning_rate: 1.0000e-05\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.6622 - mae: 0.3804 - mse: 0.1990 - val_loss: 0.4915 - val_mae: 0.1656 - val_mse: 0.0283 - learning_rate: 1.0000e-05\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.0041 - mae: 0.7123 - mse: 0.5408 - val_loss: 0.4922 - val_mae: 0.1678 - val_mse: 0.0290 - learning_rate: 1.0000e-05\n",
            "Epoch 157/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 0.6952 - mae: 0.4186 - mse: 0.2319 - val_loss: 0.4923 - val_mae: 0.1682 - val_mse: 0.0291 - learning_rate: 1.0000e-05\n",
            "Epoch 158/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.7932 - mae: 0.4825 - mse: 0.3300 - val_loss: 0.4917 - val_mae: 0.1662 - val_mse: 0.0284 - learning_rate: 1.0000e-05\n",
            "Epoch 159/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.7012 - mae: 0.3727 - mse: 0.2380 - val_loss: 0.4911 - val_mae: 0.1645 - val_mse: 0.0279 - learning_rate: 1.0000e-05\n",
            "Epoch 160/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.6862 - mae: 0.3726 - mse: 0.2230 - val_loss: 0.4913 - val_mae: 0.1652 - val_mse: 0.0281 - learning_rate: 1.0000e-05\n",
            "Epoch 161/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.8190 - mae: 0.5049 - mse: 0.3558 - val_loss: 0.4918 - val_mae: 0.1665 - val_mse: 0.0285 - learning_rate: 1.0000e-05\n",
            "Epoch 162/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.9757 - mae: 0.5173 - mse: 0.5125 - val_loss: 0.4912 - val_mae: 0.1648 - val_mse: 0.0280 - learning_rate: 1.0000e-05\n",
            "Epoch 163/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.6175 - mae: 0.3642 - mse: 0.1543 - val_loss: 0.4910 - val_mae: 0.1644 - val_mse: 0.0278 - learning_rate: 1.0000e-05\n",
            "Epoch 164/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 1.0776 - mae: 0.6520 - mse: 0.6144 - val_loss: 0.4913 - val_mae: 0.1651 - val_mse: 0.0281 - learning_rate: 1.0000e-05\n",
            "Epoch 165/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 0.7510 - mae: 0.4802 - mse: 0.2877 - val_loss: 0.4911 - val_mae: 0.1645 - val_mse: 0.0278 - learning_rate: 1.0000e-05\n",
            "Epoch 166/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - loss: 0.7333 - mae: 0.4551 - mse: 0.2701 - val_loss: 0.4906 - val_mae: 0.1632 - val_mse: 0.0274 - learning_rate: 1.0000e-05\n",
            "Epoch 167/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 0.8520 - mae: 0.4863 - mse: 0.3888 - val_loss: 0.4916 - val_mae: 0.1660 - val_mse: 0.0284 - learning_rate: 1.0000e-05\n",
            "Epoch 168/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.8929 - mae: 0.4740 - mse: 0.4297 - val_loss: 0.4914 - val_mae: 0.1656 - val_mse: 0.0282 - learning_rate: 1.0000e-05\n",
            "Epoch 169/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 0.5408 - mae: 0.2159 - mse: 0.0775 - val_loss: 0.4903 - val_mae: 0.1621 - val_mse: 0.0271 - learning_rate: 1.0000e-05\n",
            "Epoch 170/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.8530 - mae: 0.4479 - mse: 0.3898 - val_loss: 0.4897 - val_mae: 0.1602 - val_mse: 0.0265 - learning_rate: 1.0000e-05\n",
            "Epoch 171/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.5986 - mae: 0.3115 - mse: 0.1354 - val_loss: 0.4900 - val_mae: 0.1612 - val_mse: 0.0268 - learning_rate: 1.0000e-05\n",
            "Epoch 172/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 1.0227 - mae: 0.6407 - mse: 0.5595 - val_loss: 0.4902 - val_mae: 0.1618 - val_mse: 0.0270 - learning_rate: 1.0000e-05\n",
            "Epoch 173/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 0.4812 - mae: 0.0921 - mse: 0.0180 - val_loss: 0.4898 - val_mae: 0.1606 - val_mse: 0.0266 - learning_rate: 1.0000e-05\n",
            "Epoch 174/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 1.0034 - mae: 0.6945 - mse: 0.5402 - val_loss: 0.4900 - val_mae: 0.1611 - val_mse: 0.0268 - learning_rate: 1.0000e-05\n",
            "Epoch 175/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 0.7322 - mae: 0.4911 - mse: 0.2690 - val_loss: 0.4897 - val_mae: 0.1602 - val_mse: 0.0265 - learning_rate: 1.0000e-05\n",
            "Epoch 176/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.8047 - mae: 0.4475 - mse: 0.3415 - val_loss: 0.4895 - val_mae: 0.1597 - val_mse: 0.0263 - learning_rate: 1.0000e-05\n",
            "Epoch 177/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.6343 - mae: 0.3272 - mse: 0.1711 - val_loss: 0.4888 - val_mae: 0.1574 - val_mse: 0.0256 - learning_rate: 1.0000e-05\n",
            "Epoch 178/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 1.1955 - mae: 0.5233 - mse: 0.7323 - val_loss: 0.4879 - val_mae: 0.1547 - val_mse: 0.0247 - learning_rate: 1.0000e-05\n",
            "Epoch 179/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.8657 - mae: 0.5639 - mse: 0.4025 - val_loss: 0.4873 - val_mae: 0.1527 - val_mse: 0.0241 - learning_rate: 1.0000e-05\n",
            "Epoch 180/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.9199 - mae: 0.5838 - mse: 0.4567 - val_loss: 0.4885 - val_mae: 0.1564 - val_mse: 0.0253 - learning_rate: 1.0000e-05\n",
            "Epoch 181/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.6811 - mae: 0.3983 - mse: 0.2179 - val_loss: 0.4882 - val_mae: 0.1557 - val_mse: 0.0251 - learning_rate: 1.0000e-05\n",
            "Epoch 182/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.5586 - mae: 0.2598 - mse: 0.0954 - val_loss: 0.4883 - val_mae: 0.1559 - val_mse: 0.0251 - learning_rate: 1.0000e-05\n",
            "Epoch 183/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.6867 - mae: 0.4129 - mse: 0.2235 - val_loss: 0.4891 - val_mae: 0.1584 - val_mse: 0.0259 - learning_rate: 1.0000e-05\n",
            "Epoch 184/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.7573 - mae: 0.9521 - mse: 1.2941 - val_loss: 0.4898 - val_mae: 0.1605 - val_mse: 0.0266 - learning_rate: 1.0000e-05\n",
            "Epoch 185/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.8228 - mae: 0.5840 - mse: 0.3596 - val_loss: 0.4895 - val_mae: 0.1595 - val_mse: 0.0263 - learning_rate: 1.0000e-05\n",
            "Epoch 186/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.6785 - mae: 0.4231 - mse: 0.2153 - val_loss: 0.4899 - val_mae: 0.1608 - val_mse: 0.0267 - learning_rate: 1.0000e-05\n",
            "Epoch 187/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.6384 - mae: 0.2727 - mse: 0.1753 - val_loss: 0.4896 - val_mae: 0.1601 - val_mse: 0.0265 - learning_rate: 1.0000e-05\n",
            "Epoch 188/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 0.5596 - mae: 0.2956 - mse: 0.0964 - val_loss: 0.4899 - val_mae: 0.1608 - val_mse: 0.0267 - learning_rate: 1.0000e-05\n",
            "Epoch 189/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.9837 - mae: 0.5443 - mse: 0.5205 - val_loss: 0.4896 - val_mae: 0.1600 - val_mse: 0.0264 - learning_rate: 1.0000e-05\n",
            "Epoch 190/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.0461 - mae: 0.5683 - mse: 0.5829 - val_loss: 0.4892 - val_mae: 0.1586 - val_mse: 0.0260 - learning_rate: 1.0000e-05\n",
            "Epoch 191/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.7025 - mae: 0.4403 - mse: 0.2393 - val_loss: 0.4885 - val_mae: 0.1563 - val_mse: 0.0253 - learning_rate: 1.0000e-05\n",
            "Epoch 192/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 0.8299 - mae: 0.5363 - mse: 0.3667 - val_loss: 0.4888 - val_mae: 0.1574 - val_mse: 0.0256 - learning_rate: 1.0000e-05\n",
            "Epoch 193/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 1.2789 - mae: 0.7427 - mse: 0.8157 - val_loss: 0.4884 - val_mae: 0.1561 - val_mse: 0.0252 - learning_rate: 1.0000e-05\n",
            "Epoch 194/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.5481 - mae: 0.2650 - mse: 0.0849 - val_loss: 0.4888 - val_mae: 0.1573 - val_mse: 0.0256 - learning_rate: 1.0000e-05\n",
            "Grupo 5 - RMSE: 0.000024, MAE: 0.000024, sMAPE: 12.56%\n",
            "\n",
            "Treinando modelo para grupo etário 10...\n",
            "Grupo 10: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - loss: 0.9972 - mae: 0.6039 - mse: 0.5303 - val_loss: 0.5095 - val_mae: 0.2030 - val_mse: 0.0430 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592ms/step - loss: 1.2441 - mae: 0.7908 - mse: 0.7777 - val_loss: 0.5083 - val_mae: 0.2004 - val_mse: 0.0420 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 1.8384 - mae: 0.9139 - mse: 1.3722 - val_loss: 0.5056 - val_mae: 0.1939 - val_mse: 0.0394 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 1.1732 - mae: 0.6782 - mse: 0.7071 - val_loss: 0.5040 - val_mae: 0.1899 - val_mse: 0.0379 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: 2.8327 - mae: 1.3620 - mse: 2.3666 - val_loss: 0.5023 - val_mae: 0.1858 - val_mse: 0.0363 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 2.0275 - mae: 1.2138 - mse: 1.5615 - val_loss: 0.5012 - val_mae: 0.1829 - val_mse: 0.0353 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 2.1026 - mae: 1.1409 - mse: 1.6367 - val_loss: 0.4999 - val_mae: 0.1797 - val_mse: 0.0341 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 0.8529 - mae: 0.5633 - mse: 0.3871 - val_loss: 0.4990 - val_mae: 0.1772 - val_mse: 0.0332 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.4263 - mae: 0.8256 - mse: 0.9605 - val_loss: 0.4985 - val_mae: 0.1758 - val_mse: 0.0327 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 1.8515 - mae: 0.9580 - mse: 1.3858 - val_loss: 0.4976 - val_mae: 0.1735 - val_mse: 0.0319 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 2.1888 - mae: 0.9973 - mse: 1.7231 - val_loss: 0.4970 - val_mae: 0.1718 - val_mse: 0.0313 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 1.4153 - mae: 0.6751 - mse: 0.9497 - val_loss: 0.4961 - val_mae: 0.1695 - val_mse: 0.0305 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 1.1332 - mae: 0.7243 - mse: 0.6676 - val_loss: 0.4960 - val_mae: 0.1692 - val_mse: 0.0304 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.9903 - mae: 0.5539 - mse: 0.5248 - val_loss: 0.4957 - val_mae: 0.1685 - val_mse: 0.0302 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.6178 - mae: 0.3388 - mse: 0.1523 - val_loss: 0.4949 - val_mae: 0.1663 - val_mse: 0.0294 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.8472 - mae: 0.5269 - mse: 0.3817 - val_loss: 0.4941 - val_mae: 0.1641 - val_mse: 0.0287 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.9680 - mae: 0.6522 - mse: 0.5026 - val_loss: 0.4939 - val_mae: 0.1634 - val_mse: 0.0285 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 1.9462 - mae: 1.0010 - mse: 1.4808 - val_loss: 0.4934 - val_mae: 0.1622 - val_mse: 0.0281 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.9090 - mae: 0.5408 - mse: 0.4436 - val_loss: 0.4932 - val_mae: 0.1615 - val_mse: 0.0279 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.9897 - mae: 0.5686 - mse: 0.5244 - val_loss: 0.4926 - val_mae: 0.1599 - val_mse: 0.0274 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 1.9953 - mae: 1.0415 - mse: 1.5301 - val_loss: 0.4922 - val_mae: 0.1589 - val_mse: 0.0271 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 1.8088 - mae: 0.9296 - mse: 1.3436 - val_loss: 0.4921 - val_mae: 0.1587 - val_mse: 0.0270 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 1.8336 - mae: 0.8247 - mse: 1.3685 - val_loss: 0.4918 - val_mae: 0.1577 - val_mse: 0.0267 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 1.1110 - mae: 0.7825 - mse: 0.6459 - val_loss: 0.4910 - val_mae: 0.1555 - val_mse: 0.0260 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.9601 - mae: 0.6047 - mse: 0.4950 - val_loss: 0.4905 - val_mae: 0.1539 - val_mse: 0.0255 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.9031 - mae: 0.9953 - mse: 1.4381 - val_loss: 0.4898 - val_mae: 0.1517 - val_mse: 0.0248 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 1.4200 - mae: 0.6671 - mse: 0.9550 - val_loss: 0.4893 - val_mae: 0.1504 - val_mse: 0.0244 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.8688 - mae: 0.9382 - mse: 1.4039 - val_loss: 0.4895 - val_mae: 0.1512 - val_mse: 0.0247 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.0144 - mae: 0.6266 - mse: 0.5495 - val_loss: 0.4896 - val_mae: 0.1514 - val_mse: 0.0247 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.9647 - mae: 0.5512 - mse: 0.4998 - val_loss: 0.4893 - val_mae: 0.1507 - val_mse: 0.0245 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.5298 - mae: 0.8642 - mse: 1.0650 - val_loss: 0.4894 - val_mae: 0.1510 - val_mse: 0.0246 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 1.6919 - mae: 1.0367 - mse: 1.2271 - val_loss: 0.4888 - val_mae: 0.1493 - val_mse: 0.0241 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 1.7456 - mae: 0.9801 - mse: 1.2809 - val_loss: 0.4884 - val_mae: 0.1478 - val_mse: 0.0237 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 2.6621 - mae: 0.9100 - mse: 2.1974 - val_loss: 0.4874 - val_mae: 0.1448 - val_mse: 0.0228 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 1.4604 - mae: 0.8166 - mse: 0.9957 - val_loss: 0.4869 - val_mae: 0.1430 - val_mse: 0.0223 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 1.3322 - mae: 0.8167 - mse: 0.8676 - val_loss: 0.4860 - val_mae: 0.1401 - val_mse: 0.0215 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 2.9905 - mae: 1.4191 - mse: 2.5259 - val_loss: 0.4855 - val_mae: 0.1382 - val_mse: 0.0209 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 3.0259 - mae: 1.1799 - mse: 2.5614 - val_loss: 0.4850 - val_mae: 0.1364 - val_mse: 0.0205 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 1.8474 - mae: 1.1233 - mse: 1.3829 - val_loss: 0.4845 - val_mae: 0.1349 - val_mse: 0.0200 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 1.2896 - mae: 0.7323 - mse: 0.8251 - val_loss: 0.4841 - val_mae: 0.1335 - val_mse: 0.0197 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.9529 - mae: 0.4437 - mse: 0.4885 - val_loss: 0.4837 - val_mae: 0.1320 - val_mse: 0.0193 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.9636 - mae: 0.6086 - mse: 0.4992 - val_loss: 0.4831 - val_mae: 0.1298 - val_mse: 0.0187 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 1.1164 - mae: 0.7505 - mse: 0.6521 - val_loss: 0.4829 - val_mae: 0.1292 - val_mse: 0.0186 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.4233 - mae: 0.8150 - mse: 0.9590 - val_loss: 0.4825 - val_mae: 0.1278 - val_mse: 0.0182 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.9739 - mae: 0.6656 - mse: 0.5096 - val_loss: 0.4826 - val_mae: 0.1281 - val_mse: 0.0183 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 1.2989 - mae: 0.8375 - mse: 0.8346 - val_loss: 0.4826 - val_mae: 0.1283 - val_mse: 0.0184 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - loss: 1.4092 - mae: 0.8043 - mse: 0.9450 - val_loss: 0.4824 - val_mae: 0.1277 - val_mse: 0.0182 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.4707 - mae: 0.7778 - mse: 1.0065 - val_loss: 0.4823 - val_mae: 0.1272 - val_mse: 0.0181 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.6629 - mae: 0.3643 - mse: 0.1987 - val_loss: 0.4824 - val_mae: 0.1279 - val_mse: 0.0183 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 0.8311 - mae: 0.5280 - mse: 0.3669 - val_loss: 0.4823 - val_mae: 0.1277 - val_mse: 0.0182 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.0650 - mae: 0.6095 - mse: 0.6008 - val_loss: 0.4823 - val_mae: 0.1274 - val_mse: 0.0182 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.0406 - mae: 0.5880 - mse: 0.5765 - val_loss: 0.4820 - val_mae: 0.1265 - val_mse: 0.0179 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.8248 - mae: 0.5204 - mse: 0.3607 - val_loss: 0.4819 - val_mae: 0.1262 - val_mse: 0.0179 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.9258 - mae: 0.4204 - mse: 0.4618 - val_loss: 0.4814 - val_mae: 0.1245 - val_mse: 0.0174 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.7055 - mae: 0.4780 - mse: 0.2415 - val_loss: 0.4815 - val_mae: 0.1247 - val_mse: 0.0175 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.7186 - mae: 0.4374 - mse: 0.2546 - val_loss: 0.4814 - val_mae: 0.1247 - val_mse: 0.0175 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.6029 - mae: 0.9130 - mse: 1.1389 - val_loss: 0.4813 - val_mae: 0.1244 - val_mse: 0.0174 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step - loss: 0.9302 - mae: 0.5999 - mse: 0.4663 - val_loss: 0.4811 - val_mae: 0.1235 - val_mse: 0.0172 - learning_rate: 5.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 1.1440 - mae: 0.6246 - mse: 0.6801 - val_loss: 0.4803 - val_mae: 0.1203 - val_mse: 0.0164 - learning_rate: 5.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - loss: 0.7569 - mae: 0.4312 - mse: 0.2930 - val_loss: 0.4797 - val_mae: 0.1183 - val_mse: 0.0159 - learning_rate: 5.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 0.6053 - mae: 0.3371 - mse: 0.1415 - val_loss: 0.4793 - val_mae: 0.1165 - val_mse: 0.0155 - learning_rate: 5.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 1.3229 - mae: 0.7533 - mse: 0.8591 - val_loss: 0.4791 - val_mae: 0.1156 - val_mse: 0.0153 - learning_rate: 5.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 0.8432 - mae: 0.4890 - mse: 0.3794 - val_loss: 0.4788 - val_mae: 0.1146 - val_mse: 0.0150 - learning_rate: 5.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.1311 - mae: 0.6812 - mse: 0.6674 - val_loss: 0.4788 - val_mae: 0.1149 - val_mse: 0.0151 - learning_rate: 5.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.7804 - mae: 0.4389 - mse: 0.3167 - val_loss: 0.4786 - val_mae: 0.1139 - val_mse: 0.0149 - learning_rate: 5.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 1.1632 - mae: 0.7871 - mse: 0.6995 - val_loss: 0.4782 - val_mae: 0.1125 - val_mse: 0.0146 - learning_rate: 5.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.6649 - mae: 0.3814 - mse: 0.2013 - val_loss: 0.4775 - val_mae: 0.1093 - val_mse: 0.0139 - learning_rate: 5.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 1.2413 - mae: 0.7601 - mse: 0.7777 - val_loss: 0.4772 - val_mae: 0.1081 - val_mse: 0.0136 - learning_rate: 5.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.9831 - mae: 0.9988 - mse: 1.5195 - val_loss: 0.4767 - val_mae: 0.1060 - val_mse: 0.0132 - learning_rate: 5.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 1.4133 - mae: 0.9118 - mse: 0.9498 - val_loss: 0.4762 - val_mae: 0.1037 - val_mse: 0.0127 - learning_rate: 5.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 1.1098 - mae: 0.7037 - mse: 0.6463 - val_loss: 0.4763 - val_mae: 0.1039 - val_mse: 0.0127 - learning_rate: 5.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.6657 - mae: 0.3756 - mse: 0.2022 - val_loss: 0.4759 - val_mae: 0.1021 - val_mse: 0.0124 - learning_rate: 5.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 1.0521 - mae: 0.6905 - mse: 0.5887 - val_loss: 0.4758 - val_mae: 0.1019 - val_mse: 0.0123 - learning_rate: 5.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 0.7303 - mae: 0.4350 - mse: 0.2669 - val_loss: 0.4751 - val_mae: 0.0988 - val_mse: 0.0117 - learning_rate: 5.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.6974 - mae: 0.9837 - mse: 1.2340 - val_loss: 0.4748 - val_mae: 0.0974 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 1.1882 - mae: 0.7610 - mse: 0.7248 - val_loss: 0.4749 - val_mae: 0.0980 - val_mse: 0.0115 - learning_rate: 5.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 1.0847 - mae: 0.7313 - mse: 0.6214 - val_loss: 0.4746 - val_mae: 0.0966 - val_mse: 0.0113 - learning_rate: 5.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - loss: 0.9163 - mae: 0.5745 - mse: 0.4530 - val_loss: 0.4742 - val_mae: 0.0942 - val_mse: 0.0108 - learning_rate: 5.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 1.2237 - mae: 0.6545 - mse: 0.7604 - val_loss: 0.4735 - val_mae: 0.0907 - val_mse: 0.0102 - learning_rate: 5.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 1.6757 - mae: 1.0334 - mse: 1.2124 - val_loss: 0.4732 - val_mae: 0.0896 - val_mse: 0.0100 - learning_rate: 5.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 0.7321 - mae: 0.4536 - mse: 0.2688 - val_loss: 0.4729 - val_mae: 0.0881 - val_mse: 0.0097 - learning_rate: 5.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 2.0191 - mae: 1.1714 - mse: 1.5559 - val_loss: 0.4730 - val_mae: 0.0886 - val_mse: 0.0098 - learning_rate: 5.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 1.2809 - mae: 0.7661 - mse: 0.8177 - val_loss: 0.4726 - val_mae: 0.0863 - val_mse: 0.0094 - learning_rate: 5.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 1.3898 - mae: 0.9299 - mse: 0.9266 - val_loss: 0.4722 - val_mae: 0.0845 - val_mse: 0.0091 - learning_rate: 5.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 1.1298 - mae: 0.7516 - mse: 0.6666 - val_loss: 0.4717 - val_mae: 0.0816 - val_mse: 0.0086 - learning_rate: 5.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.7080 - mae: 0.4419 - mse: 0.2449 - val_loss: 0.4715 - val_mae: 0.0804 - val_mse: 0.0084 - learning_rate: 5.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1.0295 - mae: 0.6319 - mse: 0.5665 - val_loss: 0.4712 - val_mae: 0.0787 - val_mse: 0.0082 - learning_rate: 5.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.9046 - mae: 0.5675 - mse: 0.4416 - val_loss: 0.4708 - val_mae: 0.0764 - val_mse: 0.0078 - learning_rate: 5.0000e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.7084 - mae: 0.3502 - mse: 0.2454 - val_loss: 0.4705 - val_mae: 0.0740 - val_mse: 0.0074 - learning_rate: 5.0000e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1.3861 - mae: 0.8353 - mse: 0.9231 - val_loss: 0.4700 - val_mae: 0.0712 - val_mse: 0.0070 - learning_rate: 5.0000e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.9704 - mae: 0.5724 - mse: 0.5074 - val_loss: 0.4697 - val_mae: 0.0687 - val_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.2904 - mae: 0.6408 - mse: 0.8274 - val_loss: 0.4696 - val_mae: 0.0685 - val_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 1.0910 - mae: 0.6639 - mse: 0.6281 - val_loss: 0.4695 - val_mae: 0.0681 - val_mse: 0.0066 - learning_rate: 5.0000e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 0.8455 - mae: 0.5166 - mse: 0.3826 - val_loss: 0.4694 - val_mae: 0.0678 - val_mse: 0.0066 - learning_rate: 5.0000e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1.3228 - mae: 0.8153 - mse: 0.8600 - val_loss: 0.4692 - val_mae: 0.0662 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 1.0188 - mae: 0.5998 - mse: 0.5559 - val_loss: 0.4691 - val_mae: 0.0651 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.8852 - mae: 0.6181 - mse: 0.4224 - val_loss: 0.4689 - val_mae: 0.0641 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.7075 - mae: 0.3824 - mse: 0.2447 - val_loss: 0.4690 - val_mae: 0.0648 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 1.9454 - mae: 1.0359 - mse: 1.4826 - val_loss: 0.4687 - val_mae: 0.0634 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.4670 - mae: 0.8246 - mse: 1.0043 - val_loss: 0.4687 - val_mae: 0.0630 - val_mse: 0.0059 - learning_rate: 5.0000e-04\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 0.8047 - mae: 0.5543 - mse: 0.3419 - val_loss: 0.4685 - val_mae: 0.0623 - val_mse: 0.0058 - learning_rate: 5.0000e-04\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - loss: 0.8785 - mae: 0.4906 - mse: 0.4157 - val_loss: 0.4683 - val_mae: 0.0615 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 1.7682 - mae: 1.0215 - mse: 1.3055 - val_loss: 0.4683 - val_mae: 0.0614 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.6234 - mae: 0.3402 - mse: 0.1607 - val_loss: 0.4681 - val_mae: 0.0606 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.0120 - mae: 0.5735 - mse: 0.5494 - val_loss: 0.4681 - val_mae: 0.0608 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.0751 - mae: 0.7054 - mse: 0.6125 - val_loss: 0.4681 - val_mae: 0.0611 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - loss: 0.7998 - mae: 0.5103 - mse: 0.3372 - val_loss: 0.4682 - val_mae: 0.0614 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 1.1204 - mae: 0.7549 - mse: 0.6578 - val_loss: 0.4681 - val_mae: 0.0614 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - loss: 1.1621 - mae: 0.7775 - mse: 0.6995 - val_loss: 0.4683 - val_mae: 0.0622 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.7917 - mae: 0.4810 - mse: 0.3292 - val_loss: 0.4681 - val_mae: 0.0612 - val_mse: 0.0055 - learning_rate: 1.0000e-04\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 0.7293 - mae: 0.4274 - mse: 0.2668 - val_loss: 0.4680 - val_mae: 0.0608 - val_mse: 0.0055 - learning_rate: 1.0000e-04\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - loss: 1.3882 - mae: 0.7520 - mse: 0.9257 - val_loss: 0.4679 - val_mae: 0.0604 - val_mse: 0.0054 - learning_rate: 1.0000e-04\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.0078 - mae: 0.6373 - mse: 0.5453 - val_loss: 0.4679 - val_mae: 0.0604 - val_mse: 0.0054 - learning_rate: 1.0000e-04\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 0.8355 - mae: 0.5449 - mse: 0.3730 - val_loss: 0.4676 - val_mae: 0.0588 - val_mse: 0.0051 - learning_rate: 1.0000e-04\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 0.6808 - mae: 0.4003 - mse: 0.2183 - val_loss: 0.4673 - val_mae: 0.0574 - val_mse: 0.0048 - learning_rate: 1.0000e-04\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 1.0116 - mae: 0.6032 - mse: 0.5492 - val_loss: 0.4671 - val_mae: 0.0566 - val_mse: 0.0047 - learning_rate: 1.0000e-04\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 1.6110 - mae: 0.8002 - mse: 1.1485 - val_loss: 0.4668 - val_mae: 0.0548 - val_mse: 0.0044 - learning_rate: 1.0000e-04\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 0.6127 - mae: 0.2942 - mse: 0.1502 - val_loss: 0.4667 - val_mae: 0.0537 - val_mse: 0.0042 - learning_rate: 1.0000e-04\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 0.6631 - mae: 0.3978 - mse: 0.2006 - val_loss: 0.4665 - val_mae: 0.0527 - val_mse: 0.0040 - learning_rate: 1.0000e-04\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.6359 - mae: 0.3596 - mse: 0.1734 - val_loss: 0.4663 - val_mae: 0.0515 - val_mse: 0.0039 - learning_rate: 1.0000e-04\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.6792 - mae: 0.3581 - mse: 0.2168 - val_loss: 0.4661 - val_mae: 0.0499 - val_mse: 0.0037 - learning_rate: 1.0000e-04\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 0.8468 - mae: 0.5594 - mse: 0.3843 - val_loss: 0.4661 - val_mae: 0.0497 - val_mse: 0.0036 - learning_rate: 1.0000e-04\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.2518 - mae: 0.7609 - mse: 0.7894 - val_loss: 0.4659 - val_mae: 0.0484 - val_mse: 0.0035 - learning_rate: 1.0000e-04\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 2.2534 - mae: 1.1807 - mse: 1.7910 - val_loss: 0.4656 - val_mae: 0.0463 - val_mse: 0.0032 - learning_rate: 1.0000e-04\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.9354 - mae: 0.6187 - mse: 0.4730 - val_loss: 0.4655 - val_mae: 0.0454 - val_mse: 0.0031 - learning_rate: 1.0000e-04\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.7741 - mae: 0.5559 - mse: 0.3117 - val_loss: 0.4655 - val_mae: 0.0450 - val_mse: 0.0031 - learning_rate: 1.0000e-04\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.9343 - mae: 0.5197 - mse: 0.4719 - val_loss: 0.4654 - val_mae: 0.0445 - val_mse: 0.0030 - learning_rate: 1.0000e-04\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.8479 - mae: 0.5296 - mse: 0.3855 - val_loss: 0.4653 - val_mae: 0.0433 - val_mse: 0.0029 - learning_rate: 1.0000e-04\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.6029 - mae: 0.3098 - mse: 0.1405 - val_loss: 0.4652 - val_mae: 0.0430 - val_mse: 0.0028 - learning_rate: 1.0000e-04\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 0.7852 - mae: 0.4697 - mse: 0.3229 - val_loss: 0.4651 - val_mae: 0.0428 - val_mse: 0.0027 - learning_rate: 1.0000e-04\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.5201 - mae: 0.2030 - mse: 0.0577 - val_loss: 0.4650 - val_mae: 0.0423 - val_mse: 0.0026 - learning_rate: 1.0000e-04\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.7912 - mae: 0.4406 - mse: 0.3288 - val_loss: 0.4648 - val_mae: 0.0414 - val_mse: 0.0024 - learning_rate: 1.0000e-04\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.5539 - mae: 0.2607 - mse: 0.0916 - val_loss: 0.4648 - val_mae: 0.0413 - val_mse: 0.0024 - learning_rate: 1.0000e-04\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.0972 - mae: 0.6619 - mse: 0.6348 - val_loss: 0.4648 - val_mae: 0.0416 - val_mse: 0.0025 - learning_rate: 1.0000e-04\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.7485 - mae: 0.7165 - mse: 1.2862 - val_loss: 0.4648 - val_mae: 0.0416 - val_mse: 0.0025 - learning_rate: 1.0000e-04\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.9353 - mae: 0.5143 - mse: 0.4730 - val_loss: 0.4648 - val_mae: 0.0415 - val_mse: 0.0025 - learning_rate: 1.0000e-04\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.4762 - mae: 0.9472 - mse: 1.0139 - val_loss: 0.4647 - val_mae: 0.0413 - val_mse: 0.0024 - learning_rate: 1.0000e-04\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 0.8016 - mae: 0.5074 - mse: 0.3393 - val_loss: 0.4647 - val_mae: 0.0410 - val_mse: 0.0024 - learning_rate: 2.0000e-05\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 1.1360 - mae: 0.7069 - mse: 0.6736 - val_loss: 0.4647 - val_mae: 0.0409 - val_mse: 0.0024 - learning_rate: 2.0000e-05\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 0.7696 - mae: 0.3776 - mse: 0.3073 - val_loss: 0.4647 - val_mae: 0.0406 - val_mse: 0.0024 - learning_rate: 2.0000e-05\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.9882 - mae: 0.5012 - mse: 0.5259 - val_loss: 0.4647 - val_mae: 0.0401 - val_mse: 0.0024 - learning_rate: 2.0000e-05\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.7851 - mae: 0.4888 - mse: 0.3228 - val_loss: 0.4647 - val_mae: 0.0398 - val_mse: 0.0024 - learning_rate: 2.0000e-05\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.7060 - mae: 0.4693 - mse: 0.2437 - val_loss: 0.4647 - val_mae: 0.0394 - val_mse: 0.0024 - learning_rate: 2.0000e-05\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - loss: 0.7015 - mae: 0.3838 - mse: 0.2391 - val_loss: 0.4647 - val_mae: 0.0390 - val_mse: 0.0024 - learning_rate: 2.0000e-05\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 1.1294 - mae: 0.6018 - mse: 0.6671 - val_loss: 0.4648 - val_mae: 0.0386 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.0994 - mae: 0.6892 - mse: 0.6371 - val_loss: 0.4648 - val_mae: 0.0389 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.1535 - mae: 0.6579 - mse: 0.6911 - val_loss: 0.4649 - val_mae: 0.0391 - val_mse: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.2976 - mae: 0.8088 - mse: 0.8353 - val_loss: 0.4650 - val_mae: 0.0397 - val_mse: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.5545 - mae: 0.2582 - mse: 0.0922 - val_loss: 0.4650 - val_mae: 0.0399 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1.5304 - mae: 0.7919 - mse: 1.0681 - val_loss: 0.4651 - val_mae: 0.0410 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.5810 - mae: 0.8276 - mse: 1.1187 - val_loss: 0.4652 - val_mae: 0.0425 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.5710 - mae: 0.2397 - mse: 0.1087 - val_loss: 0.4653 - val_mae: 0.0445 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.5999 - mae: 0.2855 - mse: 0.1376 - val_loss: 0.4655 - val_mae: 0.0463 - val_mse: 0.0032 - learning_rate: 1.0000e-05\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 0.8983 - mae: 0.5238 - mse: 0.4360 - val_loss: 0.4656 - val_mae: 0.0474 - val_mse: 0.0033 - learning_rate: 1.0000e-05\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 1.1227 - mae: 0.7401 - mse: 0.6604 - val_loss: 0.4657 - val_mae: 0.0490 - val_mse: 0.0034 - learning_rate: 1.0000e-05\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.9679 - mae: 0.7053 - mse: 0.5056 - val_loss: 0.4658 - val_mae: 0.0500 - val_mse: 0.0035 - learning_rate: 1.0000e-05\n",
            "Grupo 10 - RMSE: 0.000006, MAE: 0.000005, sMAPE: 1.94%\n",
            "\n",
            "Treinando modelo para grupo etário 15...\n",
            "Grupo 15: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3.4902 - mae: 1.4074 - mse: 3.0177 - val_loss: 0.5504 - val_mae: 0.2700 - val_mse: 0.0783 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 1.8761 - mae: 1.0562 - mse: 1.4041 - val_loss: 0.5474 - val_mae: 0.2648 - val_mse: 0.0756 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 3.6508 - mae: 1.3478 - mse: 3.1790 - val_loss: 0.5449 - val_mae: 0.2603 - val_mse: 0.0732 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 3.1579 - mae: 1.4137 - mse: 2.6862 - val_loss: 0.5426 - val_mae: 0.2561 - val_mse: 0.0710 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.6137 - mae: 1.0157 - mse: 1.1421 - val_loss: 0.5406 - val_mae: 0.2522 - val_mse: 0.0690 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 4.6335 - mae: 1.8270 - mse: 4.1619 - val_loss: 0.5386 - val_mae: 0.2483 - val_mse: 0.0671 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 2.6369 - mae: 1.2738 - mse: 2.1653 - val_loss: 0.5364 - val_mae: 0.2437 - val_mse: 0.0649 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 2.5809 - mae: 1.3545 - mse: 2.1095 - val_loss: 0.5344 - val_mae: 0.2397 - val_mse: 0.0630 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 5.1239 - mae: 1.9382 - mse: 4.6524 - val_loss: 0.5322 - val_mae: 0.2352 - val_mse: 0.0608 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 4.3452 - mae: 1.6719 - mse: 3.8738 - val_loss: 0.5292 - val_mae: 0.2288 - val_mse: 0.0579 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 1.4481 - mae: 0.7326 - mse: 0.9767 - val_loss: 0.5268 - val_mae: 0.2236 - val_mse: 0.0555 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 3.5303 - mae: 1.4974 - mse: 3.0590 - val_loss: 0.5246 - val_mae: 0.2187 - val_mse: 0.0533 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 2.1063 - mae: 1.1123 - mse: 1.6350 - val_loss: 0.5221 - val_mae: 0.2129 - val_mse: 0.0508 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 2.7509 - mae: 1.2130 - mse: 2.2797 - val_loss: 0.5199 - val_mae: 0.2079 - val_mse: 0.0487 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 4.1107 - mae: 1.7080 - mse: 3.6394 - val_loss: 0.5180 - val_mae: 0.2034 - val_mse: 0.0468 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 5.2625 - mae: 2.0615 - mse: 4.7913 - val_loss: 0.5158 - val_mae: 0.1978 - val_mse: 0.0446 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 2.2929 - mae: 0.9126 - mse: 1.8218 - val_loss: 0.5140 - val_mae: 0.1935 - val_mse: 0.0429 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 3.1388 - mae: 1.2541 - mse: 2.6677 - val_loss: 0.5119 - val_mae: 0.1878 - val_mse: 0.0408 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 2.5395 - mae: 1.1291 - mse: 2.0684 - val_loss: 0.5094 - val_mae: 0.1813 - val_mse: 0.0383 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 3.0722 - mae: 1.4756 - mse: 2.6012 - val_loss: 0.5076 - val_mae: 0.1763 - val_mse: 0.0365 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 3.5935 - mae: 1.3701 - mse: 3.1225 - val_loss: 0.5054 - val_mae: 0.1703 - val_mse: 0.0344 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 5.5352 - mae: 1.8095 - mse: 5.0642 - val_loss: 0.5034 - val_mae: 0.1644 - val_mse: 0.0325 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 2.3981 - mae: 1.2668 - mse: 1.9271 - val_loss: 0.5017 - val_mae: 0.1593 - val_mse: 0.0308 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 2.1129 - mae: 1.1672 - mse: 1.6419 - val_loss: 0.4999 - val_mae: 0.1536 - val_mse: 0.0290 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 1.8371 - mae: 0.8888 - mse: 1.3661 - val_loss: 0.4983 - val_mae: 0.1485 - val_mse: 0.0274 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 3.8002 - mae: 1.7829 - mse: 3.3293 - val_loss: 0.4972 - val_mae: 0.1448 - val_mse: 0.0263 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 2.5757 - mae: 1.2678 - mse: 2.1048 - val_loss: 0.4959 - val_mae: 0.1403 - val_mse: 0.0250 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 2.6896 - mae: 1.3192 - mse: 2.2187 - val_loss: 0.4947 - val_mae: 0.1360 - val_mse: 0.0239 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 2.0122 - mae: 1.0516 - mse: 1.5414 - val_loss: 0.4934 - val_mae: 0.1310 - val_mse: 0.0225 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 1.9539 - mae: 1.0567 - mse: 1.4831 - val_loss: 0.4922 - val_mae: 0.1266 - val_mse: 0.0214 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1.3111 - mae: 0.8697 - mse: 0.8403 - val_loss: 0.4909 - val_mae: 0.1216 - val_mse: 0.0202 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - loss: 1.4940 - mae: 0.8461 - mse: 1.0232 - val_loss: 0.4900 - val_mae: 0.1179 - val_mse: 0.0193 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 2.5104 - mae: 1.0067 - mse: 2.0397 - val_loss: 0.4890 - val_mae: 0.1136 - val_mse: 0.0183 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.9202 - mae: 0.4758 - mse: 0.4495 - val_loss: 0.4880 - val_mae: 0.1095 - val_mse: 0.0172 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 2.4334 - mae: 0.9275 - mse: 1.9627 - val_loss: 0.4867 - val_mae: 0.1059 - val_mse: 0.0160 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 2.1581 - mae: 1.1744 - mse: 1.6874 - val_loss: 0.4857 - val_mae: 0.1031 - val_mse: 0.0150 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 2.9732 - mae: 1.3852 - mse: 2.5025 - val_loss: 0.4844 - val_mae: 0.0989 - val_mse: 0.0137 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 1.5021 - mae: 0.9299 - mse: 1.0314 - val_loss: 0.4835 - val_mae: 0.0962 - val_mse: 0.0129 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 2.5944 - mae: 1.2359 - mse: 2.1238 - val_loss: 0.4825 - val_mae: 0.0927 - val_mse: 0.0119 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 2.5063 - mae: 1.1720 - mse: 2.0357 - val_loss: 0.4818 - val_mae: 0.0901 - val_mse: 0.0112 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 4.0064 - mae: 1.3007 - mse: 3.5358 - val_loss: 0.4811 - val_mae: 0.0874 - val_mse: 0.0106 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 2.4627 - mae: 1.1014 - mse: 1.9922 - val_loss: 0.4805 - val_mae: 0.0848 - val_mse: 0.0100 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 2.4177 - mae: 1.1539 - mse: 1.9472 - val_loss: 0.4797 - val_mae: 0.0811 - val_mse: 0.0092 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 2.6145 - mae: 1.2155 - mse: 2.1440 - val_loss: 0.4789 - val_mae: 0.0771 - val_mse: 0.0084 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 1.4241 - mae: 0.8852 - mse: 0.9536 - val_loss: 0.4783 - val_mae: 0.0740 - val_mse: 0.0079 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 2.5051 - mae: 1.0262 - mse: 2.0346 - val_loss: 0.4779 - val_mae: 0.0714 - val_mse: 0.0074 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 3.0670 - mae: 1.1348 - mse: 2.5966 - val_loss: 0.4774 - val_mae: 0.0701 - val_mse: 0.0069 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 3.6383 - mae: 1.6349 - mse: 3.1679 - val_loss: 0.4769 - val_mae: 0.0690 - val_mse: 0.0065 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - loss: 1.2888 - mae: 0.8055 - mse: 0.8183 - val_loss: 0.4766 - val_mae: 0.0680 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 1.3495 - mae: 0.9208 - mse: 0.8791 - val_loss: 0.4764 - val_mae: 0.0671 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.8476 - mae: 0.4768 - mse: 0.3772 - val_loss: 0.4761 - val_mae: 0.0658 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.9444 - mae: 0.6174 - mse: 0.4741 - val_loss: 0.4759 - val_mae: 0.0647 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - loss: 2.5023 - mae: 1.2812 - mse: 2.0320 - val_loss: 0.4758 - val_mae: 0.0641 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 2.1258 - mae: 1.2351 - mse: 1.6555 - val_loss: 0.4757 - val_mae: 0.0628 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 3.4094 - mae: 1.3238 - mse: 2.9390 - val_loss: 0.4757 - val_mae: 0.0634 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 3.9887 - mae: 1.3129 - mse: 3.5184 - val_loss: 0.4758 - val_mae: 0.0644 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 0.8421 - mae: 0.3961 - mse: 0.3718 - val_loss: 0.4759 - val_mae: 0.0656 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.3175 - mae: 0.9056 - mse: 0.8472 - val_loss: 0.4760 - val_mae: 0.0666 - val_mse: 0.0058 - learning_rate: 5.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.8865 - mae: 0.6024 - mse: 0.4163 - val_loss: 0.4761 - val_mae: 0.0673 - val_mse: 0.0059 - learning_rate: 5.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 2.7165 - mae: 1.3518 - mse: 2.2463 - val_loss: 0.4763 - val_mae: 0.0679 - val_mse: 0.0060 - learning_rate: 1.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 2.6212 - mae: 1.2569 - mse: 2.1509 - val_loss: 0.4765 - val_mae: 0.0687 - val_mse: 0.0062 - learning_rate: 1.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 2.5466 - mae: 1.4148 - mse: 2.0763 - val_loss: 0.4766 - val_mae: 0.0693 - val_mse: 0.0064 - learning_rate: 1.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.4774 - mae: 0.6742 - mse: 1.0072 - val_loss: 0.4769 - val_mae: 0.0700 - val_mse: 0.0066 - learning_rate: 1.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 1.7131 - mae: 0.8960 - mse: 1.2429 - val_loss: 0.4771 - val_mae: 0.0708 - val_mse: 0.0069 - learning_rate: 1.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 2.7720 - mae: 1.3072 - mse: 2.3018 - val_loss: 0.4773 - val_mae: 0.0711 - val_mse: 0.0070 - learning_rate: 2.0000e-05\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 2.5121 - mae: 1.1703 - mse: 2.0419 - val_loss: 0.4774 - val_mae: 0.0715 - val_mse: 0.0072 - learning_rate: 2.0000e-05\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.3359 - mae: 0.7338 - mse: 0.8657 - val_loss: 0.4776 - val_mae: 0.0719 - val_mse: 0.0074 - learning_rate: 2.0000e-05\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.1253 - mae: 0.6781 - mse: 0.6551 - val_loss: 0.4776 - val_mae: 0.0721 - val_mse: 0.0074 - learning_rate: 2.0000e-05\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.1802 - mae: 0.7671 - mse: 0.7100 - val_loss: 0.4778 - val_mae: 0.0723 - val_mse: 0.0075 - learning_rate: 2.0000e-05\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 1.8759 - mae: 1.0573 - mse: 1.4057 - val_loss: 0.4779 - val_mae: 0.0726 - val_mse: 0.0077 - learning_rate: 1.0000e-05\n",
            "Grupo 15 - RMSE: 0.000013, MAE: 0.000012, sMAPE: 2.55%\n",
            "\n",
            "Treinando modelo para grupo etário 20...\n",
            "Grupo 20: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 1.2446 - mae: 0.7368 - mse: 0.7734 - val_loss: 0.4720 - val_mae: 0.0281 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step - loss: 4.5724 - mae: 1.5807 - mse: 4.1017 - val_loss: 0.4717 - val_mae: 0.0280 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 2.7842 - mae: 1.2613 - mse: 2.3138 - val_loss: 0.4715 - val_mae: 0.0279 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 3.7607 - mae: 1.2235 - mse: 3.2904 - val_loss: 0.4714 - val_mae: 0.0273 - val_mse: 0.0012 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 3.7623 - mae: 1.5115 - mse: 3.2921 - val_loss: 0.4713 - val_mae: 0.0271 - val_mse: 0.0012 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 1.8189 - mae: 1.0537 - mse: 1.3488 - val_loss: 0.4712 - val_mae: 0.0266 - val_mse: 0.0012 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 2.7683 - mae: 1.4922 - mse: 2.2983 - val_loss: 0.4711 - val_mae: 0.0260 - val_mse: 0.0011 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 2.0379 - mae: 1.0104 - mse: 1.5679 - val_loss: 0.4709 - val_mae: 0.0250 - val_mse: 0.0010 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 2.1623 - mae: 0.9761 - mse: 1.6924 - val_loss: 0.4708 - val_mae: 0.0241 - val_mse: 9.6735e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.6901 - mae: 1.0082 - mse: 1.2203 - val_loss: 0.4707 - val_mae: 0.0232 - val_mse: 9.0884e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 4.7517 - mae: 1.7241 - mse: 4.2820 - val_loss: 0.4706 - val_mae: 0.0229 - val_mse: 8.8766e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 2.3526 - mae: 1.2600 - mse: 1.8829 - val_loss: 0.4705 - val_mae: 0.0220 - val_mse: 8.3583e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.6000 - mae: 0.7757 - mse: 1.1304 - val_loss: 0.4703 - val_mae: 0.0216 - val_mse: 7.7443e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 2.8448 - mae: 1.3277 - mse: 2.3752 - val_loss: 0.4702 - val_mae: 0.0212 - val_mse: 7.1353e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.2893 - mae: 0.8039 - mse: 0.8198 - val_loss: 0.4701 - val_mae: 0.0206 - val_mse: 6.4412e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.7757 - mae: 0.9636 - mse: 1.3063 - val_loss: 0.4700 - val_mae: 0.0203 - val_mse: 6.1071e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - loss: 0.9045 - mae: 0.5951 - mse: 0.4351 - val_loss: 0.4699 - val_mae: 0.0198 - val_mse: 5.7011e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 1.8008 - mae: 1.0680 - mse: 1.3315 - val_loss: 0.4698 - val_mae: 0.0193 - val_mse: 5.4288e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - loss: 1.4014 - mae: 0.8205 - mse: 0.9321 - val_loss: 0.4698 - val_mae: 0.0188 - val_mse: 5.3046e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.7671 - mae: 0.4624 - mse: 0.2979 - val_loss: 0.4697 - val_mae: 0.0188 - val_mse: 5.2822e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - loss: 1.2887 - mae: 0.5936 - mse: 0.8195 - val_loss: 0.4696 - val_mae: 0.0192 - val_mse: 5.2762e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - loss: 0.8591 - mae: 0.4894 - mse: 0.3900 - val_loss: 0.4696 - val_mae: 0.0194 - val_mse: 5.2982e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 1.1985 - mae: 0.6489 - mse: 0.7294 - val_loss: 0.4695 - val_mae: 0.0198 - val_mse: 5.4390e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 1.5100 - mae: 0.7934 - mse: 1.0410 - val_loss: 0.4695 - val_mae: 0.0201 - val_mse: 5.5639e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 1.7706 - mae: 0.9260 - mse: 1.3016 - val_loss: 0.4694 - val_mae: 0.0202 - val_mse: 5.6622e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 1.1474 - mae: 0.7240 - mse: 0.6785 - val_loss: 0.4694 - val_mae: 0.0206 - val_mse: 5.9461e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 2.8728 - mae: 1.1286 - mse: 2.4040 - val_loss: 0.4694 - val_mae: 0.0212 - val_mse: 6.2881e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 0.9059 - mae: 0.5634 - mse: 0.4371 - val_loss: 0.4694 - val_mae: 0.0218 - val_mse: 6.5187e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 1.2902 - mae: 0.7831 - mse: 0.8215 - val_loss: 0.4693 - val_mae: 0.0227 - val_mse: 6.9165e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 1.5924 - mae: 0.9324 - mse: 1.1238 - val_loss: 0.4693 - val_mae: 0.0233 - val_mse: 7.1708e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 1.5665 - mae: 0.8378 - mse: 1.0979 - val_loss: 0.4693 - val_mae: 0.0238 - val_mse: 7.4030e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.9326 - mae: 0.6027 - mse: 0.4641 - val_loss: 0.4693 - val_mae: 0.0244 - val_mse: 7.7296e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.8657 - mae: 0.5421 - mse: 0.3972 - val_loss: 0.4692 - val_mae: 0.0244 - val_mse: 7.7385e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 1.1470 - mae: 0.6133 - mse: 0.6786 - val_loss: 0.4692 - val_mae: 0.0244 - val_mse: 7.7649e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 1.4202 - mae: 0.9084 - mse: 0.9518 - val_loss: 0.4691 - val_mae: 0.0252 - val_mse: 8.2130e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.7644 - mae: 0.4389 - mse: 0.2960 - val_loss: 0.4691 - val_mae: 0.0260 - val_mse: 8.7053e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.1088 - mae: 0.7217 - mse: 0.6405 - val_loss: 0.4692 - val_mae: 0.0273 - val_mse: 9.5600e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.7269 - mae: 0.4722 - mse: 0.2587 - val_loss: 0.4692 - val_mae: 0.0283 - val_mse: 0.0010 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.7174 - mae: 0.3419 - mse: 0.2492 - val_loss: 0.4692 - val_mae: 0.0289 - val_mse: 0.0011 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 1.0149 - mae: 0.6815 - mse: 0.5468 - val_loss: 0.4692 - val_mae: 0.0296 - val_mse: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 1.7494 - mae: 1.0119 - mse: 1.2813 - val_loss: 0.4692 - val_mae: 0.0298 - val_mse: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 1.6008 - mae: 0.9658 - mse: 1.1327 - val_loss: 0.4692 - val_mae: 0.0300 - val_mse: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 1.8636 - mae: 1.0203 - mse: 1.3955 - val_loss: 0.4692 - val_mae: 0.0295 - val_mse: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.2879 - mae: 0.7138 - mse: 0.8198 - val_loss: 0.4692 - val_mae: 0.0299 - val_mse: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 1.6480 - mae: 0.9728 - mse: 1.1799 - val_loss: 0.4692 - val_mae: 0.0297 - val_mse: 0.0011 - learning_rate: 2.0000e-05\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.5508 - mae: 0.2218 - mse: 0.0828 - val_loss: 0.4691 - val_mae: 0.0287 - val_mse: 0.0011 - learning_rate: 2.0000e-05\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.6726 - mae: 0.4054 - mse: 0.2046 - val_loss: 0.4690 - val_mae: 0.0277 - val_mse: 9.8795e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.9977 - mae: 0.6053 - mse: 0.5297 - val_loss: 0.4690 - val_mae: 0.0270 - val_mse: 9.3626e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 1.9475 - mae: 1.0065 - mse: 1.4795 - val_loss: 0.4689 - val_mae: 0.0261 - val_mse: 8.7264e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.2718 - mae: 0.8604 - mse: 0.8037 - val_loss: 0.4689 - val_mae: 0.0260 - val_mse: 8.6738e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 1.8953 - mae: 1.0693 - mse: 1.4273 - val_loss: 0.4689 - val_mae: 0.0256 - val_mse: 8.4610e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.5558 - mae: 0.9596 - mse: 1.0877 - val_loss: 0.4688 - val_mae: 0.0251 - val_mse: 8.1427e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.6520 - mae: 1.0445 - mse: 1.1839 - val_loss: 0.4688 - val_mae: 0.0247 - val_mse: 7.9253e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 0.8661 - mae: 0.5151 - mse: 0.3980 - val_loss: 0.4688 - val_mae: 0.0248 - val_mse: 7.9829e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 0.9388 - mae: 0.5564 - mse: 0.4708 - val_loss: 0.4687 - val_mae: 0.0235 - val_mse: 7.2605e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 1.1219 - mae: 0.7746 - mse: 0.6539 - val_loss: 0.4687 - val_mae: 0.0231 - val_mse: 7.0966e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 2.0636 - mae: 1.0794 - mse: 1.5956 - val_loss: 0.4687 - val_mae: 0.0229 - val_mse: 7.0082e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.8936 - mae: 0.5370 - mse: 0.4256 - val_loss: 0.4686 - val_mae: 0.0217 - val_mse: 6.4549e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.0394 - mae: 0.6732 - mse: 0.5714 - val_loss: 0.4686 - val_mae: 0.0209 - val_mse: 6.1488e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 1.4175 - mae: 0.7080 - mse: 0.9495 - val_loss: 0.4686 - val_mae: 0.0210 - val_mse: 6.1767e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 2.0179 - mae: 1.1957 - mse: 1.5499 - val_loss: 0.4686 - val_mae: 0.0205 - val_mse: 5.7866e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 1.5592 - mae: 0.9642 - mse: 1.0912 - val_loss: 0.4686 - val_mae: 0.0202 - val_mse: 5.5438e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.8503 - mae: 1.0170 - mse: 1.3823 - val_loss: 0.4685 - val_mae: 0.0202 - val_mse: 5.5016e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.7021 - mae: 0.3209 - mse: 0.2341 - val_loss: 0.4685 - val_mae: 0.0200 - val_mse: 5.3621e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.5959 - mae: 0.7578 - mse: 1.1279 - val_loss: 0.4685 - val_mae: 0.0195 - val_mse: 5.1357e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 1.1164 - mae: 0.6465 - mse: 0.6485 - val_loss: 0.4685 - val_mae: 0.0195 - val_mse: 5.0985e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 2.2355 - mae: 0.8952 - mse: 1.7675 - val_loss: 0.4685 - val_mae: 0.0193 - val_mse: 5.0442e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.8662 - mae: 0.5338 - mse: 0.3982 - val_loss: 0.4685 - val_mae: 0.0191 - val_mse: 4.9833e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 1.5382 - mae: 0.8189 - mse: 1.0702 - val_loss: 0.4685 - val_mae: 0.0188 - val_mse: 4.9319e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 1.1356 - mae: 0.7277 - mse: 0.6676 - val_loss: 0.4685 - val_mae: 0.0187 - val_mse: 4.9197e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.8509 - mae: 0.5181 - mse: 0.3829 - val_loss: 0.4685 - val_mae: 0.0184 - val_mse: 4.9619e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 3.6015 - mae: 1.6599 - mse: 3.1335 - val_loss: 0.4685 - val_mae: 0.0188 - val_mse: 5.0696e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 1.4668 - mae: 0.8595 - mse: 0.9988 - val_loss: 0.4685 - val_mae: 0.0190 - val_mse: 5.1496e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.7038 - mae: 0.3139 - mse: 0.2358 - val_loss: 0.4685 - val_mae: 0.0191 - val_mse: 5.2222e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 1.2943 - mae: 0.6303 - mse: 0.8263 - val_loss: 0.4685 - val_mae: 0.0191 - val_mse: 5.2678e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 1.0188 - mae: 0.7043 - mse: 0.5508 - val_loss: 0.4685 - val_mae: 0.0191 - val_mse: 5.2701e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 0.9086 - mae: 0.5508 - mse: 0.4406 - val_loss: 0.4686 - val_mae: 0.0198 - val_mse: 5.7777e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - loss: 0.8416 - mae: 0.5378 - mse: 0.3737 - val_loss: 0.4686 - val_mae: 0.0207 - val_mse: 6.7632e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 2.9682 - mae: 1.3692 - mse: 2.5003 - val_loss: 0.4687 - val_mae: 0.0213 - val_mse: 7.5845e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 1.9700 - mae: 0.9978 - mse: 1.5020 - val_loss: 0.4688 - val_mae: 0.0223 - val_mse: 8.4180e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 1.0966 - mae: 0.6198 - mse: 0.6286 - val_loss: 0.4688 - val_mae: 0.0221 - val_mse: 8.2997e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 1.0770 - mae: 0.6526 - mse: 0.6091 - val_loss: 0.4689 - val_mae: 0.0233 - val_mse: 9.0305e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 0.7222 - mae: 0.4246 - mse: 0.2542 - val_loss: 0.4689 - val_mae: 0.0234 - val_mse: 9.1143e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 1.4329 - mae: 0.7381 - mse: 0.9650 - val_loss: 0.4689 - val_mae: 0.0235 - val_mse: 9.2032e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.7934 - mae: 0.4353 - mse: 0.3254 - val_loss: 0.4690 - val_mae: 0.0252 - val_mse: 0.0010 - learning_rate: 1.0000e-05\n",
            "Grupo 20 - RMSE: 0.000004, MAE: 0.000003, sMAPE: 0.60%\n",
            "\n",
            "Treinando modelo para grupo etário 25...\n",
            "Grupo 25: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 1.0536 - mae: 0.6261 - mse: 0.5828 - val_loss: 0.4769 - val_mae: 0.0591 - val_mse: 0.0066 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 1.3063 - mae: 0.7271 - mse: 0.8360 - val_loss: 0.4767 - val_mae: 0.0593 - val_mse: 0.0066 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 1.2133 - mae: 0.7630 - mse: 0.7432 - val_loss: 0.4767 - val_mae: 0.0601 - val_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1.2423 - mae: 0.8693 - mse: 0.7723 - val_loss: 0.4766 - val_mae: 0.0602 - val_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.5709 - mae: 0.7490 - mse: 1.1010 - val_loss: 0.4762 - val_mae: 0.0585 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 0.6232 - mae: 0.2696 - mse: 0.1535 - val_loss: 0.4760 - val_mae: 0.0578 - val_mse: 0.0063 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.8670 - mae: 0.5481 - mse: 0.3974 - val_loss: 0.4757 - val_mae: 0.0568 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 1.0749 - mae: 0.6488 - mse: 0.6054 - val_loss: 0.4756 - val_mae: 0.0570 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 1.1292 - mae: 0.5856 - mse: 0.6597 - val_loss: 0.4755 - val_mae: 0.0566 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 1.0135 - mae: 0.4930 - mse: 0.5441 - val_loss: 0.4750 - val_mae: 0.0547 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.8109 - mae: 0.4821 - mse: 0.3416 - val_loss: 0.4750 - val_mae: 0.0550 - val_mse: 0.0058 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 1.8089 - mae: 0.8957 - mse: 1.3396 - val_loss: 0.4749 - val_mae: 0.0549 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.3250 - mae: 0.8133 - mse: 0.8558 - val_loss: 0.4751 - val_mae: 0.0560 - val_mse: 0.0059 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.9427 - mae: 0.5862 - mse: 0.4736 - val_loss: 0.4747 - val_mae: 0.0543 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 1.8861 - mae: 0.9783 - mse: 1.4170 - val_loss: 0.4747 - val_mae: 0.0546 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.4187 - mae: 0.8416 - mse: 0.9497 - val_loss: 0.4745 - val_mae: 0.0537 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.5970 - mae: 0.3111 - mse: 0.1281 - val_loss: 0.4744 - val_mae: 0.0536 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.7912 - mae: 0.5163 - mse: 0.3222 - val_loss: 0.4743 - val_mae: 0.0533 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 1.1466 - mae: 0.6733 - mse: 0.6777 - val_loss: 0.4742 - val_mae: 0.0529 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 1.0346 - mae: 0.5132 - mse: 0.5658 - val_loss: 0.4740 - val_mae: 0.0522 - val_mse: 0.0053 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 1.1714 - mae: 0.7790 - mse: 0.7027 - val_loss: 0.4739 - val_mae: 0.0518 - val_mse: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.8101 - mae: 0.4932 - mse: 0.3414 - val_loss: 0.4738 - val_mae: 0.0516 - val_mse: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 1.0971 - mae: 0.5747 - mse: 0.6285 - val_loss: 0.4738 - val_mae: 0.0520 - val_mse: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.1037 - mae: 0.6074 - mse: 0.6350 - val_loss: 0.4738 - val_mae: 0.0522 - val_mse: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.6151 - mae: 0.3120 - mse: 0.1465 - val_loss: 0.4737 - val_mae: 0.0523 - val_mse: 0.0053 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 1.2301 - mae: 0.6489 - mse: 0.7616 - val_loss: 0.4737 - val_mae: 0.0525 - val_mse: 0.0053 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 1.0566 - mae: 0.6768 - mse: 0.5882 - val_loss: 0.4736 - val_mae: 0.0521 - val_mse: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 1.1391 - mae: 0.6243 - mse: 0.6707 - val_loss: 0.4735 - val_mae: 0.0517 - val_mse: 0.0051 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 1.2480 - mae: 0.7356 - mse: 0.7796 - val_loss: 0.4732 - val_mae: 0.0506 - val_mse: 0.0050 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 1.1102 - mae: 0.7000 - mse: 0.6419 - val_loss: 0.4732 - val_mae: 0.0508 - val_mse: 0.0050 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 1.3234 - mae: 0.7879 - mse: 0.8552 - val_loss: 0.4732 - val_mae: 0.0509 - val_mse: 0.0050 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 1.2558 - mae: 0.7018 - mse: 0.7876 - val_loss: 0.4734 - val_mae: 0.0528 - val_mse: 0.0053 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.5677 - mae: 0.8582 - mse: 1.0996 - val_loss: 0.4736 - val_mae: 0.0541 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.4690 - mae: 0.8985 - mse: 1.0010 - val_loss: 0.4736 - val_mae: 0.0546 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 2.0176 - mae: 1.1008 - mse: 1.5496 - val_loss: 0.4738 - val_mae: 0.0560 - val_mse: 0.0059 - learning_rate: 1.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 0.6320 - mae: 0.3652 - mse: 0.1640 - val_loss: 0.4739 - val_mae: 0.0564 - val_mse: 0.0059 - learning_rate: 1.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - loss: 1.7606 - mae: 0.7854 - mse: 1.2926 - val_loss: 0.4738 - val_mae: 0.0557 - val_mse: 0.0058 - learning_rate: 1.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1.9964 - mae: 0.9563 - mse: 1.5284 - val_loss: 0.4737 - val_mae: 0.0556 - val_mse: 0.0058 - learning_rate: 1.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - loss: 1.2859 - mae: 0.7302 - mse: 0.8179 - val_loss: 0.4738 - val_mae: 0.0559 - val_mse: 0.0058 - learning_rate: 1.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - loss: 0.9047 - mae: 0.5748 - mse: 0.4368 - val_loss: 0.4738 - val_mae: 0.0561 - val_mse: 0.0059 - learning_rate: 2.0000e-05\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 0.5772 - mae: 0.2845 - mse: 0.1093 - val_loss: 0.4737 - val_mae: 0.0556 - val_mse: 0.0058 - learning_rate: 2.0000e-05\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 3.0536 - mae: 1.2983 - mse: 2.5857 - val_loss: 0.4736 - val_mae: 0.0550 - val_mse: 0.0057 - learning_rate: 2.0000e-05\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - loss: 0.9131 - mae: 0.5753 - mse: 0.4452 - val_loss: 0.4736 - val_mae: 0.0550 - val_mse: 0.0057 - learning_rate: 2.0000e-05\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - loss: 1.4332 - mae: 0.6964 - mse: 0.9653 - val_loss: 0.4736 - val_mae: 0.0552 - val_mse: 0.0057 - learning_rate: 2.0000e-05\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 2.3532 - mae: 1.2425 - mse: 1.8852 - val_loss: 0.4736 - val_mae: 0.0549 - val_mse: 0.0057 - learning_rate: 1.0000e-05\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 1.1905 - mae: 0.7792 - mse: 0.7226 - val_loss: 0.4735 - val_mae: 0.0545 - val_mse: 0.0056 - learning_rate: 1.0000e-05\n",
            "Grupo 25 - RMSE: 0.000020, MAE: 0.000015, sMAPE: 2.22%\n",
            "\n",
            "Treinando modelo para grupo etário 30...\n",
            "Grupo 30: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.8441 - mae: 0.4782 - mse: 0.3725 - val_loss: 0.4763 - val_mae: 0.0531 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.2999 - mae: 0.6879 - mse: 0.8290 - val_loss: 0.4762 - val_mae: 0.0550 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 1.0723 - mae: 0.6867 - mse: 0.6016 - val_loss: 0.4761 - val_mae: 0.0564 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.8251 - mae: 0.4188 - mse: 0.3547 - val_loss: 0.4764 - val_mae: 0.0600 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 1.1786 - mae: 0.6794 - mse: 0.7084 - val_loss: 0.4765 - val_mae: 0.0630 - val_mse: 0.0065 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1.3504 - mae: 0.8307 - mse: 0.8804 - val_loss: 0.4767 - val_mae: 0.0653 - val_mse: 0.0068 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 3.1921 - mae: 1.3691 - mse: 2.7223 - val_loss: 0.4766 - val_mae: 0.0664 - val_mse: 0.0070 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 1.0090 - mae: 0.6353 - mse: 0.5393 - val_loss: 0.4765 - val_mae: 0.0653 - val_mse: 0.0068 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.9797 - mae: 0.6258 - mse: 0.5100 - val_loss: 0.4763 - val_mae: 0.0643 - val_mse: 0.0067 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.1758 - mae: 0.6345 - mse: 0.7062 - val_loss: 0.4763 - val_mae: 0.0646 - val_mse: 0.0067 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 2.4371 - mae: 1.2604 - mse: 1.9675 - val_loss: 0.4764 - val_mae: 0.0657 - val_mse: 0.0069 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 1.5134 - mae: 0.8081 - mse: 1.0439 - val_loss: 0.4762 - val_mae: 0.0644 - val_mse: 0.0067 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 2.4329 - mae: 1.2031 - mse: 1.9634 - val_loss: 0.4761 - val_mae: 0.0639 - val_mse: 0.0066 - learning_rate: 2.0000e-05\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 1.4082 - mae: 0.9032 - mse: 0.9387 - val_loss: 0.4760 - val_mae: 0.0628 - val_mse: 0.0065 - learning_rate: 2.0000e-05\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.5251 - mae: 0.9315 - mse: 1.0556 - val_loss: 0.4761 - val_mae: 0.0635 - val_mse: 0.0066 - learning_rate: 2.0000e-05\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 1.6649 - mae: 0.8589 - mse: 1.1954 - val_loss: 0.4759 - val_mae: 0.0619 - val_mse: 0.0064 - learning_rate: 2.0000e-05\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 2.3743 - mae: 1.2394 - mse: 1.9048 - val_loss: 0.4758 - val_mae: 0.0611 - val_mse: 0.0063 - learning_rate: 2.0000e-05\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.9903 - mae: 0.5278 - mse: 0.5208 - val_loss: 0.4756 - val_mae: 0.0595 - val_mse: 0.0061 - learning_rate: 2.0000e-05\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 1.5069 - mae: 0.7461 - mse: 1.0374 - val_loss: 0.4753 - val_mae: 0.0574 - val_mse: 0.0058 - learning_rate: 2.0000e-05\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 1.1059 - mae: 0.6435 - mse: 0.6364 - val_loss: 0.4751 - val_mae: 0.0556 - val_mse: 0.0056 - learning_rate: 2.0000e-05\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.7924 - mae: 0.8471 - mse: 1.3229 - val_loss: 0.4749 - val_mae: 0.0540 - val_mse: 0.0054 - learning_rate: 2.0000e-05\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 2.3073 - mae: 1.1781 - mse: 1.8378 - val_loss: 0.4748 - val_mae: 0.0536 - val_mse: 0.0053 - learning_rate: 2.0000e-05\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 0.8143 - mae: 0.4565 - mse: 0.3448 - val_loss: 0.4748 - val_mae: 0.0530 - val_mse: 0.0053 - learning_rate: 2.0000e-05\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 2.0096 - mae: 0.9085 - mse: 1.5401 - val_loss: 0.4748 - val_mae: 0.0530 - val_mse: 0.0053 - learning_rate: 2.0000e-05\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 2.9799 - mae: 1.3834 - mse: 2.5104 - val_loss: 0.4747 - val_mae: 0.0522 - val_mse: 0.0052 - learning_rate: 2.0000e-05\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.9441 - mae: 0.8007 - mse: 1.4746 - val_loss: 0.4747 - val_mae: 0.0525 - val_mse: 0.0052 - learning_rate: 2.0000e-05\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 2.0831 - mae: 1.0634 - mse: 1.6136 - val_loss: 0.4746 - val_mae: 0.0514 - val_mse: 0.0051 - learning_rate: 2.0000e-05\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.6606 - mae: 0.3860 - mse: 0.1911 - val_loss: 0.4745 - val_mae: 0.0509 - val_mse: 0.0051 - learning_rate: 2.0000e-05\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 1.8639 - mae: 1.0851 - mse: 1.3945 - val_loss: 0.4744 - val_mae: 0.0504 - val_mse: 0.0050 - learning_rate: 2.0000e-05\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.2163 - mae: 0.6880 - mse: 0.7469 - val_loss: 0.4743 - val_mae: 0.0495 - val_mse: 0.0048 - learning_rate: 2.0000e-05\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 1.0236 - mae: 0.6504 - mse: 0.5541 - val_loss: 0.4741 - val_mae: 0.0487 - val_mse: 0.0047 - learning_rate: 2.0000e-05\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 1.4453 - mae: 0.7289 - mse: 0.9759 - val_loss: 0.4739 - val_mae: 0.0482 - val_mse: 0.0045 - learning_rate: 2.0000e-05\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.5786 - mae: 0.7857 - mse: 1.1092 - val_loss: 0.4739 - val_mae: 0.0482 - val_mse: 0.0045 - learning_rate: 2.0000e-05\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 2.0043 - mae: 1.0634 - mse: 1.5349 - val_loss: 0.4738 - val_mae: 0.0480 - val_mse: 0.0044 - learning_rate: 2.0000e-05\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 2.2806 - mae: 1.1798 - mse: 1.8112 - val_loss: 0.4736 - val_mae: 0.0476 - val_mse: 0.0042 - learning_rate: 2.0000e-05\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 1.7488 - mae: 0.9596 - mse: 1.2794 - val_loss: 0.4735 - val_mae: 0.0473 - val_mse: 0.0041 - learning_rate: 2.0000e-05\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 1.2008 - mae: 0.6814 - mse: 0.7314 - val_loss: 0.4734 - val_mae: 0.0469 - val_mse: 0.0040 - learning_rate: 2.0000e-05\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 1.1167 - mae: 0.6901 - mse: 0.6473 - val_loss: 0.4732 - val_mae: 0.0466 - val_mse: 0.0038 - learning_rate: 2.0000e-05\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.8485 - mae: 0.5565 - mse: 0.3791 - val_loss: 0.4732 - val_mae: 0.0466 - val_mse: 0.0038 - learning_rate: 2.0000e-05\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 1.8595 - mae: 1.0402 - mse: 1.3900 - val_loss: 0.4731 - val_mae: 0.0463 - val_mse: 0.0037 - learning_rate: 2.0000e-05\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 1.1473 - mae: 0.6877 - mse: 0.6779 - val_loss: 0.4731 - val_mae: 0.0461 - val_mse: 0.0037 - learning_rate: 2.0000e-05\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - loss: 0.9239 - mae: 0.5248 - mse: 0.4546 - val_loss: 0.4729 - val_mae: 0.0457 - val_mse: 0.0035 - learning_rate: 2.0000e-05\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.3744 - mae: 0.8008 - mse: 0.9050 - val_loss: 0.4729 - val_mae: 0.0456 - val_mse: 0.0035 - learning_rate: 2.0000e-05\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.6895 - mae: 0.3675 - mse: 0.2201 - val_loss: 0.4730 - val_mae: 0.0459 - val_mse: 0.0036 - learning_rate: 2.0000e-05\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 0.9028 - mae: 0.5327 - mse: 0.4334 - val_loss: 0.4729 - val_mae: 0.0457 - val_mse: 0.0035 - learning_rate: 2.0000e-05\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.7889 - mae: 0.9927 - mse: 1.3195 - val_loss: 0.4730 - val_mae: 0.0459 - val_mse: 0.0036 - learning_rate: 2.0000e-05\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step - loss: 1.2388 - mae: 0.7284 - mse: 0.7694 - val_loss: 0.4728 - val_mae: 0.0455 - val_mse: 0.0035 - learning_rate: 2.0000e-05\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 2.2307 - mae: 1.2666 - mse: 1.7613 - val_loss: 0.4727 - val_mae: 0.0452 - val_mse: 0.0034 - learning_rate: 1.0000e-05\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.4630 - mae: 0.9043 - mse: 0.9936 - val_loss: 0.4727 - val_mae: 0.0450 - val_mse: 0.0033 - learning_rate: 1.0000e-05\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 0.9245 - mae: 0.5004 - mse: 0.4551 - val_loss: 0.4726 - val_mae: 0.0447 - val_mse: 0.0032 - learning_rate: 1.0000e-05\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - loss: 0.5103 - mae: 0.1849 - mse: 0.0410 - val_loss: 0.4725 - val_mae: 0.0443 - val_mse: 0.0031 - learning_rate: 1.0000e-05\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.7184 - mae: 0.4354 - mse: 0.2490 - val_loss: 0.4725 - val_mae: 0.0442 - val_mse: 0.0031 - learning_rate: 1.0000e-05\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 1.8107 - mae: 1.0247 - mse: 1.3414 - val_loss: 0.4724 - val_mae: 0.0440 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - loss: 1.6096 - mae: 0.8099 - mse: 1.1402 - val_loss: 0.4723 - val_mae: 0.0438 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 1.6960 - mae: 0.7902 - mse: 1.2266 - val_loss: 0.4724 - val_mae: 0.0440 - val_mse: 0.0031 - learning_rate: 1.0000e-05\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 1.9288 - mae: 1.0162 - mse: 1.4595 - val_loss: 0.4724 - val_mae: 0.0439 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.9278 - mae: 0.9617 - mse: 1.4585 - val_loss: 0.4724 - val_mae: 0.0439 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 1.0094 - mae: 0.6096 - mse: 0.5401 - val_loss: 0.4723 - val_mae: 0.0437 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 1.0484 - mae: 0.6881 - mse: 0.5791 - val_loss: 0.4723 - val_mae: 0.0437 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.5349 - mae: 0.8749 - mse: 1.0655 - val_loss: 0.4723 - val_mae: 0.0438 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 1.4323 - mae: 0.8995 - mse: 0.9630 - val_loss: 0.4723 - val_mae: 0.0437 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 1.2288 - mae: 0.7373 - mse: 0.7595 - val_loss: 0.4723 - val_mae: 0.0436 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 1.6245 - mae: 0.9812 - mse: 1.1552 - val_loss: 0.4722 - val_mae: 0.0432 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 1.1884 - mae: 0.6711 - mse: 0.7190 - val_loss: 0.4722 - val_mae: 0.0431 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.6749 - mae: 0.8274 - mse: 1.2056 - val_loss: 0.4721 - val_mae: 0.0424 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 1.6595 - mae: 0.8774 - mse: 1.1902 - val_loss: 0.4721 - val_mae: 0.0425 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 1.5569 - mae: 0.9910 - mse: 1.0876 - val_loss: 0.4721 - val_mae: 0.0425 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - loss: 1.5816 - mae: 0.9158 - mse: 1.1123 - val_loss: 0.4720 - val_mae: 0.0422 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 2.2741 - mae: 1.1365 - mse: 1.8048 - val_loss: 0.4720 - val_mae: 0.0423 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.3580 - mae: 0.8163 - mse: 0.8887 - val_loss: 0.4720 - val_mae: 0.0420 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 0.8763 - mae: 0.5180 - mse: 0.4070 - val_loss: 0.4720 - val_mae: 0.0420 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 1.6303 - mae: 0.9797 - mse: 1.1610 - val_loss: 0.4719 - val_mae: 0.0418 - val_mse: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.9695 - mae: 0.4625 - mse: 0.5002 - val_loss: 0.4719 - val_mae: 0.0417 - val_mse: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 2.2165 - mae: 1.0835 - mse: 1.7472 - val_loss: 0.4719 - val_mae: 0.0418 - val_mse: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.7745 - mae: 0.4434 - mse: 0.3052 - val_loss: 0.4718 - val_mae: 0.0424 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 1.2039 - mae: 0.6990 - mse: 0.7346 - val_loss: 0.4718 - val_mae: 0.0428 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 2.0162 - mae: 0.9925 - mse: 1.5469 - val_loss: 0.4718 - val_mae: 0.0430 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.5442 - mae: 0.7508 - mse: 1.0750 - val_loss: 0.4718 - val_mae: 0.0431 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 1.9326 - mae: 1.1551 - mse: 1.4633 - val_loss: 0.4718 - val_mae: 0.0433 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 1.5573 - mae: 0.9530 - mse: 1.0881 - val_loss: 0.4718 - val_mae: 0.0434 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 1.6170 - mae: 0.8551 - mse: 1.1477 - val_loss: 0.4718 - val_mae: 0.0432 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 2.3377 - mae: 1.1111 - mse: 1.8684 - val_loss: 0.4718 - val_mae: 0.0434 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 1.1937 - mae: 0.7030 - mse: 0.7244 - val_loss: 0.4718 - val_mae: 0.0436 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 1.6697 - mae: 0.8283 - mse: 1.2004 - val_loss: 0.4718 - val_mae: 0.0437 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 1.1063 - mae: 0.7288 - mse: 0.6370 - val_loss: 0.4718 - val_mae: 0.0437 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.9199 - mae: 0.5928 - mse: 0.4506 - val_loss: 0.4718 - val_mae: 0.0441 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1.3015 - mae: 0.6620 - mse: 0.8322 - val_loss: 0.4718 - val_mae: 0.0448 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 2.0557 - mae: 0.7547 - mse: 1.5864 - val_loss: 0.4718 - val_mae: 0.0449 - val_mse: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.9193 - mae: 1.0760 - mse: 1.4500 - val_loss: 0.4718 - val_mae: 0.0453 - val_mse: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 1.3624 - mae: 0.8365 - mse: 0.8931 - val_loss: 0.4718 - val_mae: 0.0455 - val_mse: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 1.1184 - mae: 0.7402 - mse: 0.6491 - val_loss: 0.4719 - val_mae: 0.0458 - val_mse: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 3.2282 - mae: 1.4201 - mse: 2.7590 - val_loss: 0.4719 - val_mae: 0.0461 - val_mse: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.9663 - mae: 0.5448 - mse: 0.4971 - val_loss: 0.4719 - val_mae: 0.0462 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 1.5977 - mae: 0.8045 - mse: 1.1284 - val_loss: 0.4719 - val_mae: 0.0466 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 2.8968 - mae: 1.4362 - mse: 2.4276 - val_loss: 0.4720 - val_mae: 0.0469 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 2.0809 - mae: 1.0420 - mse: 1.6117 - val_loss: 0.4720 - val_mae: 0.0470 - val_mse: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 1.1212 - mae: 0.7495 - mse: 0.6520 - val_loss: 0.4721 - val_mae: 0.0481 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - loss: 1.4684 - mae: 0.7499 - mse: 0.9992 - val_loss: 0.4722 - val_mae: 0.0488 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Grupo 30 - RMSE: 0.000022, MAE: 0.000019, sMAPE: 2.17%\n",
            "\n",
            "Treinando modelo para grupo etário 35...\n",
            "Grupo 35: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - loss: 4.4120 - mae: 1.8167 - mse: 3.9400 - val_loss: 0.4782 - val_mae: 0.0631 - val_mse: 0.0068 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 5.7072 - mae: 1.9869 - mse: 5.2358 - val_loss: 0.4779 - val_mae: 0.0627 - val_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 3.0534 - mae: 1.5684 - mse: 2.5822 - val_loss: 0.4775 - val_mae: 0.0616 - val_mse: 0.0065 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 4.0054 - mae: 1.7912 - mse: 3.5344 - val_loss: 0.4772 - val_mae: 0.0605 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step - loss: 4.2600 - mae: 1.7509 - mse: 3.7890 - val_loss: 0.4768 - val_mae: 0.0594 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 2.7607 - mae: 1.3787 - mse: 2.2899 - val_loss: 0.4766 - val_mae: 0.0584 - val_mse: 0.0059 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 3.9817 - mae: 1.8250 - mse: 3.5110 - val_loss: 0.4763 - val_mae: 0.0577 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - loss: 4.8612 - mae: 1.8398 - mse: 4.3906 - val_loss: 0.4761 - val_mae: 0.0569 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 3.7114 - mae: 1.4648 - mse: 3.2409 - val_loss: 0.4759 - val_mae: 0.0561 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 3.4228 - mae: 1.5045 - mse: 2.9524 - val_loss: 0.4757 - val_mae: 0.0556 - val_mse: 0.0053 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 3.0418 - mae: 1.4270 - mse: 2.5714 - val_loss: 0.4755 - val_mae: 0.0552 - val_mse: 0.0053 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 4.7118 - mae: 1.7061 - mse: 4.2416 - val_loss: 0.4753 - val_mae: 0.0544 - val_mse: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 3.2622 - mae: 1.5911 - mse: 2.7921 - val_loss: 0.4751 - val_mae: 0.0541 - val_mse: 0.0050 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 3.3908 - mae: 1.5854 - mse: 2.9207 - val_loss: 0.4749 - val_mae: 0.0539 - val_mse: 0.0049 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 4.5326 - mae: 1.9096 - mse: 4.0626 - val_loss: 0.4748 - val_mae: 0.0538 - val_mse: 0.0049 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.9616 - mae: 1.0918 - mse: 1.4917 - val_loss: 0.4746 - val_mae: 0.0536 - val_mse: 0.0047 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 4.1328 - mae: 1.7367 - mse: 3.6629 - val_loss: 0.4745 - val_mae: 0.0535 - val_mse: 0.0046 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 2.6575 - mae: 1.3882 - mse: 2.1877 - val_loss: 0.4742 - val_mae: 0.0532 - val_mse: 0.0045 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 3.9583 - mae: 1.6426 - mse: 3.4886 - val_loss: 0.4741 - val_mae: 0.0529 - val_mse: 0.0044 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.9753 - mae: 1.1738 - mse: 1.5056 - val_loss: 0.4739 - val_mae: 0.0527 - val_mse: 0.0043 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 3.7718 - mae: 1.6106 - mse: 3.3022 - val_loss: 0.4738 - val_mae: 0.0525 - val_mse: 0.0042 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 4.3782 - mae: 1.9148 - mse: 3.9087 - val_loss: 0.4736 - val_mae: 0.0522 - val_mse: 0.0041 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 2.0980 - mae: 1.1591 - mse: 1.6285 - val_loss: 0.4734 - val_mae: 0.0518 - val_mse: 0.0040 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 2.2682 - mae: 1.0854 - mse: 1.7987 - val_loss: 0.4733 - val_mae: 0.0516 - val_mse: 0.0039 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.9969 - mae: 1.0943 - mse: 1.5275 - val_loss: 0.4731 - val_mae: 0.0513 - val_mse: 0.0038 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 3.3484 - mae: 1.5577 - mse: 2.8791 - val_loss: 0.4730 - val_mae: 0.0510 - val_mse: 0.0037 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 3.7661 - mae: 1.7686 - mse: 3.2969 - val_loss: 0.4728 - val_mae: 0.0507 - val_mse: 0.0037 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 2.9314 - mae: 1.4088 - mse: 2.4623 - val_loss: 0.4727 - val_mae: 0.0506 - val_mse: 0.0036 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 4.1608 - mae: 1.6495 - mse: 3.6917 - val_loss: 0.4726 - val_mae: 0.0503 - val_mse: 0.0036 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 2.2788 - mae: 1.2732 - mse: 1.8097 - val_loss: 0.4725 - val_mae: 0.0501 - val_mse: 0.0035 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 2.8392 - mae: 1.2074 - mse: 2.3702 - val_loss: 0.4723 - val_mae: 0.0497 - val_mse: 0.0034 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 2.8237 - mae: 1.3661 - mse: 2.3548 - val_loss: 0.4722 - val_mae: 0.0494 - val_mse: 0.0033 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 2.6981 - mae: 1.4532 - mse: 2.2292 - val_loss: 0.4721 - val_mae: 0.0491 - val_mse: 0.0033 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 2.4651 - mae: 1.3549 - mse: 1.9963 - val_loss: 0.4719 - val_mae: 0.0486 - val_mse: 0.0032 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.6864 - mae: 0.9889 - mse: 1.2176 - val_loss: 0.4718 - val_mae: 0.0483 - val_mse: 0.0031 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 2.4485 - mae: 1.3318 - mse: 1.9798 - val_loss: 0.4717 - val_mae: 0.0482 - val_mse: 0.0031 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 2.5653 - mae: 1.4202 - mse: 2.0967 - val_loss: 0.4717 - val_mae: 0.0480 - val_mse: 0.0031 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 2.9694 - mae: 1.4945 - mse: 2.5008 - val_loss: 0.4716 - val_mae: 0.0478 - val_mse: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 1.9598 - mae: 1.0730 - mse: 1.4913 - val_loss: 0.4715 - val_mae: 0.0476 - val_mse: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 2.0380 - mae: 1.1104 - mse: 1.5695 - val_loss: 0.4714 - val_mae: 0.0473 - val_mse: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 2.3386 - mae: 1.1897 - mse: 1.8702 - val_loss: 0.4713 - val_mae: 0.0470 - val_mse: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.9053 - mae: 0.9847 - mse: 1.4369 - val_loss: 0.4713 - val_mae: 0.0468 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 1.4062 - mae: 0.7242 - mse: 0.9379 - val_loss: 0.4712 - val_mae: 0.0464 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - loss: 1.1766 - mae: 0.7908 - mse: 0.7083 - val_loss: 0.4711 - val_mae: 0.0464 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 1.6975 - mae: 0.9131 - mse: 1.2292 - val_loss: 0.4711 - val_mae: 0.0465 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 2.9700 - mae: 1.4330 - mse: 2.5018 - val_loss: 0.4710 - val_mae: 0.0467 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 1.3562 - mae: 0.8222 - mse: 0.8880 - val_loss: 0.4709 - val_mae: 0.0469 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 2.5793 - mae: 1.3941 - mse: 2.1112 - val_loss: 0.4709 - val_mae: 0.0471 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 3.3503 - mae: 1.5567 - mse: 2.8823 - val_loss: 0.4708 - val_mae: 0.0473 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 1.9450 - mae: 1.1204 - mse: 1.4770 - val_loss: 0.4708 - val_mae: 0.0477 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - loss: 1.7145 - mae: 1.0630 - mse: 1.2466 - val_loss: 0.4707 - val_mae: 0.0480 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.0710 - mae: 0.6955 - mse: 0.6032 - val_loss: 0.4707 - val_mae: 0.0483 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 1.3536 - mae: 0.8264 - mse: 0.8858 - val_loss: 0.4706 - val_mae: 0.0487 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 2.0158 - mae: 1.1822 - mse: 1.5481 - val_loss: 0.4706 - val_mae: 0.0490 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 2.8089 - mae: 1.4298 - mse: 2.3412 - val_loss: 0.4706 - val_mae: 0.0492 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 2.4600 - mae: 1.1834 - mse: 1.9923 - val_loss: 0.4706 - val_mae: 0.0495 - val_mse: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 2.8539 - mae: 1.2274 - mse: 2.3863 - val_loss: 0.4705 - val_mae: 0.0497 - val_mse: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.2554 - mae: 0.8085 - mse: 0.7879 - val_loss: 0.4705 - val_mae: 0.0501 - val_mse: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 1.6088 - mae: 0.9423 - mse: 1.1413 - val_loss: 0.4705 - val_mae: 0.0506 - val_mse: 0.0031 - learning_rate: 5.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 2.2592 - mae: 1.0683 - mse: 1.7917 - val_loss: 0.4705 - val_mae: 0.0509 - val_mse: 0.0031 - learning_rate: 5.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - loss: 1.6759 - mae: 0.8481 - mse: 1.2085 - val_loss: 0.4705 - val_mae: 0.0510 - val_mse: 0.0032 - learning_rate: 1.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 1.5360 - mae: 0.9219 - mse: 1.0686 - val_loss: 0.4706 - val_mae: 0.0511 - val_mse: 0.0032 - learning_rate: 1.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - loss: 1.2650 - mae: 0.7544 - mse: 0.7976 - val_loss: 0.4705 - val_mae: 0.0510 - val_mse: 0.0032 - learning_rate: 1.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step - loss: 2.4409 - mae: 1.1421 - mse: 1.9735 - val_loss: 0.4705 - val_mae: 0.0508 - val_mse: 0.0031 - learning_rate: 1.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 1.4463 - mae: 0.8478 - mse: 0.9789 - val_loss: 0.4705 - val_mae: 0.0511 - val_mse: 0.0032 - learning_rate: 1.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 2.3564 - mae: 1.3366 - mse: 1.8890 - val_loss: 0.4705 - val_mae: 0.0509 - val_mse: 0.0031 - learning_rate: 2.0000e-05\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 1.2871 - mae: 0.7672 - mse: 0.8197 - val_loss: 0.4705 - val_mae: 0.0509 - val_mse: 0.0031 - learning_rate: 2.0000e-05\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.6351 - mae: 0.9842 - mse: 1.1678 - val_loss: 0.4705 - val_mae: 0.0509 - val_mse: 0.0031 - learning_rate: 2.0000e-05\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 1.5584 - mae: 0.8756 - mse: 1.0910 - val_loss: 0.4705 - val_mae: 0.0508 - val_mse: 0.0031 - learning_rate: 2.0000e-05\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 3.3396 - mae: 1.4133 - mse: 2.8723 - val_loss: 0.4705 - val_mae: 0.0507 - val_mse: 0.0031 - learning_rate: 2.0000e-05\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 3.2573 - mae: 1.6160 - mse: 2.7900 - val_loss: 0.4704 - val_mae: 0.0506 - val_mse: 0.0031 - learning_rate: 2.0000e-05\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.8415 - mae: 1.1241 - mse: 1.3742 - val_loss: 0.4704 - val_mae: 0.0505 - val_mse: 0.0031 - learning_rate: 2.0000e-05\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.4019 - mae: 0.8226 - mse: 0.9346 - val_loss: 0.4704 - val_mae: 0.0505 - val_mse: 0.0031 - learning_rate: 2.0000e-05\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 2.7508 - mae: 1.0724 - mse: 2.2835 - val_loss: 0.4704 - val_mae: 0.0506 - val_mse: 0.0031 - learning_rate: 2.0000e-05\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.3656 - mae: 0.9151 - mse: 0.8983 - val_loss: 0.4704 - val_mae: 0.0506 - val_mse: 0.0031 - learning_rate: 2.0000e-05\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.9460 - mae: 0.6319 - mse: 0.4786 - val_loss: 0.4704 - val_mae: 0.0505 - val_mse: 0.0031 - learning_rate: 1.0000e-05\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 1.5598 - mae: 0.8591 - mse: 1.0924 - val_loss: 0.4704 - val_mae: 0.0505 - val_mse: 0.0031 - learning_rate: 1.0000e-05\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.9893 - mae: 0.9694 - mse: 1.5220 - val_loss: 0.4704 - val_mae: 0.0504 - val_mse: 0.0031 - learning_rate: 1.0000e-05\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 0.8655 - mae: 0.5852 - mse: 0.3981 - val_loss: 0.4704 - val_mae: 0.0504 - val_mse: 0.0031 - learning_rate: 1.0000e-05\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 2.7508 - mae: 1.2552 - mse: 2.2835 - val_loss: 0.4704 - val_mae: 0.0502 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 2.3717 - mae: 1.2990 - mse: 1.9044 - val_loss: 0.4704 - val_mae: 0.0501 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.9301 - mae: 1.0740 - mse: 1.4628 - val_loss: 0.4703 - val_mae: 0.0500 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.7549 - mae: 1.0556 - mse: 1.2876 - val_loss: 0.4704 - val_mae: 0.0501 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 1.9397 - mae: 1.1292 - mse: 1.4724 - val_loss: 0.4703 - val_mae: 0.0501 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 2.1268 - mae: 1.2208 - mse: 1.6594 - val_loss: 0.4703 - val_mae: 0.0500 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 2.2556 - mae: 1.2538 - mse: 1.7883 - val_loss: 0.4703 - val_mae: 0.0498 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 2.2937 - mae: 1.1307 - mse: 1.8264 - val_loss: 0.4703 - val_mae: 0.0498 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 2.4753 - mae: 1.3415 - mse: 2.0080 - val_loss: 0.4703 - val_mae: 0.0496 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 2.1220 - mae: 1.1359 - mse: 1.6546 - val_loss: 0.4703 - val_mae: 0.0494 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.8687 - mae: 0.9069 - mse: 1.4014 - val_loss: 0.4703 - val_mae: 0.0494 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 1.0577 - mae: 0.6232 - mse: 0.5904 - val_loss: 0.4703 - val_mae: 0.0493 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 1.8898 - mae: 1.0772 - mse: 1.4225 - val_loss: 0.4702 - val_mae: 0.0491 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 1.0476 - mae: 0.6975 - mse: 0.5803 - val_loss: 0.4702 - val_mae: 0.0489 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 2.4004 - mae: 1.3200 - mse: 1.9331 - val_loss: 0.4702 - val_mae: 0.0488 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 1.4556 - mae: 0.9435 - mse: 0.9883 - val_loss: 0.4702 - val_mae: 0.0486 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 1.8213 - mae: 0.8671 - mse: 1.3539 - val_loss: 0.4702 - val_mae: 0.0484 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 2.3180 - mae: 1.0701 - mse: 1.8507 - val_loss: 0.4702 - val_mae: 0.0483 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 1.3794 - mae: 0.8518 - mse: 0.9121 - val_loss: 0.4702 - val_mae: 0.0480 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 1.0441 - mae: 0.7022 - mse: 0.5767 - val_loss: 0.4702 - val_mae: 0.0478 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 2.0602 - mae: 1.1203 - mse: 1.5929 - val_loss: 0.4701 - val_mae: 0.0476 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 1.9059 - mae: 0.9137 - mse: 1.4386 - val_loss: 0.4701 - val_mae: 0.0473 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - loss: 1.1563 - mae: 0.6189 - mse: 0.6890 - val_loss: 0.4701 - val_mae: 0.0473 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 2.5325 - mae: 1.1852 - mse: 2.0652 - val_loss: 0.4701 - val_mae: 0.0474 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 1.5556 - mae: 1.0195 - mse: 1.0883 - val_loss: 0.4701 - val_mae: 0.0471 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 1.5742 - mae: 1.0170 - mse: 1.1069 - val_loss: 0.4702 - val_mae: 0.0470 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.9103 - mae: 0.8111 - mse: 1.4430 - val_loss: 0.4701 - val_mae: 0.0469 - val_mse: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 1.8327 - mae: 1.1383 - mse: 1.3654 - val_loss: 0.4702 - val_mae: 0.0467 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 2.2684 - mae: 1.1299 - mse: 1.8011 - val_loss: 0.4702 - val_mae: 0.0466 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - loss: 1.2990 - mae: 0.7547 - mse: 0.8317 - val_loss: 0.4701 - val_mae: 0.0467 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - loss: 1.3424 - mae: 0.6468 - mse: 0.8751 - val_loss: 0.4702 - val_mae: 0.0467 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - loss: 1.4110 - mae: 0.8979 - mse: 0.9437 - val_loss: 0.4702 - val_mae: 0.0466 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.4593 - mae: 0.8630 - mse: 0.9920 - val_loss: 0.4702 - val_mae: 0.0466 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 1.5681 - mae: 0.9216 - mse: 1.1009 - val_loss: 0.4702 - val_mae: 0.0465 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - loss: 1.9345 - mae: 1.1766 - mse: 1.4673 - val_loss: 0.4702 - val_mae: 0.0464 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 2.0198 - mae: 1.1487 - mse: 1.5525 - val_loss: 0.4702 - val_mae: 0.0463 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 1.6072 - mae: 0.9857 - mse: 1.1400 - val_loss: 0.4702 - val_mae: 0.0465 - val_mse: 0.0029 - learning_rate: 1.0000e-05\n",
            "Grupo 35 - RMSE: 0.000038, MAE: 0.000033, sMAPE: 2.63%\n",
            "\n",
            "Treinando modelo para grupo etário 40...\n",
            "Grupo 40: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - loss: 11.6426 - mae: 3.2499 - mse: 11.1725 - val_loss: 0.4753 - val_mae: 0.0570 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - loss: 6.6199 - mae: 2.4183 - mse: 6.1500 - val_loss: 0.4751 - val_mae: 0.0559 - val_mse: 0.0053 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 7.6681 - mae: 2.5982 - mse: 7.1983 - val_loss: 0.4751 - val_mae: 0.0563 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 11.6456 - mae: 2.8941 - mse: 11.1759 - val_loss: 0.4751 - val_mae: 0.0566 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 6.5244 - mae: 2.4497 - mse: 6.0547 - val_loss: 0.4751 - val_mae: 0.0573 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 7.7702 - mae: 2.6458 - mse: 7.3005 - val_loss: 0.4752 - val_mae: 0.0580 - val_mse: 0.0056 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 8.8416 - mae: 2.7586 - mse: 8.3719 - val_loss: 0.4753 - val_mae: 0.0589 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 6.4122 - mae: 2.2956 - mse: 5.9426 - val_loss: 0.4757 - val_mae: 0.0616 - val_mse: 0.0060 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 9.6327 - mae: 2.7553 - mse: 9.1631 - val_loss: 0.4758 - val_mae: 0.0625 - val_mse: 0.0061 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 8.1024 - mae: 2.6388 - mse: 7.6327 - val_loss: 0.4759 - val_mae: 0.0630 - val_mse: 0.0062 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 12.3240 - mae: 3.2510 - mse: 11.8543 - val_loss: 0.4760 - val_mae: 0.0641 - val_mse: 0.0063 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 7.4886 - mae: 2.5845 - mse: 7.0190 - val_loss: 0.4761 - val_mae: 0.0651 - val_mse: 0.0065 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 6.8652 - mae: 2.2908 - mse: 6.3956 - val_loss: 0.4763 - val_mae: 0.0664 - val_mse: 0.0066 - learning_rate: 2.0000e-05\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 5.9120 - mae: 2.0783 - mse: 5.4424 - val_loss: 0.4764 - val_mae: 0.0673 - val_mse: 0.0068 - learning_rate: 2.0000e-05\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 8.0896 - mae: 2.6563 - mse: 7.6199 - val_loss: 0.4768 - val_mae: 0.0700 - val_mse: 0.0071 - learning_rate: 2.0000e-05\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 10.9012 - mae: 3.1156 - mse: 10.4315 - val_loss: 0.4769 - val_mae: 0.0710 - val_mse: 0.0073 - learning_rate: 2.0000e-05\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 6.5537 - mae: 2.3093 - mse: 6.0841 - val_loss: 0.4771 - val_mae: 0.0721 - val_mse: 0.0074 - learning_rate: 2.0000e-05\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 10.2123 - mae: 3.0461 - mse: 9.7426 - val_loss: 0.4774 - val_mae: 0.0741 - val_mse: 0.0077 - learning_rate: 1.0000e-05\n",
            "Grupo 40 - RMSE: 0.000074, MAE: 0.000057, sMAPE: 3.10%\n",
            "\n",
            "Treinando modelo para grupo etário 45...\n",
            "Grupo 45: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - loss: 2.3335 - mae: 1.3130 - mse: 1.8624 - val_loss: 0.4780 - val_mae: 0.0711 - val_mse: 0.0074 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 3.1574 - mae: 1.5651 - mse: 2.6867 - val_loss: 0.4772 - val_mae: 0.0671 - val_mse: 0.0068 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 3.6875 - mae: 1.4651 - mse: 3.2171 - val_loss: 0.4765 - val_mae: 0.0623 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 3.4855 - mae: 1.7073 - mse: 3.0152 - val_loss: 0.4758 - val_mae: 0.0592 - val_mse: 0.0055 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 9.0068 - mae: 2.4592 - mse: 8.5366 - val_loss: 0.4754 - val_mae: 0.0572 - val_mse: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 3.4179 - mae: 1.4453 - mse: 2.9477 - val_loss: 0.4748 - val_mae: 0.0542 - val_mse: 0.0047 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 3.9185 - mae: 1.5666 - mse: 3.4484 - val_loss: 0.4743 - val_mae: 0.0511 - val_mse: 0.0042 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - loss: 2.8416 - mae: 1.3069 - mse: 2.3715 - val_loss: 0.4740 - val_mae: 0.0497 - val_mse: 0.0039 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 4.5760 - mae: 1.9272 - mse: 4.1059 - val_loss: 0.4735 - val_mae: 0.0487 - val_mse: 0.0035 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.6103 - mae: 0.8988 - mse: 1.1402 - val_loss: 0.4732 - val_mae: 0.0482 - val_mse: 0.0032 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 2.3709 - mae: 1.2696 - mse: 1.9009 - val_loss: 0.4729 - val_mae: 0.0468 - val_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - loss: 5.5410 - mae: 1.8554 - mse: 5.0711 - val_loss: 0.4726 - val_mae: 0.0460 - val_mse: 0.0027 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 1.3064 - mae: 0.7377 - mse: 0.8365 - val_loss: 0.4724 - val_mae: 0.0450 - val_mse: 0.0025 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 1.6664 - mae: 0.8635 - mse: 1.1965 - val_loss: 0.4723 - val_mae: 0.0440 - val_mse: 0.0024 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 3.1218 - mae: 1.5366 - mse: 2.6520 - val_loss: 0.4721 - val_mae: 0.0431 - val_mse: 0.0023 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 2.9165 - mae: 1.4661 - mse: 2.4467 - val_loss: 0.4720 - val_mae: 0.0421 - val_mse: 0.0023 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 3.4664 - mae: 1.4308 - mse: 2.9966 - val_loss: 0.4720 - val_mae: 0.0411 - val_mse: 0.0023 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 1.2783 - mae: 0.7079 - mse: 0.8086 - val_loss: 0.4720 - val_mae: 0.0411 - val_mse: 0.0023 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 3.4293 - mae: 1.2204 - mse: 2.9596 - val_loss: 0.4720 - val_mae: 0.0420 - val_mse: 0.0023 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 2.9652 - mae: 1.4422 - mse: 2.4956 - val_loss: 0.4721 - val_mae: 0.0427 - val_mse: 0.0024 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 1.9243 - mae: 1.0373 - mse: 1.4546 - val_loss: 0.4721 - val_mae: 0.0434 - val_mse: 0.0025 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 3.4409 - mae: 1.3178 - mse: 2.9713 - val_loss: 0.4723 - val_mae: 0.0444 - val_mse: 0.0027 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 2.4270 - mae: 1.2930 - mse: 1.9574 - val_loss: 0.4723 - val_mae: 0.0446 - val_mse: 0.0028 - learning_rate: 1.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 2.4801 - mae: 1.2056 - mse: 2.0105 - val_loss: 0.4724 - val_mae: 0.0450 - val_mse: 0.0029 - learning_rate: 1.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 2.2684 - mae: 1.0948 - mse: 1.7988 - val_loss: 0.4725 - val_mae: 0.0452 - val_mse: 0.0029 - learning_rate: 1.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 1.6108 - mae: 1.0064 - mse: 1.1413 - val_loss: 0.4724 - val_mae: 0.0451 - val_mse: 0.0029 - learning_rate: 1.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 2.2171 - mae: 1.2275 - mse: 1.7476 - val_loss: 0.4724 - val_mae: 0.0453 - val_mse: 0.0029 - learning_rate: 1.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 2.0932 - mae: 0.9933 - mse: 1.6236 - val_loss: 0.4724 - val_mae: 0.0452 - val_mse: 0.0029 - learning_rate: 2.0000e-05\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 2.6564 - mae: 1.1546 - mse: 2.1868 - val_loss: 0.4724 - val_mae: 0.0452 - val_mse: 0.0029 - learning_rate: 2.0000e-05\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 3.3224 - mae: 1.2272 - mse: 2.8529 - val_loss: 0.4724 - val_mae: 0.0454 - val_mse: 0.0029 - learning_rate: 2.0000e-05\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 1.6812 - mae: 1.0674 - mse: 1.2116 - val_loss: 0.4725 - val_mae: 0.0456 - val_mse: 0.0030 - learning_rate: 2.0000e-05\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 4.3931 - mae: 1.5433 - mse: 3.9235 - val_loss: 0.4725 - val_mae: 0.0455 - val_mse: 0.0029 - learning_rate: 2.0000e-05\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 3.9902 - mae: 1.7535 - mse: 3.5207 - val_loss: 0.4726 - val_mae: 0.0458 - val_mse: 0.0030 - learning_rate: 1.0000e-05\n",
            "Grupo 45 - RMSE: 0.000075, MAE: 0.000064, sMAPE: 2.37%\n",
            "\n",
            "Treinando modelo para grupo etário 50...\n",
            "Grupo 50: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 1.6054 - mae: 0.7662 - mse: 1.1346 - val_loss: 0.4837 - val_mae: 0.1040 - val_mse: 0.0134 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: 3.1275 - mae: 1.3061 - mse: 2.6572 - val_loss: 0.4843 - val_mae: 0.1074 - val_mse: 0.0142 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 1.8334 - mae: 1.1200 - mse: 1.3632 - val_loss: 0.4845 - val_mae: 0.1085 - val_mse: 0.0144 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.3090 - mae: 0.7449 - mse: 0.8390 - val_loss: 0.4843 - val_mae: 0.1082 - val_mse: 0.0143 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 1.1691 - mae: 0.7609 - mse: 0.6992 - val_loss: 0.4842 - val_mae: 0.1082 - val_mse: 0.0143 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - loss: 1.2207 - mae: 0.7695 - mse: 0.7508 - val_loss: 0.4843 - val_mae: 0.1095 - val_mse: 0.0146 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 1.2236 - mae: 0.6575 - mse: 0.7539 - val_loss: 0.4843 - val_mae: 0.1096 - val_mse: 0.0146 - learning_rate: 1.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 1.8938 - mae: 1.0796 - mse: 1.4241 - val_loss: 0.4843 - val_mae: 0.1095 - val_mse: 0.0146 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.7243 - mae: 0.4096 - mse: 0.2546 - val_loss: 0.4842 - val_mae: 0.1093 - val_mse: 0.0146 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.8659 - mae: 0.5595 - mse: 0.3963 - val_loss: 0.4842 - val_mae: 0.1091 - val_mse: 0.0145 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 1.6795 - mae: 0.6125 - mse: 1.2099 - val_loss: 0.4841 - val_mae: 0.1087 - val_mse: 0.0144 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.6178 - mae: 0.3461 - mse: 0.1481 - val_loss: 0.4838 - val_mae: 0.1076 - val_mse: 0.0142 - learning_rate: 2.0000e-05\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.1920 - mae: 0.8236 - mse: 0.7224 - val_loss: 0.4840 - val_mae: 0.1084 - val_mse: 0.0143 - learning_rate: 2.0000e-05\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.9802 - mae: 0.5298 - mse: 0.5106 - val_loss: 0.4838 - val_mae: 0.1076 - val_mse: 0.0142 - learning_rate: 2.0000e-05\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.3841 - mae: 0.7542 - mse: 0.9145 - val_loss: 0.4838 - val_mae: 0.1077 - val_mse: 0.0142 - learning_rate: 2.0000e-05\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 1.7608 - mae: 0.9023 - mse: 1.2912 - val_loss: 0.4838 - val_mae: 0.1077 - val_mse: 0.0142 - learning_rate: 2.0000e-05\n",
            "Grupo 50 - RMSE: 0.000248, MAE: 0.000223, sMAPE: 5.67%\n",
            "\n",
            "Treinando modelo para grupo etário 55...\n",
            "Grupo 55: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - loss: 1.4059 - mae: 0.9093 - mse: 0.9359 - val_loss: 0.4873 - val_mae: 0.1232 - val_mse: 0.0177 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 3.7894 - mae: 1.7487 - mse: 3.3198 - val_loss: 0.4871 - val_mae: 0.1230 - val_mse: 0.0177 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.2058 - mae: 0.6655 - mse: 0.7363 - val_loss: 0.4868 - val_mae: 0.1220 - val_mse: 0.0174 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 0.9896 - mae: 0.6162 - mse: 0.5203 - val_loss: 0.4868 - val_mae: 0.1225 - val_mse: 0.0175 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.8066 - mae: 0.4859 - mse: 0.3374 - val_loss: 0.4869 - val_mae: 0.1237 - val_mse: 0.0178 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 2.2649 - mae: 1.2043 - mse: 1.7957 - val_loss: 0.4870 - val_mae: 0.1244 - val_mse: 0.0180 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.7977 - mae: 1.0505 - mse: 1.3287 - val_loss: 0.4873 - val_mae: 0.1262 - val_mse: 0.0184 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.0161 - mae: 0.7047 - mse: 0.5471 - val_loss: 0.4874 - val_mae: 0.1270 - val_mse: 0.0186 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.7726 - mae: 0.3847 - mse: 0.3038 - val_loss: 0.4875 - val_mae: 0.1274 - val_mse: 0.0187 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.5846 - mae: 0.2759 - mse: 0.1157 - val_loss: 0.4875 - val_mae: 0.1276 - val_mse: 0.0187 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 2.0782 - mae: 1.0934 - mse: 1.6094 - val_loss: 0.4878 - val_mae: 0.1286 - val_mse: 0.0189 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 2.4671 - mae: 1.2175 - mse: 1.9983 - val_loss: 0.4878 - val_mae: 0.1288 - val_mse: 0.0190 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 2.3588 - mae: 1.3170 - mse: 1.8900 - val_loss: 0.4878 - val_mae: 0.1287 - val_mse: 0.0190 - learning_rate: 1.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.9112 - mae: 0.5085 - mse: 0.4424 - val_loss: 0.4876 - val_mae: 0.1283 - val_mse: 0.0189 - learning_rate: 2.0000e-05\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.6079 - mae: 1.0088 - mse: 1.1391 - val_loss: 0.4877 - val_mae: 0.1287 - val_mse: 0.0190 - learning_rate: 2.0000e-05\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.6704 - mae: 0.8715 - mse: 1.2017 - val_loss: 0.4877 - val_mae: 0.1286 - val_mse: 0.0190 - learning_rate: 2.0000e-05\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.6830 - mae: 0.3981 - mse: 0.2142 - val_loss: 0.4873 - val_mae: 0.1270 - val_mse: 0.0186 - learning_rate: 2.0000e-05\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 3.8490 - mae: 1.5677 - mse: 3.3802 - val_loss: 0.4871 - val_mae: 0.1260 - val_mse: 0.0183 - learning_rate: 2.0000e-05\n",
            "Grupo 55 - RMSE: 0.000438, MAE: 0.000405, sMAPE: 6.93%\n",
            "\n",
            "Treinando modelo para grupo etário 60...\n",
            "Grupo 60: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 2.5097 - mae: 1.3423 - mse: 2.0365 - val_loss: 0.4945 - val_mae: 0.1446 - val_mse: 0.0218 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - loss: 0.5662 - mae: 0.2196 - mse: 0.0936 - val_loss: 0.4940 - val_mae: 0.1442 - val_mse: 0.0217 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 2.1999 - mae: 1.1749 - mse: 1.7277 - val_loss: 0.4933 - val_mae: 0.1426 - val_mse: 0.0213 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.1501 - mae: 0.7457 - mse: 0.6780 - val_loss: 0.4932 - val_mae: 0.1429 - val_mse: 0.0213 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.4149 - mae: 0.8697 - mse: 0.9430 - val_loss: 0.4938 - val_mae: 0.1455 - val_mse: 0.0221 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 1.0929 - mae: 0.7322 - mse: 0.6212 - val_loss: 0.4935 - val_mae: 0.1449 - val_mse: 0.0219 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 1.0197 - mae: 0.5827 - mse: 0.5481 - val_loss: 0.4938 - val_mae: 0.1464 - val_mse: 0.0223 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 8.0668 - mae: 2.0949 - mse: 7.5953 - val_loss: 0.4942 - val_mae: 0.1478 - val_mse: 0.0228 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - loss: 2.0121 - mae: 0.9661 - mse: 1.5407 - val_loss: 0.4945 - val_mae: 0.1491 - val_mse: 0.0231 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.9131 - mae: 0.5701 - mse: 0.4417 - val_loss: 0.4952 - val_mae: 0.1514 - val_mse: 0.0238 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 1.8226 - mae: 1.0759 - mse: 1.3512 - val_loss: 0.4958 - val_mae: 0.1536 - val_mse: 0.0244 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 4.5620 - mae: 1.6380 - mse: 4.0906 - val_loss: 0.4964 - val_mae: 0.1554 - val_mse: 0.0250 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 2.8637 - mae: 1.4580 - mse: 2.3924 - val_loss: 0.4968 - val_mae: 0.1567 - val_mse: 0.0254 - learning_rate: 1.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 4.2194 - mae: 1.6530 - mse: 3.7480 - val_loss: 0.4976 - val_mae: 0.1593 - val_mse: 0.0262 - learning_rate: 2.0000e-05\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - loss: 1.8887 - mae: 1.0284 - mse: 1.4174 - val_loss: 0.4978 - val_mae: 0.1602 - val_mse: 0.0265 - learning_rate: 2.0000e-05\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 3.5155 - mae: 1.4373 - mse: 3.0442 - val_loss: 0.4979 - val_mae: 0.1604 - val_mse: 0.0266 - learning_rate: 2.0000e-05\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 3.1722 - mae: 1.4144 - mse: 2.7009 - val_loss: 0.4978 - val_mae: 0.1603 - val_mse: 0.0265 - learning_rate: 2.0000e-05\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.9080 - mae: 0.5291 - mse: 0.4367 - val_loss: 0.4982 - val_mae: 0.1614 - val_mse: 0.0269 - learning_rate: 2.0000e-05\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.0079 - mae: 0.5790 - mse: 0.5366 - val_loss: 0.4993 - val_mae: 0.1649 - val_mse: 0.0280 - learning_rate: 1.0000e-05\n",
            "Grupo 60 - RMSE: 0.000699, MAE: 0.000684, sMAPE: 7.69%\n",
            "\n",
            "Treinando modelo para grupo etário 65...\n",
            "Grupo 65: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 1.6168 - mae: 0.8742 - mse: 1.1461 - val_loss: 0.4884 - val_mae: 0.1296 - val_mse: 0.0180 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - loss: 1.9959 - mae: 1.0613 - mse: 1.5255 - val_loss: 0.4888 - val_mae: 0.1318 - val_mse: 0.0186 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 2.5570 - mae: 1.2886 - mse: 2.0868 - val_loss: 0.4892 - val_mae: 0.1338 - val_mse: 0.0192 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 0.9159 - mae: 0.5419 - mse: 0.4459 - val_loss: 0.4891 - val_mae: 0.1339 - val_mse: 0.0192 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.1227 - mae: 0.6938 - mse: 0.6528 - val_loss: 0.4891 - val_mae: 0.1342 - val_mse: 0.0193 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 3.4716 - mae: 1.2716 - mse: 3.0017 - val_loss: 0.4891 - val_mae: 0.1343 - val_mse: 0.0193 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.9074 - mae: 0.8511 - mse: 1.4376 - val_loss: 0.4891 - val_mae: 0.1344 - val_mse: 0.0193 - learning_rate: 1.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - loss: 1.2033 - mae: 0.7051 - mse: 0.7335 - val_loss: 0.4893 - val_mae: 0.1351 - val_mse: 0.0195 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 1.5593 - mae: 0.8880 - mse: 1.0895 - val_loss: 0.4891 - val_mae: 0.1346 - val_mse: 0.0194 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.2822 - mae: 0.8098 - mse: 0.8125 - val_loss: 0.4896 - val_mae: 0.1363 - val_mse: 0.0199 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 1.4076 - mae: 0.8412 - mse: 0.9378 - val_loss: 0.4895 - val_mae: 0.1361 - val_mse: 0.0198 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - loss: 1.3406 - mae: 0.7784 - mse: 0.8709 - val_loss: 0.4897 - val_mae: 0.1369 - val_mse: 0.0200 - learning_rate: 2.0000e-05\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.9614 - mae: 0.5781 - mse: 0.4917 - val_loss: 0.4898 - val_mae: 0.1372 - val_mse: 0.0201 - learning_rate: 2.0000e-05\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 1.3417 - mae: 0.7199 - mse: 0.8720 - val_loss: 0.4899 - val_mae: 0.1374 - val_mse: 0.0202 - learning_rate: 2.0000e-05\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 0.7358 - mae: 0.3955 - mse: 0.2661 - val_loss: 0.4899 - val_mae: 0.1377 - val_mse: 0.0202 - learning_rate: 2.0000e-05\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 1.7215 - mae: 0.9489 - mse: 1.2518 - val_loss: 0.4900 - val_mae: 0.1380 - val_mse: 0.0203 - learning_rate: 2.0000e-05\n",
            "Grupo 65 - RMSE: 0.000854, MAE: 0.000824, sMAPE: 5.97%\n",
            "\n",
            "Treinando modelo para grupo etário 70...\n",
            "Grupo 70: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - loss: 2.0217 - mae: 1.0784 - mse: 1.5539 - val_loss: 0.4923 - val_mae: 0.1471 - val_mse: 0.0249 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 3.4926 - mae: 1.5140 - mse: 3.0252 - val_loss: 0.4916 - val_mae: 0.1449 - val_mse: 0.0243 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.7797 - mae: 0.9964 - mse: 1.3125 - val_loss: 0.4911 - val_mae: 0.1437 - val_mse: 0.0239 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.8371 - mae: 0.8992 - mse: 1.3699 - val_loss: 0.4905 - val_mae: 0.1417 - val_mse: 0.0234 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 0.9771 - mae: 0.5928 - mse: 0.5100 - val_loss: 0.4900 - val_mae: 0.1404 - val_mse: 0.0230 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 1.8802 - mae: 1.0364 - mse: 1.4131 - val_loss: 0.4894 - val_mae: 0.1382 - val_mse: 0.0224 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 4.4370 - mae: 1.7676 - mse: 3.9700 - val_loss: 0.4888 - val_mae: 0.1364 - val_mse: 0.0219 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 2.1018 - mae: 1.0579 - mse: 1.6349 - val_loss: 0.4883 - val_mae: 0.1345 - val_mse: 0.0214 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 1.5607 - mae: 0.8787 - mse: 1.0938 - val_loss: 0.4881 - val_mae: 0.1339 - val_mse: 0.0212 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - loss: 2.9942 - mae: 1.2121 - mse: 2.5273 - val_loss: 0.4877 - val_mae: 0.1323 - val_mse: 0.0208 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 1.5736 - mae: 0.6917 - mse: 1.1067 - val_loss: 0.4873 - val_mae: 0.1309 - val_mse: 0.0204 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 1.6837 - mae: 0.7702 - mse: 1.2169 - val_loss: 0.4868 - val_mae: 0.1294 - val_mse: 0.0200 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1.1058 - mae: 0.5522 - mse: 0.6390 - val_loss: 0.4869 - val_mae: 0.1298 - val_mse: 0.0201 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - loss: 1.3555 - mae: 0.7811 - mse: 0.8887 - val_loss: 0.4865 - val_mae: 0.1283 - val_mse: 0.0197 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - loss: 2.0661 - mae: 1.0293 - mse: 1.5994 - val_loss: 0.4859 - val_mae: 0.1260 - val_mse: 0.0191 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 2.7179 - mae: 1.2561 - mse: 2.2512 - val_loss: 0.4855 - val_mae: 0.1248 - val_mse: 0.0188 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 2.3507 - mae: 1.2284 - mse: 1.8840 - val_loss: 0.4848 - val_mae: 0.1220 - val_mse: 0.0181 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 1.6094 - mae: 0.8492 - mse: 1.1427 - val_loss: 0.4844 - val_mae: 0.1200 - val_mse: 0.0177 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 3.6575 - mae: 1.6733 - mse: 3.1909 - val_loss: 0.4839 - val_mae: 0.1181 - val_mse: 0.0172 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 2.1985 - mae: 0.9753 - mse: 1.7318 - val_loss: 0.4831 - val_mae: 0.1147 - val_mse: 0.0164 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.6779 - mae: 0.9875 - mse: 1.2113 - val_loss: 0.4824 - val_mae: 0.1117 - val_mse: 0.0158 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.1828 - mae: 0.7343 - mse: 0.7162 - val_loss: 0.4816 - val_mae: 0.1082 - val_mse: 0.0150 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.3948 - mae: 0.7734 - mse: 0.9282 - val_loss: 0.4810 - val_mae: 0.1055 - val_mse: 0.0145 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 1.1901 - mae: 0.6589 - mse: 0.7235 - val_loss: 0.4804 - val_mae: 0.1026 - val_mse: 0.0138 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.4132 - mae: 0.7027 - mse: 0.9466 - val_loss: 0.4797 - val_mae: 0.0995 - val_mse: 0.0132 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.7494 - mae: 0.9885 - mse: 1.2829 - val_loss: 0.4791 - val_mae: 0.0963 - val_mse: 0.0126 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 2.5712 - mae: 1.4173 - mse: 2.1047 - val_loss: 0.4785 - val_mae: 0.0933 - val_mse: 0.0120 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 1.2454 - mae: 0.8408 - mse: 0.7789 - val_loss: 0.4782 - val_mae: 0.0918 - val_mse: 0.0117 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.9483 - mae: 0.6441 - mse: 0.4819 - val_loss: 0.4776 - val_mae: 0.0886 - val_mse: 0.0111 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - loss: 2.3847 - mae: 1.0212 - mse: 1.9182 - val_loss: 0.4771 - val_mae: 0.0857 - val_mse: 0.0107 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 1.5273 - mae: 0.8029 - mse: 1.0609 - val_loss: 0.4767 - val_mae: 0.0838 - val_mse: 0.0103 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 1.1074 - mae: 0.7114 - mse: 0.6410 - val_loss: 0.4766 - val_mae: 0.0828 - val_mse: 0.0102 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 1.2073 - mae: 0.6651 - mse: 0.7410 - val_loss: 0.4762 - val_mae: 0.0806 - val_mse: 0.0098 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.5128 - mae: 0.6737 - mse: 1.0465 - val_loss: 0.4755 - val_mae: 0.0772 - val_mse: 0.0092 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.5489 - mae: 0.2179 - mse: 0.0826 - val_loss: 0.4752 - val_mae: 0.0758 - val_mse: 0.0089 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 1.2043 - mae: 0.8134 - mse: 0.7380 - val_loss: 0.4749 - val_mae: 0.0748 - val_mse: 0.0086 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 1.0238 - mae: 0.5889 - mse: 0.5575 - val_loss: 0.4747 - val_mae: 0.0741 - val_mse: 0.0085 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 1.0840 - mae: 0.6198 - mse: 0.6177 - val_loss: 0.4743 - val_mae: 0.0723 - val_mse: 0.0080 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - loss: 1.7575 - mae: 0.8880 - mse: 1.2913 - val_loss: 0.4742 - val_mae: 0.0719 - val_mse: 0.0079 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 2.4082 - mae: 1.0803 - mse: 1.9420 - val_loss: 0.4740 - val_mae: 0.0712 - val_mse: 0.0078 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 1.9673 - mae: 0.9693 - mse: 1.5011 - val_loss: 0.4740 - val_mae: 0.0713 - val_mse: 0.0078 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 1.9777 - mae: 1.1436 - mse: 1.5115 - val_loss: 0.4740 - val_mae: 0.0713 - val_mse: 0.0079 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - loss: 1.9716 - mae: 0.9497 - mse: 1.5054 - val_loss: 0.4738 - val_mae: 0.0708 - val_mse: 0.0077 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.9310 - mae: 0.4816 - mse: 0.4649 - val_loss: 0.4736 - val_mae: 0.0698 - val_mse: 0.0075 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.0706 - mae: 0.7107 - mse: 0.6045 - val_loss: 0.4732 - val_mae: 0.0680 - val_mse: 0.0071 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - loss: 0.8800 - mae: 0.5991 - mse: 0.4139 - val_loss: 0.4730 - val_mae: 0.0669 - val_mse: 0.0069 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 2.2709 - mae: 1.0478 - mse: 1.8049 - val_loss: 0.4728 - val_mae: 0.0665 - val_mse: 0.0068 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.9854 - mae: 1.0694 - mse: 1.5194 - val_loss: 0.4726 - val_mae: 0.0653 - val_mse: 0.0066 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.8999 - mae: 1.0545 - mse: 1.4339 - val_loss: 0.4723 - val_mae: 0.0640 - val_mse: 0.0064 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 2.2289 - mae: 1.0103 - mse: 1.7630 - val_loss: 0.4721 - val_mae: 0.0632 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1.9736 - mae: 1.0952 - mse: 1.5077 - val_loss: 0.4721 - val_mae: 0.0631 - val_mse: 0.0062 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 1.4408 - mae: 0.8409 - mse: 0.9749 - val_loss: 0.4719 - val_mae: 0.0619 - val_mse: 0.0060 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.9471 - mae: 0.9693 - mse: 1.4812 - val_loss: 0.4716 - val_mae: 0.0603 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 1.6220 - mae: 0.9660 - mse: 1.1561 - val_loss: 0.4713 - val_mae: 0.0583 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.1792 - mae: 0.8209 - mse: 0.7133 - val_loss: 0.4711 - val_mae: 0.0577 - val_mse: 0.0052 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.6367 - mae: 0.3449 - mse: 0.1709 - val_loss: 0.4709 - val_mae: 0.0573 - val_mse: 0.0051 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.7077 - mae: 0.3783 - mse: 0.2419 - val_loss: 0.4709 - val_mae: 0.0573 - val_mse: 0.0051 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - loss: 3.4753 - mae: 1.2287 - mse: 3.0094 - val_loss: 0.4708 - val_mae: 0.0571 - val_mse: 0.0050 - learning_rate: 5.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 1.5896 - mae: 0.9650 - mse: 1.1238 - val_loss: 0.4708 - val_mae: 0.0572 - val_mse: 0.0050 - learning_rate: 5.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - loss: 1.6563 - mae: 0.7229 - mse: 1.1905 - val_loss: 0.4707 - val_mae: 0.0569 - val_mse: 0.0049 - learning_rate: 5.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - loss: 2.4150 - mae: 1.2936 - mse: 1.9493 - val_loss: 0.4706 - val_mae: 0.0567 - val_mse: 0.0048 - learning_rate: 5.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 1.7640 - mae: 1.0051 - mse: 1.2983 - val_loss: 0.4704 - val_mae: 0.0561 - val_mse: 0.0046 - learning_rate: 5.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 2.0073 - mae: 1.0385 - mse: 1.5416 - val_loss: 0.4703 - val_mae: 0.0560 - val_mse: 0.0046 - learning_rate: 5.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 1.2425 - mae: 0.7623 - mse: 0.7768 - val_loss: 0.4701 - val_mae: 0.0555 - val_mse: 0.0044 - learning_rate: 5.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 1.3356 - mae: 0.8826 - mse: 0.8699 - val_loss: 0.4700 - val_mae: 0.0551 - val_mse: 0.0043 - learning_rate: 5.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 1.3109 - mae: 0.8336 - mse: 0.8452 - val_loss: 0.4699 - val_mae: 0.0548 - val_mse: 0.0042 - learning_rate: 5.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 2.6545 - mae: 1.1186 - mse: 2.1889 - val_loss: 0.4697 - val_mae: 0.0542 - val_mse: 0.0041 - learning_rate: 5.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.9051 - mae: 0.6109 - mse: 0.4395 - val_loss: 0.4696 - val_mae: 0.0540 - val_mse: 0.0040 - learning_rate: 5.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - loss: 1.0333 - mae: 0.6065 - mse: 0.5677 - val_loss: 0.4695 - val_mae: 0.0537 - val_mse: 0.0039 - learning_rate: 5.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.9304 - mae: 1.0456 - mse: 1.4648 - val_loss: 0.4695 - val_mae: 0.0535 - val_mse: 0.0039 - learning_rate: 5.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: 0.6207 - mae: 0.3663 - mse: 0.1551 - val_loss: 0.4694 - val_mae: 0.0532 - val_mse: 0.0038 - learning_rate: 5.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.0105 - mae: 0.5958 - mse: 0.5449 - val_loss: 0.4694 - val_mae: 0.0530 - val_mse: 0.0038 - learning_rate: 5.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 1.7034 - mae: 0.7582 - mse: 1.2378 - val_loss: 0.4693 - val_mae: 0.0530 - val_mse: 0.0037 - learning_rate: 5.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 1.4443 - mae: 0.9118 - mse: 0.9787 - val_loss: 0.4692 - val_mae: 0.0524 - val_mse: 0.0036 - learning_rate: 5.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 1.3965 - mae: 0.8292 - mse: 0.9310 - val_loss: 0.4691 - val_mae: 0.0521 - val_mse: 0.0036 - learning_rate: 5.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.1165 - mae: 0.6417 - mse: 0.6510 - val_loss: 0.4692 - val_mae: 0.0524 - val_mse: 0.0036 - learning_rate: 5.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - loss: 1.4386 - mae: 0.9472 - mse: 0.9730 - val_loss: 0.4692 - val_mae: 0.0523 - val_mse: 0.0036 - learning_rate: 5.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.8228 - mae: 1.0094 - mse: 1.3572 - val_loss: 0.4691 - val_mae: 0.0522 - val_mse: 0.0036 - learning_rate: 5.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.6296 - mae: 0.3342 - mse: 0.1641 - val_loss: 0.4691 - val_mae: 0.0524 - val_mse: 0.0036 - learning_rate: 5.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1.9383 - mae: 1.0975 - mse: 1.4728 - val_loss: 0.4691 - val_mae: 0.0524 - val_mse: 0.0036 - learning_rate: 1.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.5957 - mae: 0.2500 - mse: 0.1302 - val_loss: 0.4692 - val_mae: 0.0526 - val_mse: 0.0037 - learning_rate: 1.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 1.1251 - mae: 0.7167 - mse: 0.6596 - val_loss: 0.4692 - val_mae: 0.0527 - val_mse: 0.0037 - learning_rate: 1.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 1.3587 - mae: 0.8020 - mse: 0.8932 - val_loss: 0.4692 - val_mae: 0.0525 - val_mse: 0.0037 - learning_rate: 1.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.2495 - mae: 0.6379 - mse: 0.7840 - val_loss: 0.4692 - val_mae: 0.0528 - val_mse: 0.0037 - learning_rate: 1.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.6778 - mae: 1.0785 - mse: 1.2123 - val_loss: 0.4692 - val_mae: 0.0528 - val_mse: 0.0037 - learning_rate: 2.0000e-05\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1.3231 - mae: 0.9120 - mse: 0.8576 - val_loss: 0.4692 - val_mae: 0.0527 - val_mse: 0.0037 - learning_rate: 2.0000e-05\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.7455 - mae: 0.4033 - mse: 0.2800 - val_loss: 0.4692 - val_mae: 0.0528 - val_mse: 0.0037 - learning_rate: 2.0000e-05\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.7831 - mae: 0.4989 - mse: 0.3176 - val_loss: 0.4692 - val_mae: 0.0527 - val_mse: 0.0037 - learning_rate: 2.0000e-05\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1.5271 - mae: 0.7515 - mse: 1.0616 - val_loss: 0.4692 - val_mae: 0.0526 - val_mse: 0.0037 - learning_rate: 2.0000e-05\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 1.5669 - mae: 0.8344 - mse: 1.1014 - val_loss: 0.4691 - val_mae: 0.0523 - val_mse: 0.0036 - learning_rate: 1.0000e-05\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.1988 - mae: 0.7674 - mse: 0.7333 - val_loss: 0.4692 - val_mae: 0.0527 - val_mse: 0.0037 - learning_rate: 1.0000e-05\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 1.4925 - mae: 0.8745 - mse: 1.0270 - val_loss: 0.4692 - val_mae: 0.0528 - val_mse: 0.0037 - learning_rate: 1.0000e-05\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 2.5676 - mae: 1.3185 - mse: 2.1021 - val_loss: 0.4692 - val_mae: 0.0527 - val_mse: 0.0037 - learning_rate: 1.0000e-05\n",
            "Grupo 70 - RMSE: 0.000439, MAE: 0.000383, sMAPE: 1.86%\n",
            "\n",
            "Treinando modelo para grupo etário 75...\n",
            "Grupo 75: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 0.6024 - mae: 0.2969 - mse: 0.1314 - val_loss: 0.4922 - val_mae: 0.1323 - val_mse: 0.0217 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - loss: 1.0401 - mae: 0.6378 - mse: 0.5696 - val_loss: 0.4918 - val_mae: 0.1321 - val_mse: 0.0215 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.8544 - mae: 0.4956 - mse: 0.3841 - val_loss: 0.4918 - val_mae: 0.1328 - val_mse: 0.0217 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 1.2442 - mae: 0.8443 - mse: 0.7742 - val_loss: 0.4913 - val_mae: 0.1317 - val_mse: 0.0214 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.7810 - mae: 0.3879 - mse: 0.3112 - val_loss: 0.4909 - val_mae: 0.1305 - val_mse: 0.0212 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 2.4245 - mae: 1.1486 - mse: 1.9548 - val_loss: 0.4903 - val_mae: 0.1286 - val_mse: 0.0207 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 1.8546 - mae: 0.9736 - mse: 1.3851 - val_loss: 0.4897 - val_mae: 0.1271 - val_mse: 0.0204 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - loss: 1.6008 - mae: 1.0025 - mse: 1.1314 - val_loss: 0.4894 - val_mae: 0.1260 - val_mse: 0.0201 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.2230 - mae: 0.7965 - mse: 0.7537 - val_loss: 0.4886 - val_mae: 0.1234 - val_mse: 0.0194 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 1.2042 - mae: 0.7432 - mse: 0.7350 - val_loss: 0.4882 - val_mae: 0.1224 - val_mse: 0.0192 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.7988 - mae: 0.4695 - mse: 0.3298 - val_loss: 0.4875 - val_mae: 0.1199 - val_mse: 0.0185 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.4743 - mae: 0.8433 - mse: 1.0053 - val_loss: 0.4872 - val_mae: 0.1192 - val_mse: 0.0183 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 2.0816 - mae: 0.9942 - mse: 1.6128 - val_loss: 0.4867 - val_mae: 0.1179 - val_mse: 0.0180 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.2472 - mae: 0.7433 - mse: 0.7785 - val_loss: 0.4862 - val_mae: 0.1161 - val_mse: 0.0176 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.8560 - mae: 0.5993 - mse: 0.3874 - val_loss: 0.4857 - val_mae: 0.1143 - val_mse: 0.0171 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.6428 - mae: 0.3839 - mse: 0.1742 - val_loss: 0.4852 - val_mae: 0.1127 - val_mse: 0.0168 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 1.4198 - mae: 0.7339 - mse: 0.9513 - val_loss: 0.4846 - val_mae: 0.1103 - val_mse: 0.0162 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 0.8556 - mae: 0.5061 - mse: 0.3872 - val_loss: 0.4840 - val_mae: 0.1081 - val_mse: 0.0157 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 1.6608 - mae: 0.9909 - mse: 1.1925 - val_loss: 0.4834 - val_mae: 0.1058 - val_mse: 0.0152 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 1.6669 - mae: 1.0041 - mse: 1.1988 - val_loss: 0.4831 - val_mae: 0.1046 - val_mse: 0.0149 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 1.3588 - mae: 0.7342 - mse: 0.8907 - val_loss: 0.4827 - val_mae: 0.1035 - val_mse: 0.0147 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.6368 - mae: 0.3187 - mse: 0.1687 - val_loss: 0.4826 - val_mae: 0.1032 - val_mse: 0.0146 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - loss: 0.8805 - mae: 0.5165 - mse: 0.4125 - val_loss: 0.4824 - val_mae: 0.1025 - val_mse: 0.0145 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 1.4616 - mae: 0.7142 - mse: 0.9938 - val_loss: 0.4824 - val_mae: 0.1028 - val_mse: 0.0146 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 1.0307 - mae: 0.5539 - mse: 0.5629 - val_loss: 0.4826 - val_mae: 0.1042 - val_mse: 0.0149 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 1.5477 - mae: 0.9020 - mse: 1.0800 - val_loss: 0.4827 - val_mae: 0.1051 - val_mse: 0.0151 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 2.0608 - mae: 0.9912 - mse: 1.5932 - val_loss: 0.4827 - val_mae: 0.1055 - val_mse: 0.0152 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 2.2632 - mae: 1.1109 - mse: 1.7956 - val_loss: 0.4826 - val_mae: 0.1051 - val_mse: 0.0151 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 1.4669 - mae: 0.8383 - mse: 0.9994 - val_loss: 0.4829 - val_mae: 0.1065 - val_mse: 0.0153 - learning_rate: 1.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 0.8708 - mae: 0.5879 - mse: 0.4033 - val_loss: 0.4829 - val_mae: 0.1070 - val_mse: 0.0154 - learning_rate: 1.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 0.5919 - mae: 0.2874 - mse: 0.1244 - val_loss: 0.4828 - val_mae: 0.1065 - val_mse: 0.0153 - learning_rate: 1.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 2.0777 - mae: 1.0408 - mse: 1.6102 - val_loss: 0.4827 - val_mae: 0.1062 - val_mse: 0.0153 - learning_rate: 1.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 1.1966 - mae: 0.6538 - mse: 0.7292 - val_loss: 0.4826 - val_mae: 0.1055 - val_mse: 0.0152 - learning_rate: 1.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 1.0107 - mae: 0.6226 - mse: 0.5432 - val_loss: 0.4827 - val_mae: 0.1057 - val_mse: 0.0152 - learning_rate: 2.0000e-05\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 1.6579 - mae: 1.0018 - mse: 1.1905 - val_loss: 0.4826 - val_mae: 0.1051 - val_mse: 0.0151 - learning_rate: 2.0000e-05\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.7713 - mae: 0.5110 - mse: 0.3038 - val_loss: 0.4827 - val_mae: 0.1060 - val_mse: 0.0153 - learning_rate: 2.0000e-05\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.8839 - mae: 0.5398 - mse: 0.4165 - val_loss: 0.4827 - val_mae: 0.1058 - val_mse: 0.0153 - learning_rate: 2.0000e-05\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 2.3244 - mae: 0.9643 - mse: 1.8570 - val_loss: 0.4828 - val_mae: 0.1060 - val_mse: 0.0153 - learning_rate: 2.0000e-05\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 1.2082 - mae: 0.6757 - mse: 0.7408 - val_loss: 0.4830 - val_mae: 0.1072 - val_mse: 0.0156 - learning_rate: 1.0000e-05\n",
            "Grupo 75 - RMSE: 0.001247, MAE: 0.001063, sMAPE: 2.98%\n",
            "\n",
            "Treinando modelo para grupo etário 80...\n",
            "Grupo 80: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 1.1721 - mae: 0.6577 - mse: 0.7008 - val_loss: 0.4828 - val_mae: 0.0985 - val_mse: 0.0120 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 1.0830 - mae: 0.6813 - mse: 0.6122 - val_loss: 0.4825 - val_mae: 0.0984 - val_mse: 0.0120 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 2.3403 - mae: 1.0640 - mse: 1.8697 - val_loss: 0.4824 - val_mae: 0.0985 - val_mse: 0.0120 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.0425 - mae: 0.5424 - mse: 0.5721 - val_loss: 0.4821 - val_mae: 0.0973 - val_mse: 0.0118 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.3854 - mae: 0.8667 - mse: 0.9152 - val_loss: 0.4819 - val_mae: 0.0971 - val_mse: 0.0118 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 1.6625 - mae: 0.8718 - mse: 1.1923 - val_loss: 0.4817 - val_mae: 0.0962 - val_mse: 0.0116 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.8567 - mae: 0.6043 - mse: 0.3866 - val_loss: 0.4816 - val_mae: 0.0960 - val_mse: 0.0116 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 1.1553 - mae: 0.6074 - mse: 0.6854 - val_loss: 0.4813 - val_mae: 0.0947 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 1.9253 - mae: 1.0585 - mse: 1.4554 - val_loss: 0.4812 - val_mae: 0.0949 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.5815 - mae: 0.2175 - mse: 0.1117 - val_loss: 0.4810 - val_mae: 0.0945 - val_mse: 0.0113 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 1.6225 - mae: 0.8066 - mse: 1.1528 - val_loss: 0.4806 - val_mae: 0.0926 - val_mse: 0.0109 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.0030 - mae: 0.5823 - mse: 0.5333 - val_loss: 0.4805 - val_mae: 0.0923 - val_mse: 0.0109 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 2.0309 - mae: 1.0143 - mse: 1.5613 - val_loss: 0.4803 - val_mae: 0.0916 - val_mse: 0.0107 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 2.0916 - mae: 1.0577 - mse: 1.6220 - val_loss: 0.4802 - val_mae: 0.0913 - val_mse: 0.0107 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 1.8937 - mae: 1.0188 - mse: 1.4241 - val_loss: 0.4803 - val_mae: 0.0919 - val_mse: 0.0108 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 1.0354 - mae: 0.5938 - mse: 0.5659 - val_loss: 0.4800 - val_mae: 0.0905 - val_mse: 0.0106 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 2.5697 - mae: 1.2376 - mse: 2.1002 - val_loss: 0.4802 - val_mae: 0.0918 - val_mse: 0.0108 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 1.9050 - mae: 1.0221 - mse: 1.4356 - val_loss: 0.4803 - val_mae: 0.0923 - val_mse: 0.0109 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 3.5235 - mae: 1.6020 - mse: 3.0541 - val_loss: 0.4803 - val_mae: 0.0924 - val_mse: 0.0110 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - loss: 0.8883 - mae: 0.5750 - mse: 0.4189 - val_loss: 0.4801 - val_mae: 0.0912 - val_mse: 0.0108 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 1.8868 - mae: 0.7287 - mse: 1.4175 - val_loss: 0.4798 - val_mae: 0.0899 - val_mse: 0.0105 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 0.5504 - mae: 0.2706 - mse: 0.0811 - val_loss: 0.4797 - val_mae: 0.0896 - val_mse: 0.0105 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 2.6174 - mae: 1.3067 - mse: 2.1482 - val_loss: 0.4796 - val_mae: 0.0891 - val_mse: 0.0104 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 0.7422 - mae: 0.4146 - mse: 0.2730 - val_loss: 0.4793 - val_mae: 0.0876 - val_mse: 0.0101 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.2669 - mae: 0.6847 - mse: 0.7977 - val_loss: 0.4789 - val_mae: 0.0854 - val_mse: 0.0098 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 1.0697 - mae: 0.6007 - mse: 0.6005 - val_loss: 0.4789 - val_mae: 0.0852 - val_mse: 0.0097 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 1.9315 - mae: 1.0942 - mse: 1.4624 - val_loss: 0.4787 - val_mae: 0.0842 - val_mse: 0.0096 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.5667 - mae: 0.2840 - mse: 0.0976 - val_loss: 0.4788 - val_mae: 0.0849 - val_mse: 0.0097 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.5759 - mae: 1.0127 - mse: 1.1069 - val_loss: 0.4787 - val_mae: 0.0850 - val_mse: 0.0097 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.7792 - mae: 0.4851 - mse: 0.3101 - val_loss: 0.4786 - val_mae: 0.0846 - val_mse: 0.0096 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.9334 - mae: 0.5243 - mse: 0.4644 - val_loss: 0.4785 - val_mae: 0.0839 - val_mse: 0.0095 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.8445 - mae: 0.5310 - mse: 0.3756 - val_loss: 0.4785 - val_mae: 0.0839 - val_mse: 0.0095 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 0.8293 - mae: 0.5164 - mse: 0.3604 - val_loss: 0.4785 - val_mae: 0.0844 - val_mse: 0.0096 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 1.0294 - mae: 0.4910 - mse: 0.5605 - val_loss: 0.4784 - val_mae: 0.0841 - val_mse: 0.0096 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.3601 - mae: 0.7561 - mse: 0.8913 - val_loss: 0.4783 - val_mae: 0.0837 - val_mse: 0.0095 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 1.0461 - mae: 0.7084 - mse: 0.5773 - val_loss: 0.4781 - val_mae: 0.0828 - val_mse: 0.0094 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.8468 - mae: 0.5274 - mse: 0.3781 - val_loss: 0.4782 - val_mae: 0.0834 - val_mse: 0.0095 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 1.1567 - mae: 0.6640 - mse: 0.6880 - val_loss: 0.4781 - val_mae: 0.0831 - val_mse: 0.0094 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.6972 - mae: 0.3702 - mse: 0.2285 - val_loss: 0.4784 - val_mae: 0.0848 - val_mse: 0.0097 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.1329 - mae: 0.6844 - mse: 0.6642 - val_loss: 0.4785 - val_mae: 0.0854 - val_mse: 0.0098 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.9441 - mae: 0.6530 - mse: 0.4755 - val_loss: 0.4785 - val_mae: 0.0858 - val_mse: 0.0099 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.8996 - mae: 0.5833 - mse: 0.4310 - val_loss: 0.4788 - val_mae: 0.0876 - val_mse: 0.0102 - learning_rate: 1.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.1709 - mae: 0.6773 - mse: 0.7023 - val_loss: 0.4788 - val_mae: 0.0875 - val_mse: 0.0102 - learning_rate: 1.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.2413 - mae: 0.7578 - mse: 0.7727 - val_loss: 0.4787 - val_mae: 0.0872 - val_mse: 0.0101 - learning_rate: 1.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.7214 - mae: 0.3990 - mse: 0.2529 - val_loss: 0.4786 - val_mae: 0.0869 - val_mse: 0.0101 - learning_rate: 1.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.4182 - mae: 0.7993 - mse: 0.9497 - val_loss: 0.4786 - val_mae: 0.0867 - val_mse: 0.0101 - learning_rate: 1.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 1.4787 - mae: 0.8634 - mse: 1.0101 - val_loss: 0.4786 - val_mae: 0.0867 - val_mse: 0.0100 - learning_rate: 2.0000e-05\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 1.2546 - mae: 0.7578 - mse: 0.7861 - val_loss: 0.4785 - val_mae: 0.0860 - val_mse: 0.0099 - learning_rate: 2.0000e-05\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 1.0532 - mae: 0.6685 - mse: 0.5847 - val_loss: 0.4784 - val_mae: 0.0857 - val_mse: 0.0099 - learning_rate: 2.0000e-05\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1.5575 - mae: 0.8563 - mse: 1.0890 - val_loss: 0.4783 - val_mae: 0.0849 - val_mse: 0.0097 - learning_rate: 2.0000e-05\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 0.7587 - mae: 0.4430 - mse: 0.2902 - val_loss: 0.4784 - val_mae: 0.0856 - val_mse: 0.0099 - learning_rate: 2.0000e-05\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.9702 - mae: 0.6649 - mse: 0.5017 - val_loss: 0.4786 - val_mae: 0.0867 - val_mse: 0.0101 - learning_rate: 1.0000e-05\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 1.4735 - mae: 0.8993 - mse: 1.0050 - val_loss: 0.4789 - val_mae: 0.0883 - val_mse: 0.0103 - learning_rate: 1.0000e-05\n",
            "Grupo 80 - RMSE: 0.001553, MAE: 0.001330, sMAPE: 2.13%\n",
            "\n",
            "Treinando modelo para grupo etário 85...\n",
            "Grupo 85: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 1.2712 - mae: 0.7137 - mse: 0.7967 - val_loss: 0.4981 - val_mae: 0.1122 - val_mse: 0.0241 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - loss: 2.3875 - mae: 1.1245 - mse: 1.9134 - val_loss: 0.4966 - val_mae: 0.1064 - val_mse: 0.0227 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 2.7969 - mae: 1.3167 - mse: 2.3230 - val_loss: 0.4944 - val_mae: 0.1025 - val_mse: 0.0208 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 3.1420 - mae: 1.3028 - mse: 2.6684 - val_loss: 0.4934 - val_mae: 0.1013 - val_mse: 0.0199 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 2.1063 - mae: 1.1859 - mse: 1.6328 - val_loss: 0.4926 - val_mae: 0.1007 - val_mse: 0.0192 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 4.0920 - mae: 1.6024 - mse: 3.6186 - val_loss: 0.4918 - val_mae: 0.0999 - val_mse: 0.0186 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 5.3411 - mae: 1.3330 - mse: 4.8679 - val_loss: 0.4914 - val_mae: 0.0995 - val_mse: 0.0183 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 1.9264 - mae: 1.0136 - mse: 1.4533 - val_loss: 0.4907 - val_mae: 0.0987 - val_mse: 0.0176 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 2.1445 - mae: 1.1617 - mse: 1.6714 - val_loss: 0.4899 - val_mae: 0.0976 - val_mse: 0.0168 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 1.1495 - mae: 0.5920 - mse: 0.6765 - val_loss: 0.4892 - val_mae: 0.0970 - val_mse: 0.0163 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - loss: 1.9010 - mae: 0.9650 - mse: 1.4281 - val_loss: 0.4885 - val_mae: 0.0961 - val_mse: 0.0157 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 2.4444 - mae: 1.3015 - mse: 1.9715 - val_loss: 0.4880 - val_mae: 0.0955 - val_mse: 0.0153 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 4.2056 - mae: 1.6876 - mse: 3.7328 - val_loss: 0.4877 - val_mae: 0.0950 - val_mse: 0.0150 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 1.6613 - mae: 0.8712 - mse: 1.1887 - val_loss: 0.4871 - val_mae: 0.0944 - val_mse: 0.0145 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 1.5385 - mae: 0.9472 - mse: 1.0659 - val_loss: 0.4866 - val_mae: 0.0937 - val_mse: 0.0141 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 4.8524 - mae: 1.5724 - mse: 4.3799 - val_loss: 0.4861 - val_mae: 0.0929 - val_mse: 0.0137 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 3.4358 - mae: 1.3939 - mse: 2.9634 - val_loss: 0.4858 - val_mae: 0.0924 - val_mse: 0.0134 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 1.1678 - mae: 0.7305 - mse: 0.6954 - val_loss: 0.4854 - val_mae: 0.0917 - val_mse: 0.0131 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 2.6772 - mae: 1.2433 - mse: 2.2048 - val_loss: 0.4850 - val_mae: 0.0916 - val_mse: 0.0127 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 3.3601 - mae: 1.4605 - mse: 2.8878 - val_loss: 0.4846 - val_mae: 0.0923 - val_mse: 0.0124 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 3.4450 - mae: 1.1701 - mse: 2.9728 - val_loss: 0.4844 - val_mae: 0.0931 - val_mse: 0.0122 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 4.5306 - mae: 1.7439 - mse: 4.0584 - val_loss: 0.4841 - val_mae: 0.0939 - val_mse: 0.0120 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 2.3436 - mae: 1.2478 - mse: 1.8715 - val_loss: 0.4839 - val_mae: 0.0948 - val_mse: 0.0118 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 1.3097 - mae: 0.5871 - mse: 0.8377 - val_loss: 0.4837 - val_mae: 0.0955 - val_mse: 0.0116 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 2.2176 - mae: 1.2340 - mse: 1.7456 - val_loss: 0.4835 - val_mae: 0.0962 - val_mse: 0.0115 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 3.3305 - mae: 1.5730 - mse: 2.8585 - val_loss: 0.4833 - val_mae: 0.0972 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - loss: 0.9413 - mae: 0.5740 - mse: 0.4694 - val_loss: 0.4832 - val_mae: 0.0979 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 3.3266 - mae: 1.2530 - mse: 2.8548 - val_loss: 0.4832 - val_mae: 0.0989 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 2.2933 - mae: 1.1839 - mse: 1.8215 - val_loss: 0.4832 - val_mae: 0.0998 - val_mse: 0.0114 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 4.1669 - mae: 1.3995 - mse: 3.6951 - val_loss: 0.4832 - val_mae: 0.1005 - val_mse: 0.0115 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 2.8401 - mae: 1.3379 - mse: 2.3684 - val_loss: 0.4832 - val_mae: 0.1014 - val_mse: 0.0115 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 2.2263 - mae: 1.1367 - mse: 1.7547 - val_loss: 0.4833 - val_mae: 0.1021 - val_mse: 0.0117 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 4.4573 - mae: 1.6886 - mse: 3.9857 - val_loss: 0.4834 - val_mae: 0.1032 - val_mse: 0.0119 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 1.4786 - mae: 0.9826 - mse: 1.0070 - val_loss: 0.4835 - val_mae: 0.1036 - val_mse: 0.0119 - learning_rate: 1.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 2.5081 - mae: 1.1081 - mse: 2.0366 - val_loss: 0.4836 - val_mae: 0.1040 - val_mse: 0.0120 - learning_rate: 1.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - loss: 2.0522 - mae: 0.9138 - mse: 1.5807 - val_loss: 0.4836 - val_mae: 0.1043 - val_mse: 0.0121 - learning_rate: 1.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 2.0270 - mae: 1.1027 - mse: 1.5555 - val_loss: 0.4837 - val_mae: 0.1047 - val_mse: 0.0122 - learning_rate: 1.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 3.2160 - mae: 1.2813 - mse: 2.7445 - val_loss: 0.4838 - val_mae: 0.1050 - val_mse: 0.0123 - learning_rate: 1.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 3.6313 - mae: 1.4443 - mse: 3.1598 - val_loss: 0.4838 - val_mae: 0.1051 - val_mse: 0.0123 - learning_rate: 2.0000e-05\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 1.3948 - mae: 0.8233 - mse: 0.9233 - val_loss: 0.4839 - val_mae: 0.1054 - val_mse: 0.0124 - learning_rate: 2.0000e-05\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 2.1177 - mae: 1.0927 - mse: 1.6462 - val_loss: 0.4841 - val_mae: 0.1061 - val_mse: 0.0127 - learning_rate: 2.0000e-05\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 2.1070 - mae: 1.1278 - mse: 1.6355 - val_loss: 0.4842 - val_mae: 0.1062 - val_mse: 0.0127 - learning_rate: 2.0000e-05\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.5098 - mae: 0.9583 - mse: 1.0383 - val_loss: 0.4843 - val_mae: 0.1064 - val_mse: 0.0128 - learning_rate: 2.0000e-05\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 2.6520 - mae: 1.1976 - mse: 2.1806 - val_loss: 0.4844 - val_mae: 0.1067 - val_mse: 0.0129 - learning_rate: 1.0000e-05\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 1.1148 - mae: 0.7519 - mse: 0.6434 - val_loss: 0.4843 - val_mae: 0.1067 - val_mse: 0.0129 - learning_rate: 1.0000e-05\n",
            "Grupo 85 - RMSE: 0.002026, MAE: 0.001901, sMAPE: 1.73%\n",
            "\n",
            "Treinando modelo para grupo etário 90...\n",
            "Grupo 90: 5 amostras de treino, 5 amostras de teste\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - loss: 1.4216 - mae: 0.8814 - mse: 0.9512 - val_loss: 0.4948 - val_mae: 0.1559 - val_mse: 0.0246 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 2.0603 - mae: 0.9569 - mse: 1.5901 - val_loss: 0.4937 - val_mae: 0.1526 - val_mse: 0.0236 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 2.5688 - mae: 1.1709 - mse: 2.0987 - val_loss: 0.4933 - val_mae: 0.1512 - val_mse: 0.0232 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 2.2494 - mae: 1.0527 - mse: 1.7793 - val_loss: 0.4928 - val_mae: 0.1495 - val_mse: 0.0227 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 2.4527 - mae: 1.1640 - mse: 1.9826 - val_loss: 0.4919 - val_mae: 0.1468 - val_mse: 0.0219 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 2.7865 - mae: 1.3103 - mse: 2.3165 - val_loss: 0.4913 - val_mae: 0.1447 - val_mse: 0.0213 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.3028 - mae: 0.8460 - mse: 0.8328 - val_loss: 0.4906 - val_mae: 0.1424 - val_mse: 0.0206 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 1.6763 - mae: 0.9048 - mse: 1.2063 - val_loss: 0.4898 - val_mae: 0.1396 - val_mse: 0.0198 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 1.8659 - mae: 0.9475 - mse: 1.3959 - val_loss: 0.4889 - val_mae: 0.1363 - val_mse: 0.0189 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 2.1471 - mae: 1.2755 - mse: 1.6771 - val_loss: 0.4886 - val_mae: 0.1350 - val_mse: 0.0186 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 1.2047 - mae: 0.6493 - mse: 0.7347 - val_loss: 0.4878 - val_mae: 0.1320 - val_mse: 0.0178 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 1.8780 - mae: 1.0189 - mse: 1.4080 - val_loss: 0.4872 - val_mae: 0.1299 - val_mse: 0.0172 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 1.0088 - mae: 0.6605 - mse: 0.5388 - val_loss: 0.4864 - val_mae: 0.1268 - val_mse: 0.0164 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 2.4111 - mae: 1.1351 - mse: 1.9411 - val_loss: 0.4856 - val_mae: 0.1235 - val_mse: 0.0156 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 1.4455 - mae: 0.8117 - mse: 0.9756 - val_loss: 0.4846 - val_mae: 0.1194 - val_mse: 0.0146 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 1.3141 - mae: 0.8209 - mse: 0.8442 - val_loss: 0.4839 - val_mae: 0.1167 - val_mse: 0.0140 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 3.5340 - mae: 1.1741 - mse: 3.0641 - val_loss: 0.4833 - val_mae: 0.1140 - val_mse: 0.0133 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 1.3353 - mae: 0.7164 - mse: 0.8654 - val_loss: 0.4826 - val_mae: 0.1111 - val_mse: 0.0127 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - loss: 1.4079 - mae: 0.7127 - mse: 0.9380 - val_loss: 0.4822 - val_mae: 0.1089 - val_mse: 0.0122 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 1.3350 - mae: 0.7636 - mse: 0.8651 - val_loss: 0.4817 - val_mae: 0.1069 - val_mse: 0.0118 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 0.8520 - mae: 0.5240 - mse: 0.3820 - val_loss: 0.4812 - val_mae: 0.1045 - val_mse: 0.0113 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 1.6566 - mae: 0.8824 - mse: 1.1866 - val_loss: 0.4808 - val_mae: 0.1027 - val_mse: 0.0109 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 2.3036 - mae: 1.1970 - mse: 1.8337 - val_loss: 0.4801 - val_mae: 0.0992 - val_mse: 0.0102 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.3813 - mae: 0.7877 - mse: 0.9113 - val_loss: 0.4797 - val_mae: 0.0971 - val_mse: 0.0098 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.9933 - mae: 0.5509 - mse: 0.5233 - val_loss: 0.4793 - val_mae: 0.0951 - val_mse: 0.0094 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.5813 - mae: 0.9588 - mse: 1.1113 - val_loss: 0.4792 - val_mae: 0.0944 - val_mse: 0.0093 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 2.0621 - mae: 0.9768 - mse: 1.5922 - val_loss: 0.4787 - val_mae: 0.0916 - val_mse: 0.0087 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 1.8056 - mae: 0.8357 - mse: 1.3356 - val_loss: 0.4782 - val_mae: 0.0889 - val_mse: 0.0083 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 1.1323 - mae: 0.7014 - mse: 0.6623 - val_loss: 0.4776 - val_mae: 0.0853 - val_mse: 0.0076 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 0.7816 - mae: 0.5348 - mse: 0.3117 - val_loss: 0.4773 - val_mae: 0.0838 - val_mse: 0.0074 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - loss: 1.0932 - mae: 0.6394 - mse: 0.6232 - val_loss: 0.4768 - val_mae: 0.0808 - val_mse: 0.0069 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.7676 - mae: 0.4544 - mse: 0.2976 - val_loss: 0.4765 - val_mae: 0.0785 - val_mse: 0.0065 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 1.3896 - mae: 0.8642 - mse: 0.9196 - val_loss: 0.4761 - val_mae: 0.0759 - val_mse: 0.0061 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 2.1828 - mae: 1.1722 - mse: 1.7128 - val_loss: 0.4757 - val_mae: 0.0733 - val_mse: 0.0057 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 1.3961 - mae: 0.8176 - mse: 0.9261 - val_loss: 0.4753 - val_mae: 0.0709 - val_mse: 0.0054 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.9984 - mae: 0.5775 - mse: 0.5284 - val_loss: 0.4751 - val_mae: 0.0691 - val_mse: 0.0051 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 0.7957 - mae: 0.3173 - mse: 0.3258 - val_loss: 0.4747 - val_mae: 0.0661 - val_mse: 0.0047 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 3.0019 - mae: 1.0628 - mse: 2.5319 - val_loss: 0.4744 - val_mae: 0.0638 - val_mse: 0.0044 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 0.7336 - mae: 0.3357 - mse: 0.2636 - val_loss: 0.4743 - val_mae: 0.0628 - val_mse: 0.0043 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 1.7801 - mae: 1.0988 - mse: 1.3101 - val_loss: 0.4739 - val_mae: 0.0595 - val_mse: 0.0039 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.8670 - mae: 1.0648 - mse: 1.3970 - val_loss: 0.4736 - val_mae: 0.0577 - val_mse: 0.0037 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - loss: 1.6536 - mae: 0.9917 - mse: 1.1836 - val_loss: 0.4735 - val_mae: 0.0560 - val_mse: 0.0035 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 1.0693 - mae: 0.7503 - mse: 0.5993 - val_loss: 0.4733 - val_mae: 0.0544 - val_mse: 0.0033 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 0.9125 - mae: 0.5914 - mse: 0.4426 - val_loss: 0.4731 - val_mae: 0.0531 - val_mse: 0.0032 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 0.8903 - mae: 0.5472 - mse: 0.4203 - val_loss: 0.4730 - val_mae: 0.0516 - val_mse: 0.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 1.8184 - mae: 0.9692 - mse: 1.3484 - val_loss: 0.4728 - val_mae: 0.0497 - val_mse: 0.0028 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 1.4788 - mae: 0.8701 - mse: 1.0088 - val_loss: 0.4725 - val_mae: 0.0470 - val_mse: 0.0026 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 1.1871 - mae: 0.7309 - mse: 0.7171 - val_loss: 0.4723 - val_mae: 0.0443 - val_mse: 0.0023 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - loss: 1.3394 - mae: 0.8129 - mse: 0.8694 - val_loss: 0.4721 - val_mae: 0.0421 - val_mse: 0.0021 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 0.9034 - mae: 0.5091 - mse: 0.4335 - val_loss: 0.4719 - val_mae: 0.0399 - val_mse: 0.0019 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 1.2832 - mae: 0.6134 - mse: 0.8132 - val_loss: 0.4718 - val_mae: 0.0384 - val_mse: 0.0018 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 1.0534 - mae: 0.6114 - mse: 0.5835 - val_loss: 0.4717 - val_mae: 0.0378 - val_mse: 0.0018 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 1.4492 - mae: 0.7729 - mse: 0.9792 - val_loss: 0.4716 - val_mae: 0.0360 - val_mse: 0.0016 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 2.6402 - mae: 1.4358 - mse: 2.1702 - val_loss: 0.4714 - val_mae: 0.0332 - val_mse: 0.0014 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 1.1834 - mae: 0.7535 - mse: 0.7135 - val_loss: 0.4713 - val_mae: 0.0309 - val_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.6919 - mae: 0.3988 - mse: 0.2219 - val_loss: 0.4711 - val_mae: 0.0282 - val_mse: 0.0011 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 1.1333 - mae: 0.6751 - mse: 0.6634 - val_loss: 0.4710 - val_mae: 0.0263 - val_mse: 0.0010 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 1.1193 - mae: 0.7190 - mse: 0.6494 - val_loss: 0.4709 - val_mae: 0.0238 - val_mse: 9.0144e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.1090 - mae: 0.7079 - mse: 0.6390 - val_loss: 0.4709 - val_mae: 0.0240 - val_mse: 9.1974e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 1.1041 - mae: 0.6639 - mse: 0.6341 - val_loss: 0.4708 - val_mae: 0.0234 - val_mse: 8.7353e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.3169 - mae: 0.7208 - mse: 0.8470 - val_loss: 0.4707 - val_mae: 0.0215 - val_mse: 7.3146e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 1.0580 - mae: 0.5506 - mse: 0.5880 - val_loss: 0.4706 - val_mae: 0.0204 - val_mse: 6.6412e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 0.7265 - mae: 0.4330 - mse: 0.2566 - val_loss: 0.4706 - val_mae: 0.0199 - val_mse: 6.3617e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 1.4285 - mae: 0.8267 - mse: 0.9586 - val_loss: 0.4705 - val_mae: 0.0196 - val_mse: 6.1120e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 1.1438 - mae: 0.7228 - mse: 0.6738 - val_loss: 0.4705 - val_mae: 0.0196 - val_mse: 6.0756e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 1.0742 - mae: 0.6159 - mse: 0.6043 - val_loss: 0.4705 - val_mae: 0.0194 - val_mse: 5.7966e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.8998 - mae: 0.5787 - mse: 0.4299 - val_loss: 0.4705 - val_mae: 0.0193 - val_mse: 5.6304e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 1.0780 - mae: 0.7009 - mse: 0.6081 - val_loss: 0.4705 - val_mae: 0.0191 - val_mse: 5.4307e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.8490 - mae: 0.5477 - mse: 0.3791 - val_loss: 0.4704 - val_mae: 0.0190 - val_mse: 5.2687e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.1789 - mae: 0.7405 - mse: 0.7090 - val_loss: 0.4704 - val_mae: 0.0190 - val_mse: 5.2630e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 2.1700 - mae: 1.1229 - mse: 1.7001 - val_loss: 0.4704 - val_mae: 0.0190 - val_mse: 5.1774e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - loss: 1.0147 - mae: 0.6696 - mse: 0.5448 - val_loss: 0.4704 - val_mae: 0.0187 - val_mse: 4.9100e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 1.1812 - mae: 0.7153 - mse: 0.7113 - val_loss: 0.4703 - val_mae: 0.0184 - val_mse: 4.5230e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.8777 - mae: 0.5444 - mse: 0.4078 - val_loss: 0.4703 - val_mae: 0.0181 - val_mse: 4.2387e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 1.2120 - mae: 0.7244 - mse: 0.7421 - val_loss: 0.4703 - val_mae: 0.0178 - val_mse: 3.9992e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.7965 - mae: 0.3946 - mse: 0.3267 - val_loss: 0.4703 - val_mae: 0.0176 - val_mse: 3.8657e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 0.6412 - mae: 0.3652 - mse: 0.1713 - val_loss: 0.4702 - val_mae: 0.0175 - val_mse: 3.8156e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - loss: 0.7515 - mae: 0.3380 - mse: 0.2817 - val_loss: 0.4702 - val_mae: 0.0174 - val_mse: 3.7723e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 1.2400 - mae: 0.6515 - mse: 0.7701 - val_loss: 0.4702 - val_mae: 0.0175 - val_mse: 3.8270e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.7390 - mae: 1.0044 - mse: 1.2691 - val_loss: 0.4702 - val_mae: 0.0173 - val_mse: 3.7055e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 1.5084 - mae: 0.8786 - mse: 1.0385 - val_loss: 0.4702 - val_mae: 0.0173 - val_mse: 3.6861e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.9146 - mae: 0.5824 - mse: 0.4447 - val_loss: 0.4702 - val_mae: 0.0172 - val_mse: 3.6506e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - loss: 0.8464 - mae: 0.5531 - mse: 0.3766 - val_loss: 0.4702 - val_mae: 0.0172 - val_mse: 3.6502e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 1.0124 - mae: 0.7244 - mse: 0.5426 - val_loss: 0.4702 - val_mae: 0.0173 - val_mse: 3.6758e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.6018 - mae: 0.3557 - mse: 0.1320 - val_loss: 0.4702 - val_mae: 0.0170 - val_mse: 3.5813e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.0911 - mae: 0.6662 - mse: 0.6213 - val_loss: 0.4702 - val_mae: 0.0168 - val_mse: 3.5185e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.3524 - mae: 0.7443 - mse: 0.8826 - val_loss: 0.4702 - val_mae: 0.0168 - val_mse: 3.5300e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 1.9579 - mae: 0.8610 - mse: 1.4881 - val_loss: 0.4702 - val_mae: 0.0170 - val_mse: 3.5821e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.4508 - mae: 0.7493 - mse: 0.9810 - val_loss: 0.4702 - val_mae: 0.0168 - val_mse: 3.5309e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.8656 - mae: 0.5761 - mse: 0.3958 - val_loss: 0.4702 - val_mae: 0.0169 - val_mse: 3.5557e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 1.4834 - mae: 0.8342 - mse: 1.0136 - val_loss: 0.4702 - val_mae: 0.0167 - val_mse: 3.5253e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 1.0871 - mae: 0.6947 - mse: 0.6173 - val_loss: 0.4702 - val_mae: 0.0167 - val_mse: 3.5191e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 0.6764 - mae: 0.4081 - mse: 0.2066 - val_loss: 0.4702 - val_mae: 0.0166 - val_mse: 3.4802e-04 - learning_rate: 2.0000e-05\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.8601 - mae: 0.4928 - mse: 0.3903 - val_loss: 0.4702 - val_mae: 0.0164 - val_mse: 3.4700e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 0.7044 - mae: 0.3879 - mse: 0.2346 - val_loss: 0.4702 - val_mae: 0.0165 - val_mse: 3.4963e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 1.3859 - mae: 0.7973 - mse: 0.9161 - val_loss: 0.4702 - val_mae: 0.0166 - val_mse: 3.5126e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 0.7589 - mae: 0.5318 - mse: 0.2891 - val_loss: 0.4702 - val_mae: 0.0166 - val_mse: 3.5102e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 1.2238 - mae: 0.7758 - mse: 0.7540 - val_loss: 0.4702 - val_mae: 0.0166 - val_mse: 3.5016e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 0.7003 - mae: 0.3826 - mse: 0.2305 - val_loss: 0.4702 - val_mae: 0.0163 - val_mse: 3.4852e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 0.9339 - mae: 0.5130 - mse: 0.4641 - val_loss: 0.4702 - val_mae: 0.0169 - val_mse: 3.5827e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 1.1224 - mae: 0.6648 - mse: 0.6526 - val_loss: 0.4702 - val_mae: 0.0172 - val_mse: 3.6749e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.6667 - mae: 0.3439 - mse: 0.1969 - val_loss: 0.4702 - val_mae: 0.0172 - val_mse: 3.6800e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - loss: 0.8523 - mae: 0.5396 - mse: 0.3825 - val_loss: 0.4702 - val_mae: 0.0172 - val_mse: 3.6726e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 0.8866 - mae: 0.5261 - mse: 0.4168 - val_loss: 0.4702 - val_mae: 0.0173 - val_mse: 3.7077e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.6108 - mae: 0.2900 - mse: 0.1410 - val_loss: 0.4702 - val_mae: 0.0173 - val_mse: 3.7123e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 1.3993 - mae: 0.8116 - mse: 0.9295 - val_loss: 0.4702 - val_mae: 0.0176 - val_mse: 3.8466e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.6069 - mae: 0.2836 - mse: 0.1371 - val_loss: 0.4702 - val_mae: 0.0175 - val_mse: 3.7964e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 0.5384 - mae: 0.2309 - mse: 0.0686 - val_loss: 0.4702 - val_mae: 0.0174 - val_mse: 3.7618e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 1.0524 - mae: 0.6054 - mse: 0.5826 - val_loss: 0.4702 - val_mae: 0.0177 - val_mse: 3.9462e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 1.6250 - mae: 0.9767 - mse: 1.1552 - val_loss: 0.4702 - val_mae: 0.0180 - val_mse: 4.1181e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.1409 - mae: 0.6647 - mse: 0.6711 - val_loss: 0.4702 - val_mae: 0.0180 - val_mse: 4.1732e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.6282 - mae: 0.3749 - mse: 0.1584 - val_loss: 0.4702 - val_mae: 0.0182 - val_mse: 4.2915e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.9535 - mae: 0.5045 - mse: 0.4837 - val_loss: 0.4702 - val_mae: 0.0184 - val_mse: 4.5191e-04 - learning_rate: 1.0000e-05\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - loss: 0.9873 - mae: 0.6292 - mse: 0.5176 - val_loss: 0.4702 - val_mae: 0.0181 - val_mse: 4.2632e-04 - learning_rate: 1.0000e-05\n",
            "Grupo 90 - RMSE: 0.000616, MAE: 0.000539, sMAPE: 0.28%\n",
            "\n",
            "=== RESUMO DOS RESULTADOS ===\n",
            "Modelos masculinos treinados: 20\n",
            "Modelos femininos treinados: 20\n",
            "\n",
            "Métricas para grupo masculino '0':\n",
            "  RMSE: 0.0003\n",
            "  MAE: 0.0002\n",
            "  sMAPE: 1.75%\n",
            "\n",
            "Métricas para grupo feminino '0':\n",
            "  RMSE: 0.0003\n",
            "  MAE: 0.0003\n",
            "  sMAPE: 2.35%\n"
          ]
        }
      ],
      "source": [
        "# Inicializar estruturas para resultados\n",
        "models_male, predictions_male, metrics_male = {}, {}, {}\n",
        "models_female, predictions_female, metrics_female = {}, {}, {}\n",
        "\n",
        "if processed_data is not None:\n",
        "    # Separar dados por gênero\n",
        "    data_male = processed_data[0]   # Dados para homens (gender=0)\n",
        "    scalers_male = scalers_dict[0]\n",
        "\n",
        "    data_female = processed_data[1] # Dados para mulheres (gender=1)\n",
        "    scalers_female = scalers_dict[1]\n",
        "\n",
        "    # Metadados\n",
        "    age_cols = metadata['age_columns']\n",
        "    years = metadata['years']\n",
        "\n",
        "    print(f'\\nDados processados:')\n",
        "    print(f'Grupos etários: {len(age_cols)}')\n",
        "    print(f'Anos disponíveis: {min(years)} - {max(years)}')\n",
        "    print(f'  Homens: {len(data_male)} grupos etários com dados')\n",
        "    print(f'  Mulheres: {len(data_female)} grupos etários com dados')\n",
        "\n",
        "    # Treinar modelos para homens\n",
        "    if data_male:\n",
        "        print('\\n=== TREINANDO MODELOS PARA HOMENS ===')\n",
        "        models_male, predictions_male, metrics_male = train_and_predict(\n",
        "            data_dict=data_male,\n",
        "            scalers_dict=scalers_male,\n",
        "            gender_name='homens',\n",
        "            years_available=years\n",
        "        )\n",
        "    else:\n",
        "        print('AVISO: Nenhum dado disponível para homens. Pulando treinamento.')\n",
        "\n",
        "    # Treinar modelos para mulheres\n",
        "    if data_female:\n",
        "        print('\\n=== TREINANDO MODELOS PARA MULHERES ===')\n",
        "        models_female, predictions_female, metrics_female = train_and_predict(\n",
        "            data_dict=data_female,\n",
        "            scalers_dict=scalers_female,\n",
        "            gender_name='mulheres',\n",
        "            years_available=years\n",
        "        )\n",
        "    else:\n",
        "        print('AVISO: Nenhum dado disponível para mulheres. Pulando treinamento.')\n",
        "else:\n",
        "    print('Erro no processamento dos dados. Nenhum modelo será treinado.')\n",
        "\n",
        "# Verificar resultados\n",
        "print('\\n=== RESUMO DOS RESULTADOS ===')\n",
        "print(f'Modelos masculinos treinados: {len(models_male)}')\n",
        "print(f'Modelos femininos treinados: {len(models_female)}')\n",
        "\n",
        "# Exibir métricas de amostra\n",
        "if models_male and metrics_male:\n",
        "    sample_group = list(metrics_male.keys())[0]\n",
        "    print(f\"\\nMétricas para grupo masculino '{sample_group}':\")\n",
        "    print(f\"  RMSE: {metrics_male[sample_group]['RMSE']:.4f}\")\n",
        "    print(f\"  MAE: {metrics_male[sample_group]['MAE']:.4f}\")\n",
        "    print(f\"  sMAPE: {metrics_male[sample_group]['sMAPE']:.2f}%\")\n",
        "\n",
        "if models_female and metrics_female:\n",
        "    sample_group = list(metrics_female.keys())[0]\n",
        "    print(f\"\\nMétricas para grupo feminino '{sample_group}':\")\n",
        "    print(f\"  RMSE: {metrics_female[sample_group]['RMSE']:.4f}\")\n",
        "    print(f\"  MAE: {metrics_female[sample_group]['MAE']:.4f}\")\n",
        "    print(f\"  sMAPE: {metrics_female[sample_group]['sMAPE']:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WW2JYe9oFr5R"
      },
      "outputs": [],
      "source": [
        "# Função para criar CSV de previsões\n",
        "def create_predictions_csv(predictions_dict, gender_name, local='Brasil'):\n",
        "    \"\"\"\n",
        "    Cria CSV com previsões no formato especificado\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "\n",
        "    for age_group, pred_data in predictions_dict.items():\n",
        "        for i, year in enumerate(pred_data['years']):\n",
        "            rows.append({\n",
        "                'Local': local,\n",
        "                'Sexo': gender_name,\n",
        "                'Ano': year,\n",
        "                'Grupo Etário': age_group,\n",
        "                'Previsão': pred_data['predictions'][i],\n",
        "                'Limite Inferior': pred_data['lower_bound'][i],\n",
        "                'Limite Superior': pred_data['upper_bound'][i]\n",
        "            })\n",
        "\n",
        "    df_predictions = pd.DataFrame(rows)\n",
        "    filename = f'previsoes_{gender_name.lower()}_log.csv'\n",
        "    df_predictions.to_csv(filename, index=False)\n",
        "    print(f'Arquivo {filename} criado com {len(df_predictions)} registros')\n",
        "    return df_predictions\n",
        "\n",
        "# Função para criar CSV de métricas\n",
        "def create_metrics_csv(metrics_dict, gender_name, local='Brasil'):\n",
        "    \"\"\"\n",
        "    Cria CSV com métricas no formato especificado\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "\n",
        "    for age_group, metrics in metrics_dict.items():\n",
        "        rows.append({\n",
        "            'Local': local,\n",
        "            'Sexo': gender_name,\n",
        "            'Grupo Etário': age_group,\n",
        "            'RMSE': metrics['RMSE'],\n",
        "            'sMAPE': metrics['sMAPE'],\n",
        "            'MAE': metrics['MAE']\n",
        "        })\n",
        "\n",
        "    df_metrics = pd.DataFrame(rows)\n",
        "    filename = f'metricas_{gender_name.lower()}_log.csv'\n",
        "    df_metrics.to_csv(filename, index=False)\n",
        "    print(f'Arquivo {filename} criado com {len(df_metrics)} registros')\n",
        "    return df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NPpjKB6Fr5S",
        "outputId": "507f208c-e194-4cfc-c058-d54fb3abead8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GERANDO ARQUIVOS CSV PARA HOMENS ===\n",
            "Arquivo previsoes_masculino_log.csv criado com 1020 registros\n",
            "Arquivo metricas_masculino_log.csv criado com 20 registros\n",
            "Arquivos para homens gerados com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Gerar arquivos CSV para homens\n",
        "print('=== GERANDO ARQUIVOS CSV PARA HOMENS ===')\n",
        "if predictions_male:\n",
        "    df_pred_male = create_predictions_csv(predictions_male, 'Masculino')\n",
        "    df_metrics_male = create_metrics_csv(metrics_male, 'Masculino')\n",
        "    print('Arquivos para homens gerados com sucesso!')\n",
        "else:\n",
        "    print('Nenhuma previsão disponível para homens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k01fKjbFr5S",
        "outputId": "0475c93e-b729-4e12-c52d-da89f744203b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GERANDO ARQUIVOS CSV PARA MULHERES ===\n",
            "Arquivo previsoes_feminino_log.csv criado com 1020 registros\n",
            "Arquivo metricas_feminino_log.csv criado com 20 registros\n",
            "Arquivos para mulheres gerados com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Gerar arquivos CSV para mulheres\n",
        "print('=== GERANDO ARQUIVOS CSV PARA MULHERES ===')\n",
        "if predictions_female:\n",
        "    df_pred_female = create_predictions_csv(predictions_female, 'Feminino')\n",
        "    df_metrics_female = create_metrics_csv(metrics_female, 'Feminino')\n",
        "    print('Arquivos para mulheres gerados com sucesso!')\n",
        "else:\n",
        "    print('Nenhuma previsão disponível para mulheres')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar previsões para homens\n",
        "df_pred_male = pd.read_csv('/content/previsoes_masculino_log.csv')\n",
        "df_pred_male.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f5pFNlO5JYcU",
        "outputId": "98760cbf-8ec4-4437-df2b-a92ce59433ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Local       Sexo   Ano  Grupo Etário  Previsão  Limite Inferior  \\\n",
              "0  Brasil  Masculino  2020             0  0.013794         0.013794   \n",
              "1  Brasil  Masculino  2021             0  0.013791         0.013791   \n",
              "2  Brasil  Masculino  2022             0  0.013792         0.013792   \n",
              "3  Brasil  Masculino  2023             0  0.013790         0.013790   \n",
              "4  Brasil  Masculino  2024             0  0.013792         0.013792   \n",
              "\n",
              "   Limite Superior  \n",
              "0         0.013794  \n",
              "1         0.013791  \n",
              "2         0.013792  \n",
              "3         0.013790  \n",
              "4         0.013792  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fdb7232-81e7-4f8d-a3bb-cd76abfcef43\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Local</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Ano</th>\n",
              "      <th>Grupo Etário</th>\n",
              "      <th>Previsão</th>\n",
              "      <th>Limite Inferior</th>\n",
              "      <th>Limite Superior</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>2020</td>\n",
              "      <td>0</td>\n",
              "      <td>0.013794</td>\n",
              "      <td>0.013794</td>\n",
              "      <td>0.013794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>0.013791</td>\n",
              "      <td>0.013791</td>\n",
              "      <td>0.013791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>2022</td>\n",
              "      <td>0</td>\n",
              "      <td>0.013792</td>\n",
              "      <td>0.013792</td>\n",
              "      <td>0.013792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>2023</td>\n",
              "      <td>0</td>\n",
              "      <td>0.013790</td>\n",
              "      <td>0.013790</td>\n",
              "      <td>0.013790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>2024</td>\n",
              "      <td>0</td>\n",
              "      <td>0.013792</td>\n",
              "      <td>0.013792</td>\n",
              "      <td>0.013792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fdb7232-81e7-4f8d-a3bb-cd76abfcef43')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fdb7232-81e7-4f8d-a3bb-cd76abfcef43 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fdb7232-81e7-4f8d-a3bb-cd76abfcef43');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fb422506-90eb-40db-8eda-bb02ee1c0afd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb422506-90eb-40db-8eda-bb02ee1c0afd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fb422506-90eb-40db-8eda-bb02ee1c0afd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pred_male",
              "summary": "{\n  \"name\": \"df_pred_male\",\n  \"rows\": 1020,\n  \"fields\": [\n    {\n      \"column\": \"Local\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Brasil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sexo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Masculino\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ano\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 2020,\n        \"max\": 2070,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          2063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grupo Et\\u00e1rio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 90,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Previs\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053475717556324354,\n        \"min\": 0.00025087903,\n        \"max\": 0.21875905,\n        \"num_unique_values\": 556,\n        \"samples\": [\n          0.049947396\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Limite Inferior\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05347570978049,\n        \"min\": 0.00025082062,\n        \"max\": 0.21875899,\n        \"num_unique_values\": 598,\n        \"samples\": [\n          0.0003663159\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Limite Superior\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0534757251129413,\n        \"min\": 0.00025093745,\n        \"max\": 0.2187591,\n        \"num_unique_values\": 595,\n        \"samples\": [\n          0.0023783112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Organizar por ano e grupo etário\n",
        "df_pred_male = df_pred_male.sort_values(by=['Ano', 'Grupo Etário'])\n",
        "df_pred_male.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3APGn_npJmdA",
        "outputId": "ce570313-d00c-4fda-f1ab-f2bcae67b034"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Local       Sexo   Ano  Grupo Etário  Previsão  Limite Inferior  \\\n",
              "0    Brasil  Masculino  2020             0  0.013794         0.013794   \n",
              "51   Brasil  Masculino  2020             1  0.000567         0.000567   \n",
              "102  Brasil  Masculino  2020             5  0.000251         0.000251   \n",
              "153  Brasil  Masculino  2020            10  0.000370         0.000370   \n",
              "204  Brasil  Masculino  2020            15  0.001375         0.001375   \n",
              "\n",
              "     Limite Superior  \n",
              "0           0.013794  \n",
              "51          0.000568  \n",
              "102         0.000251  \n",
              "153         0.000370  \n",
              "204         0.001375  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1788ebe4-ebfb-4395-9126-bee6f34f6fb0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Local</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Ano</th>\n",
              "      <th>Grupo Etário</th>\n",
              "      <th>Previsão</th>\n",
              "      <th>Limite Inferior</th>\n",
              "      <th>Limite Superior</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>2020</td>\n",
              "      <td>0</td>\n",
              "      <td>0.013794</td>\n",
              "      <td>0.013794</td>\n",
              "      <td>0.013794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>2020</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000567</td>\n",
              "      <td>0.000567</td>\n",
              "      <td>0.000568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>2020</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000251</td>\n",
              "      <td>0.000251</td>\n",
              "      <td>0.000251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>2020</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.000370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>2020</td>\n",
              "      <td>15</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.001375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1788ebe4-ebfb-4395-9126-bee6f34f6fb0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1788ebe4-ebfb-4395-9126-bee6f34f6fb0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1788ebe4-ebfb-4395-9126-bee6f34f6fb0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-81574096-3d63-4818-be86-92963ecac79e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81574096-3d63-4818-be86-92963ecac79e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-81574096-3d63-4818-be86-92963ecac79e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pred_male",
              "summary": "{\n  \"name\": \"df_pred_male\",\n  \"rows\": 1020,\n  \"fields\": [\n    {\n      \"column\": \"Local\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Brasil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sexo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Masculino\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ano\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 2020,\n        \"max\": 2070,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          2063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grupo Et\\u00e1rio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 90,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Previs\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05347571755632427,\n        \"min\": 0.00025087903,\n        \"max\": 0.21875905,\n        \"num_unique_values\": 556,\n        \"samples\": [\n          0.002475192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Limite Inferior\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0534757097804899,\n        \"min\": 0.00025082062,\n        \"max\": 0.21875899,\n        \"num_unique_values\": 598,\n        \"samples\": [\n          0.005295215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Limite Superior\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053475725112941366,\n        \"min\": 0.00025093745,\n        \"max\": 0.2187591,\n        \"num_unique_values\": 595,\n        \"samples\": [\n          0.0029795414\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar Previsão de 2024, 2034, 2044, 2054, 2064, 2070\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_pred_male[df_pred_male['Ano'] == 2024], x='Grupo Etário', y=np.log(df_pred_male[df_pred_male['Ano'] == 2024]['Previsão']), label='2024')\n",
        "sns.lineplot(data=df_pred_male[df_pred_male['Ano'] == 2034], x='Grupo Etário', y=np.log(df_pred_male[df_pred_male['Ano'] == 2034]['Previsão']), label='2034')\n",
        "sns.lineplot(data=df_pred_male[df_pred_male['Ano'] == 2044], x='Grupo Etário', y=np.log(df_pred_male[df_pred_male['Ano'] == 2044]['Previsão']), label='2044')\n",
        "sns.lineplot(data=df_pred_male[df_pred_male['Ano'] == 2054], x='Grupo Etário', y=np.log(df_pred_male[df_pred_male['Ano'] == 2054]['Previsão']), label='2054')\n",
        "sns.lineplot(data=df_pred_male[df_pred_male['Ano'] == 2064], x='Grupo Etário', y=np.log(df_pred_male[df_pred_male['Ano'] == 2064]['Previsão']), label='2064')\n",
        "sns.lineplot(data=df_pred_male[df_pred_male['Ano'] == 2070], x='Grupo Etário', y=np.log(df_pred_male[df_pred_male['Ano'] == 2070]['Previsão']), label='2070')\n",
        "plt.xlabel('Grupo Etário')\n",
        "plt.ylabel('nMx (log)')\n",
        "plt.title('Previsão de nMx em escala logarítmica')\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45) # Rotate y-axis labels by 45 degrees\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "zopBuujqApAo",
        "outputId": "8aeb8585-069d-4083-d5f5-cc805d3cf2a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar métricas\n",
        "df_metrics_male"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "z_xmzjHeKES4",
        "outputId": "0d879226-4540-42ee-e735-9a400df1b441"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Local       Sexo Grupo Etário      RMSE      sMAPE       MAE\n",
              "0   Brasil  Masculino            0  0.000303   1.753797  0.000239\n",
              "1   Brasil  Masculino            1  0.000013   1.907636  0.000011\n",
              "2   Brasil  Masculino            5  0.000007   2.152523  0.000005\n",
              "3   Brasil  Masculino           10  0.000026   5.966766  0.000022\n",
              "4   Brasil  Masculino           15  0.000648  36.293064  0.000620\n",
              "5   Brasil  Masculino           20  0.000228   7.965161  0.000216\n",
              "6   Brasil  Masculino           25  0.000211   7.519080  0.000190\n",
              "7   Brasil  Masculino           30  0.000214   6.906526  0.000178\n",
              "8   Brasil  Masculino           35  0.000131   3.708866  0.000112\n",
              "9   Brasil  Masculino           40  0.000169   3.788570  0.000145\n",
              "10  Brasil  Masculino           45  0.000242   3.920154  0.000207\n",
              "11  Brasil  Masculino           50  0.000527   6.369888  0.000477\n",
              "12  Brasil  Masculino           55  0.000344   2.671763  0.000296\n",
              "13  Brasil  Masculino           60  0.001106   6.718014  0.001066\n",
              "14  Brasil  Masculino           65  0.000316   1.191162  0.000282\n",
              "15  Brasil  Masculino           70  0.001106   2.644220  0.000894\n",
              "16  Brasil  Masculino           75  0.003125   5.798442  0.002997\n",
              "17  Brasil  Masculino           80  0.001466   1.418426  0.001185\n",
              "18  Brasil  Masculino           85  0.001926   1.332517  0.001797\n",
              "19  Brasil  Masculino           90  0.002576   1.019369  0.002188"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7089333c-03d2-47d8-9b57-789ab7dd3f67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Local</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Grupo Etário</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>sMAPE</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>1.753797</td>\n",
              "      <td>0.000239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>1.907636</td>\n",
              "      <td>0.000011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>2.152523</td>\n",
              "      <td>0.000005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>5.966766</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>15</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>36.293064</td>\n",
              "      <td>0.000620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>20</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>7.965161</td>\n",
              "      <td>0.000216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>25</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>7.519080</td>\n",
              "      <td>0.000190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>30</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>6.906526</td>\n",
              "      <td>0.000178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>35</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>3.708866</td>\n",
              "      <td>0.000112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>40</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>3.788570</td>\n",
              "      <td>0.000145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>45</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>3.920154</td>\n",
              "      <td>0.000207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>50</td>\n",
              "      <td>0.000527</td>\n",
              "      <td>6.369888</td>\n",
              "      <td>0.000477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>55</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>2.671763</td>\n",
              "      <td>0.000296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>60</td>\n",
              "      <td>0.001106</td>\n",
              "      <td>6.718014</td>\n",
              "      <td>0.001066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>1.191162</td>\n",
              "      <td>0.000282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>70</td>\n",
              "      <td>0.001106</td>\n",
              "      <td>2.644220</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>75</td>\n",
              "      <td>0.003125</td>\n",
              "      <td>5.798442</td>\n",
              "      <td>0.002997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>80</td>\n",
              "      <td>0.001466</td>\n",
              "      <td>1.418426</td>\n",
              "      <td>0.001185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>85</td>\n",
              "      <td>0.001926</td>\n",
              "      <td>1.332517</td>\n",
              "      <td>0.001797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Masculino</td>\n",
              "      <td>90</td>\n",
              "      <td>0.002576</td>\n",
              "      <td>1.019369</td>\n",
              "      <td>0.002188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7089333c-03d2-47d8-9b57-789ab7dd3f67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7089333c-03d2-47d8-9b57-789ab7dd3f67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7089333c-03d2-47d8-9b57-789ab7dd3f67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4cc0bc8c-b105-492e-a164-1b0637c49c27\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4cc0bc8c-b105-492e-a164-1b0637c49c27')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4cc0bc8c-b105-492e-a164-1b0637c49c27 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d7bf34f1-d0f0-4ed6-baa3-f9538d2853f0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_metrics_male')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d7bf34f1-d0f0-4ed6-baa3-f9538d2853f0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_metrics_male');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_metrics_male",
              "summary": "{\n  \"name\": \"df_metrics_male\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Local\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Brasil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sexo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Masculino\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grupo Et\\u00e1rio\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0008938864925738921,\n        \"min\": 6.547722848635702e-06,\n        \"max\": 0.0031253769075890113,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.00030343885813703583\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sMAPE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.603457724571327,\n        \"min\": 1.0193693086424456,\n        \"max\": 36.29306442484815,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.753797445253643\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0008191636184169226,\n        \"min\": 5.435034791007634e-06,\n        \"max\": 0.002996608214855194,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.00023916314736604667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar previsões para mulheres\n",
        "df_pred_female = pd.read_csv('/content/previsoes_feminino_log.csv')\n",
        "df_pred_female.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YZzITQ6aKLQA",
        "outputId": "ba51ec5e-3efe-47bd-e55c-40a5a9189023"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Local      Sexo   Ano  Grupo Etário  Previsão  Limite Inferior  \\\n",
              "0  Brasil  Feminino  2020             0  0.011694         0.011694   \n",
              "1  Brasil  Feminino  2021             0  0.011693         0.011693   \n",
              "2  Brasil  Feminino  2022             0  0.011696         0.011696   \n",
              "3  Brasil  Feminino  2023             0  0.011695         0.011695   \n",
              "4  Brasil  Feminino  2024             0  0.011697         0.011697   \n",
              "\n",
              "   Limite Superior  \n",
              "0         0.011694  \n",
              "1         0.011693  \n",
              "2         0.011696  \n",
              "3         0.011695  \n",
              "4         0.011697  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74295b36-ba95-4f02-abef-e1b374f44482\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Local</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Ano</th>\n",
              "      <th>Grupo Etário</th>\n",
              "      <th>Previsão</th>\n",
              "      <th>Limite Inferior</th>\n",
              "      <th>Limite Superior</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>2020</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011694</td>\n",
              "      <td>0.011694</td>\n",
              "      <td>0.011694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>2021</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011693</td>\n",
              "      <td>0.011693</td>\n",
              "      <td>0.011693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>2022</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011696</td>\n",
              "      <td>0.011696</td>\n",
              "      <td>0.011696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>2023</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011695</td>\n",
              "      <td>0.011695</td>\n",
              "      <td>0.011695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>2024</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011697</td>\n",
              "      <td>0.011697</td>\n",
              "      <td>0.011697</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74295b36-ba95-4f02-abef-e1b374f44482')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74295b36-ba95-4f02-abef-e1b374f44482 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74295b36-ba95-4f02-abef-e1b374f44482');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6901eeac-3871-47ab-a320-3588c6107d1c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6901eeac-3871-47ab-a320-3588c6107d1c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6901eeac-3871-47ab-a320-3588c6107d1c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pred_female",
              "summary": "{\n  \"name\": \"df_pred_female\",\n  \"rows\": 1020,\n  \"fields\": [\n    {\n      \"column\": \"Local\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Brasil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sexo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Feminino\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ano\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 2020,\n        \"max\": 2070,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          2063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grupo Et\\u00e1rio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 90,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Previs\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04635880265041058,\n        \"min\": 0.00015315195,\n        \"max\": 0.1899922,\n        \"num_unique_values\": 471,\n        \"samples\": [\n          0.00015666687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Limite Inferior\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.046358799527128625,\n        \"min\": 0.00015315077,\n        \"max\": 0.18999217,\n        \"num_unique_values\": 514,\n        \"samples\": [\n          0.0027258494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Limite Superior\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.046358805909033275,\n        \"min\": 0.00015315195,\n        \"max\": 0.18999223,\n        \"num_unique_values\": 515,\n        \"samples\": [\n          0.0027258794\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Organizar por ano e grupo etário\n",
        "df_pred_female = df_pred_female.sort_values(by=['Ano', 'Grupo Etário'])\n",
        "df_pred_female.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TBwu5G6TKQOW",
        "outputId": "82d94cac-ed5f-4a8f-f403-eb9e56865e71"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Local      Sexo   Ano  Grupo Etário  Previsão  Limite Inferior  \\\n",
              "0    Brasil  Feminino  2020             0  0.011694         0.011694   \n",
              "51   Brasil  Feminino  2020             1  0.000484         0.000484   \n",
              "102  Brasil  Feminino  2020             5  0.000173         0.000173   \n",
              "153  Brasil  Feminino  2020            10  0.000244         0.000244   \n",
              "204  Brasil  Feminino  2020            15  0.000456         0.000456   \n",
              "\n",
              "     Limite Superior  \n",
              "0           0.011694  \n",
              "51          0.000484  \n",
              "102         0.000173  \n",
              "153         0.000244  \n",
              "204         0.000456  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c67150f-f45e-4494-bf17-bd6a097bd4f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Local</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Ano</th>\n",
              "      <th>Grupo Etário</th>\n",
              "      <th>Previsão</th>\n",
              "      <th>Limite Inferior</th>\n",
              "      <th>Limite Superior</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>2020</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011694</td>\n",
              "      <td>0.011694</td>\n",
              "      <td>0.011694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>2020</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>0.000484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>2020</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.000173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>2020</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.000244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>2020</td>\n",
              "      <td>15</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.000456</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c67150f-f45e-4494-bf17-bd6a097bd4f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c67150f-f45e-4494-bf17-bd6a097bd4f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c67150f-f45e-4494-bf17-bd6a097bd4f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-abe99dca-74af-42f5-9ec8-70f31a287fae\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-abe99dca-74af-42f5-9ec8-70f31a287fae')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-abe99dca-74af-42f5-9ec8-70f31a287fae button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pred_female",
              "summary": "{\n  \"name\": \"df_pred_female\",\n  \"rows\": 1020,\n  \"fields\": [\n    {\n      \"column\": \"Local\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Brasil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sexo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Feminino\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ano\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 2020,\n        \"max\": 2070,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          2063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grupo Et\\u00e1rio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 90,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Previs\\u00e3o\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.046358802650410584,\n        \"min\": 0.00015315195,\n        \"max\": 0.1899922,\n        \"num_unique_values\": 471,\n        \"samples\": [\n          0.020462893\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Limite Inferior\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04635879952712854,\n        \"min\": 0.00015315077,\n        \"max\": 0.18999217,\n        \"num_unique_values\": 514,\n        \"samples\": [\n          0.00089226017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Limite Superior\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0463588059090333,\n        \"min\": 0.00015315195,\n        \"max\": 0.18999223,\n        \"num_unique_values\": 515,\n        \"samples\": [\n          0.0008922894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar Previsão de 2024, 2034, 2044, 2054, 2064, 2070\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_pred_female[df_pred_female['Ano'] == 2024], x='Grupo Etário', y=np.log(df_pred_female[df_pred_female['Ano'] == 2024]['Previsão']), label='2024')\n",
        "sns.lineplot(data=df_pred_female[df_pred_female['Ano'] == 2034], x='Grupo Etário', y=np.log(df_pred_female[df_pred_female['Ano'] == 2034]['Previsão']), label='2034')\n",
        "sns.lineplot(data=df_pred_female[df_pred_female['Ano'] == 2044], x='Grupo Etário', y=np.log(df_pred_female[df_pred_female['Ano'] == 2044]['Previsão']), label='2044')\n",
        "sns.lineplot(data=df_pred_female[df_pred_female['Ano'] == 2054], x='Grupo Etário', y=np.log(df_pred_female[df_pred_female['Ano'] == 2054]['Previsão']), label='2054')\n",
        "sns.lineplot(data=df_pred_female[df_pred_female['Ano'] == 2064], x='Grupo Etário', y=np.log(df_pred_female[df_pred_female['Ano'] == 2064]['Previsão']), label='2064')\n",
        "sns.lineplot(data=df_pred_female[df_pred_female['Ano'] == 2070], x='Grupo Etário', y=np.log(df_pred_female[df_pred_female['Ano'] == 2070]['Previsão']), label='2070')\n",
        "plt.xlabel('Grupo Etário')\n",
        "plt.ylabel('nMx (log)')\n",
        "plt.title('Previsão de nMx em escala logarítmica')\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45) # Rotate y-axis labels by 45 degrees\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "c75251be-9ce1-479f-fdc9-df84e1aee225",
        "id": "YHyg0OlXKWji"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0wAAAIsCAYAAADBHilZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAmkhJREFUeJzs3Xd4FOUCxeHf7GbTCyQkdBTR0EtAOmJvCEixUlRAikCwoICgYgDpTZoiIirSVFABQSxYEcQCCkpTOkgJLYG0ze7cP0L2EqmBJLNJzvs8PnczOztzdnf05uSb+cYwTdNEREREREREzmKzOoCIiIiIiIi3UmESERERERE5DxUmERERERGR81BhEhEREREROQ8VJhERERERkfNQYRIRERERETkPFSYREREREZHzUGESERERERE5DxUmERERyZfS0tKYNm0a33//vdVRRKQAU2ESEQFuueUWBgwYkO3XvfPOO8TExNCtWzcOHTpEly5d+PLLL3MhYVZ79+6lYsWKLFq0KNf3Jd6tYsWKTJ482Wu3l5umTJnC3LlzqVKlSq7uZ9GiRVSsWJG9e/fm6n5ExDupMIlInsv85SPzn+rVq3PnnXcyZMgQ4uPjrY6XLa+//jo9evQgLS2Npk2bsmPHDho0aGB1rFw1efJkKlasSKVKlfj333/Pev7kyZPUqFGDihUrMmTIEAsSSmGwadMm3n77bSZMmEBERAQHDx5k8uTJbNq0yepoIlLA+FgdQEQKrz59+lCmTBnS0tL49ddfmTdvHt9++y1Lly4lICAgT7N89tlnGIaR7dctWLCAcuXK0b17dw4fPkyRIkVwOBy5kND7+Pr6snTpUrp27Zpl+eeff25RIiksXC4XgwYNolevXtStWxeAQ4cOMWXKFEqXLk3lypVzdH/33nsv99xzD76+vjm6XRHJH1SYRMQyTZs2pXr16gDcf//9FClShFmzZvHVV1/RvHnzc74mKSmJwMDAHM9yub8IlStXzvM4MjIyp+LkCzfeeCOffvrpWYVp6dKl3HTTTaxYscKiZFKQJScnExAQkKeno9rtdux2e57tT0S8i07JExGvkXkqW+Z1AgMGDCAmJobdu3fTtWtXYmJiePbZZwFwu928/fbb3HPPPVSvXp1GjRrx0ksvceLECc/2unfvzq233nrOfT344IO0adPG8/N/r2FyOp1MmTKFO+64g+rVq1O/fn0efvhhVq1a5Vln06ZN9OvXj1tuuYXq1avTuHFjnn/+eY4dO3bW/v766y8ef/xxateuTUxMDI8++ijr16+/pM8lISGBAQMGUKdOHa6//nr69+9PYmLiOdf9559/6NOnD/Xq1aN69eq0adOGr7766qL7yLwmaubMmSxYsIDbbruNatWq0bZtW/74449zvqZ58+Zs2rSJf/75x7Ps8OHDrFmz5pyFt3///lSvXj3L+gBdunShbt26HDx48IIZL+U7h4zvsnv37vz000+0adOGGjVq0KJFC3766ScgYwSsRYsWns/nr7/+uujnAxnfwyuvvMKNN95ItWrVuP3223njjTdwu91Z1vv0009p06YNMTEx1K5dmxYtWvDOO++cta3hw4dzyy23UK1aNZo2bUq/fv04evQokDGZwauvvkqbNm2oU6cOtWrVol27dqxZs+aiOfft28fLL7/MnXfeSY0aNahfvz59+vS5outvLvX43bx5Mx06dKBGjRo0bdqUadOmsXDhwrOu//nyyy/p1q0bTZo0oVq1atx2221MnToVl8uVZXsdO3akefPmbNy4kfbt21OzZk3Gjx/vea5jx44A/PTTT9x3330APP/8857TfTNLVeZ2MvPVrFmT22+/nc8++wyAtWvXcv/991OjRg3uvPNOfvzxxyw5zncN07fffkuHDh0833Xbtm1ZsmSJ5/lffvmFPn36cNNNN1GtWjVuvPFGhg8fTkpKyuV8DSJiEY0wiYjX2L17NwBFihTxLEtPT6dLly7UqVOH/v374+/vD8BLL73ERx99RJs2bejYsSN79+5lzpw5/PXXX8ybNw+Hw8Hdd99N//79+eOPP6hRo4Znm/v27WP9+vX069fvvFmmTJnC9OnTPb9EnTx5ko0bN/Lnn3/SuHFjAL7//nv27dtH27ZtiYyMZNu2bbz//vv8/fffvP/++55T/LZt20b79u0JCgri8ccfx8fHhwULFtCxY0fee+89atased4cpmnSs2dPfv31Vx566CEqVKjAF198Qf/+/c9ad9u2bTz88MMUL16crl27EhgYyPLly+nVqxeTJ0/m9ttvv+h3sHTpUk6dOsWDDz6IYRi8+eabxMbG8uWXX551qmHdunUpUaIES5cu5cknnwRg2bJlBAYGctNNN5217UGDBrFmzRr69+/PggULsNvtzJ8/nx9++IHRo0dTvHjxC2a7lO88065du+jbty8PPfQQLVu25K233qJHjx7ExcUxYcIEHn74YQDeeOMNnnrqKT777DNstvP/DTE5OZkOHTpw8OBBHnroIUqWLMm6desYP348hw8fZtCgQQCsWrWKZ555hoYNG3rK/fbt2/ntt9949NFHATh16hTt27fnn3/+oW3btlSpUoVjx46xcuVKDh48SHh4OCdPnuSDDz6gefPm3H///Zw6dYoPP/yQxx9/nA8++OCCp5xt2LCBdevWcc8991CiRAn27dvHvHnzeOSRR/j000+zfbrrpR6/Bw8e9LzHbt26ERgYyAcffHDO0duPPvqIwMBAOnXqRGBgIGvWrGHSpEmcPHnyrGP7+PHjdO3alXvuuYeWLVsSERFx1vYqVKhAnz59mDRpEg8++CB16tQBoHbt2p51Tpw4QY8ePWjWrBl33XUX8+bN45lnnsHtdjN8+HAeeughmjdvzsyZM+nTpw/ffPMNwcHB5/1cFi1axMCBA7nuuuvo3r07ISEhbNq0ie+//54WLVoAGaf6pqSk8PDDD1OkSBH++OMP3nvvPQ4cOMCkSZOy9T2IiIVMEZE8tnDhQjM6Otr88ccfzSNHjpj//vuv+emnn5r16tUza9SoYR44cMA0TdPs37+/GR0dbY4dOzbL63/++WczOjraXLx4cZbl3333XZbliYmJZrVq1cyRI0dmWW/GjBlmxYoVzX379nmW3XzzzWb//v09P7ds2dLs1q3bBd9HUlLSWcuWLl1qRkdHmz///LNnWc+ePc2qVauau3fv9iw7ePCgGRMTY7Zv3/6C+/jiiy/M6Ohoc8aMGZ5l6enpZrt27czo6Ghz4cKFnuWPPvqo2bx5czM1NdWzzO12mw8++KB5xx13XHA/e/bsMaOjo8169eqZx48f9yz/8ssvzejoaHPlypWeZZMmTTKjo6PNI0eOmCNHjjRvv/12z3Nt27Y1BwwYYJqmaUZHR5txcXFZ9vP999+b0dHR5rRp08zdu3ebtWrVMnv27HnBbKZ56d+5aWZ8l9HR0eZvv/121n5r1KiR5XufP3++GR0dba5Zs+aC+586dapZq1Ytc8eOHVmWjx071qxcubK5f/9+0zRNc9iwYWbt2rXN9PT0827r1VdfNaOjo83PP//8rOfcbrdpmhnf8Znfo2ma5okTJ8xGjRqZzz//fJbl0dHR5qRJkzw/Jycnn7XddevWmdHR0eZHH310wfd5ru1d6vE7dOhQs2LFiuZff/3lWXbs2DGzXr16ZnR0tLlnz54LZnzxxRfNmjVrZnnfHTp0MKOjo8158+adtX6HDh3MDh06eH7+448/zvp34r/bWbJkiWfZP//8Y0ZHR5uVKlUy169f71meeaycuZ3M/2ZlvoeEhAQzJibGvP/++82UlJQs+8r8Ds/3PqdPn37Wf39ExLvplDwRscxjjz1Gw4YNufHGG3n66acJCgpiypQpZ400ZI4GZPrss88ICQmhcePGHD161PNP1apVCQwM9Jx6FRwcTNOmTVm+fDmmaXpev2zZMmrVqkWpUqXOmy00NJRt27axc+fO865z5l/qU1NTOXr0qOev7X/++SeQcXH6qlWruO222yhbtqxn/aioKJo3b86vv/7KyZMnz7uP7777Dh8fnyyfgd1up0OHDlnWO378OGvWrOHuu+/m5MmTns/k2LFjNGnShJ07d170lDeAZs2aERYW5vn5+uuvB2DPnj3nXL9Fixbs2rWLP/74g127drFhwwbPX9fPpUmTJjz44INMnTqV2NhY/Pz8LmkmvUv9zjNde+21xMTEeH7O/F4aNGiQ5XvPXH6+93fm/uvUqUNoaGiW/Tdq1AiXy8XPP/8MZBw3ycnJWU7d/K/PP/+cSpUqnXPEL3NU0m63e0Zm3G43x48fJz09nWrVql30FMLMUVjIOLX02LFjlCtXjtDQ0Es+/TBTdo7f77//nlq1amUZ/SpSpMg5j4czM2Yer9dffz3Jycls3749y7q+vr5ZTp+9XIGBgdxzzz2en6+55hpCQ0OpUKFCllHeSzkmVq1axalTp+jWrRt+fn5Znjtz8pgz32dSUhJHjx4lJiYG0zSz/V2IiHV0Sp6IWOall16ifPny2O12ihUrRvny5c86LcrHx4cSJUpkWbZr1y4SExNp2LDhObd75MgRz+NmzZrx5Zdfsm7dOmrXrs3u3bv5888/GThw4AWz9enTh549e3LnnXcSHR1NkyZNuPfee6lUqZJnnePHjzNlyhSWLVuWZZ+A5xqjo0ePkpycTPny5c/aR4UKFXC73fz7779cd91158yxb98+IiMjCQoKyrL8v9vbvXs3pmny6quv8uqrr55zW0eOHLnoaW8lS5bM8nNmeUpISDjn+lWqVOGaa65h6dKlhIaGEhkZedFp1fv378/KlSvZtGkT48aNO+cpVv+Vne/8XO8jJCQE4KxjKfOUq/O9vzP3v2XLlvPuP/Pao3bt2rF8+XK6du1K8eLFady4MXfffTdNmzb1rLt7927uuOOOC+4PMk5be+utt9ixYwdOp9OzvEyZMhd8XUpKCtOnT2fRokUcPHgwyx8Lznft2/lk5/jdt28ftWrVOmu9MydGybRt2zYmTpzImjVrzvqDwX8zFi9ePEdmpytRosRZM2GGhIScdUxkHisXOiYyTx8+37+3mfbv38+kSZNYuXLlWdfaXegPJSLiXVSYRMQyNWrU8MySdz6+vr5nlSi3201ERARjx44952vCw8M9j2+++WYCAgJYvnw5tWvXZvny5dhsNu66664L7rdu3bp88cUXfPXVV6xatYoPP/yQd955h7i4OO6//34AnnrqKdatW0eXLl2oXLkygYGBuN1uHn/88Sy/pOaFzIkHOnfuzA033HDOdc71i+t/nW8msAu9n+bNmzNv3jyCgoK4++67L3gtEGRMlpFZcLZu3XrRTJC97xzO/z4u5/1l7r9x48Y8/vjj53z+6quvBiAiIoKPP/6YH374ge+++47vvvuORYsW0apVK0aNGnXBfZzpk08+YcCAAdx222106dKFiIgI7HY706dPv+ho2NChQ1m0aBGPPvootWrVIiQkBMMwePrpp/P8uDyXhIQEOnToQHBwMH369KFcuXL4+fnx559/Mnbs2LMm0ThzlOZK5PQxcTEul4tOnTpx4sQJHn/8ca655hoCAwM5ePAgAwYMOOt9ioj3UmESkXynXLlyrF69mtq1a1/0l6nMCQg+++wznn/+eZYtW8b1119/0ZEWyDidqG3btrRt25ZTp07RoUMHJk+ezP3338+JEydYvXo1sbGx9O7d2/Oa/57CFx4eTkBAADt27Dhr+9u3b8dms501GnKm0qVLs2bNGk6dOpVllOm/28s8XcrhcNCoUaOLvrec1KJFCyZNmsThw4cZM2bMBddNSkri+eef95wy9+abb3LbbbdlmZTjXLLzneeGcuXKkZSUdEmfra+vL7fccgu33HILbrebl19+mQULFtCzZ0+uuuoqypUrx7Zt2y64jRUrVlC2bFmmTJmSZVTkUiYKWLFiBa1atcoy62Nqamq2R5cge8dv6dKl2bVr11nrZY7GZFq7dq1ndDbzHkrAFc3iB1zWfdQuV+YfH7Zt28ZVV111znW2bt3Kzp07GTVqFK1atfIsv9DpmiLinXQNk4jkO3fffTcul4tp06ad9Vx6evpZp9I0a9aMQ4cO8cEHH7B582buvvvui+7jv1ODBwUFUa5cOdLS0oDz/1X6v9NH2+12GjduzFdffZXlF8L4+HiWLl1KnTp1LjgTV9OmTUlPT2fevHmeZS6Xi/feey/LehEREdSrV48FCxZw6NChs7aTecpYbihXrhwDBw6kb9++Fy0+Y8eO5d9//2XkyJEMGDCA0qVLM2DAAM/nej7Z/c5z2t133826dev4/vvvz3ouISGB9PR04OzjxmazUbFiRQDPe7zjjjvYvHkzX3zxxVnbyhzVyDy+zhzl+P333y9pKvpzHZuzZ88+a8ruS5Gd47dJkyasX7+eTZs2edY7fvx4lmm2Ac8I5JnvLS0tjblz52Y735kyrynM7WMBMt5rUFAQ06dPJzU1Nctzme/rXO/TNE3efffdXM8nIjlLI0wiku/Uq1ePBx98kOnTp7Np0yYaN26Mw+Fg586dfPbZZwwaNCjLKXc33ngjQUFBjBo1Crvdzp133nnRfdxzzz3Uq1ePqlWrUqRIETZs2MCKFSs8ky0EBwdTt25d3nzzTZxOJ8WLF2fVqlXn/Cv5U089xY8//ki7du1o164ddrudBQsWkJaWxnPPPXfBHLfccgu1a9dm3Lhx7Nu3j2uvvZbPP//8nKMFgwcPpl27drRo0YIHHniAsmXLEh8fz/r16zlw4ACLFy++6Pu+XJnTSV/I6tWrmTt3Lr1796Zq1aoAjBgxgo4dOzJx4sQLTvOe3e88p3Xp0oWVK1fSo0cPWrduTdWqVUlOTmbr1q2sWLGCr776ivDwcF544QVOnDhBgwYNKF68OPv37+e9996jcuXKVKhQwbOtFStW8OSTT9K2bVuqVq3KiRMnWLlyJXFxcVSqVImbbrqJzz//nF69enHTTTexd+9e5s+fz7XXXktSUtIFs95000188sknBAcHc+2117J+/Xp+/PHHLNP1Z8elHr+PP/44ixcvplOnTnTo0MEzrXjJkiU5fvy4ZwQoJiaGsLAwBgwYQMeOHTEMg08++eSKT4HLnNhi/vz5BAUFERgYSI0aNbJMVpFTgoODef7553nhhRe47777aN68OaGhoWzevJmUlBRGjRrFNddcQ7ly5Rg1ahQHDx4kODiYFStW5EmhE5GcpcIkIvnSkCFDqFatGvPnz2fChAnY7XZKly5Ny5Yts9x7BcDPz49bbrmFJUuW0KhRo0uaZKBjx46sXLmSVatWkZaWRqlSpXjqqafo0qWLZ51x48YxdOhQ5s6di2maNG7cmBkzZpx1DdF1113HnDlzGDduHNOnT8c0TWrUqMGYMWMueA8myPgr9Wuvvcbw4cNZvHgxhmF4brJ75mk+kDEz3MKFC5kyZQofffQRx48fJzw8nCpVqtCrV6+LvufcdPLkSQYNGkSVKlXo0aOHZ/n111/PI488wqxZs7jjjjvOOWlApux85zktICCA2bNnM336dD777DM+/vhjgoODufrqq4mNjfVMFNCyZUvef/995s6dS0JCApGRkdx9993ExsZ6RhyCgoKYM2cOkydP5osvvuCjjz4iIiKChg0bek4VbdOmDfHx8SxYsIAffviBa6+9ljFjxvDZZ5+xdu3aC2YdNGgQNpuNJUuWkJqaSu3atZk1a9Z5r7+6mEs9fkuWLMm7777LsGHDmD59OuHh4bRv356AgACGDRvmmU2uaNGivP7664waNYqJEycSGhpKy5YtadiwYZZ/v7LL4XAwcuRIxo8fz8svv0x6ejojRozIlcIEcP/99xMREcEbb7zBtGnT8PHx4ZprruGxxx7z5Hn99dc9n4efnx+333477du35957782VTCKSOwzTG64AFRERkQLplVdeYcGCBaxbt+68p7KKiHgzXcMkIiIiOSIlJSXLz8eOHWPx4sXUqVNHZUlE8i2dkiciIiI54sEHH6RevXpUqFCB+Ph4Fi5cyMmTJ+nZs6fV0URELptOyRMREZEcMX78eFasWMGBAwcwDIMqVarQu3fvPJ/qXkQkJ6kwiYiIiIiInIeuYRIRERERETkPFSYREREREZHzKFSTPrjdbtLT07HZbJ4b6ImIiIiISOFjmiZutxsfHx/PvfLOpVAVpvT0dDZs2GB1DBERERER8RLVq1fH19f3vM8XqsKU2RyrV69u+f0gXC4XGzZs8IosUjjomJO8pONN8pqOOclLOt4Khszv8UKjS1DIClPmaXh2u91rDm5vyiKFg445yUs63iSv6ZiTvKTjrWC42KU6mvRBRERERETkPFSYREREREREzkOFSURERERE5DwK1TVMl8rlcuF0OnN9HwApKSkF8txXh8NRIN+XiIiIiBQuKkxnME2TAwcOcPz48TzZl4+PD7t27Sqw94QqUqQIJUqUKLDvT0REREQKPhWmM2SWpaioKAIDA3P1F33TNElOTiYgIKDAFQrTNElKSuLQoUMAlCxZ0uJEIiIiIiKXR4XpNJfL5SlLERERub6/zDsL+/v7F7jCBBAQEADAoUOHiIqK0ul5IiIiIpIvadKH0zKvWQoMDLQ4ScGR+Vnm9vVgIiIiIiK5RYXpPwriaI9V9FmKiIiISH6nwiQiIiIiInIeKkwiIiIiIiLnocKUz02fPp22bdsSExNDw4YN6dmzJ9u3b8+yTmpqKnFxcdSvX5+YmBhiY2OJj4/3PL9582aeeeYZbrzxRmrUqMHdd9/NO++8c959/vrrr1SpUoV77703196XiIiIiIg3UGHK59auXUv79u15//33mTVrFunp6XTp0oWkpCTPOsOHD+frr79m4sSJzJ49m0OHDtG7d2/P8xs3biQ8PJwxY8bw6aef0qNHD8aPH89777131v4SEhLo378/DRs2zJP3JyIiIiJiJU0rfgGmaZLsdOXatpPSXOCTnmVyhACHPVuTJcycOTPLzyNHjqRhw4b8+eef1K1bl8TERBYuXMjYsWM9JWf48OE0a9aM9evXU6tWLe67774s2yhbtizr16/n888/p0OHDlmeGzx4MM2bN8dut/Pll19m922LiIiIiOQrKkznYZom972+ml93HcvT/V5/VVE+6NHwsmeYS0xMBCAsLAzIGD1yOp00atTIs06FChUoVaqUpzCdbztFihTJsmzhwoXs2bOHMWPG8Nprr11WPhERERGR/ESF6QLy26TYbreb4cOHU7t2baKjowGIj4/H4XAQGhqaZd2IiAgOHz58zu389ttvLF++nOnTp3uW7dy5k3HjxjFnzhx8fHTYiIiIiEjhoN98z8MwDD7o0TB3T8lLSiYwMOCKTsk7U1xcHNu2bWPu3LmXnWvr1q307NmTXr160aRJEwBcLhd9+/YlNjaW8uXLX/a2RURERKRwO3jsJMWLBlsdI1tUmC7AMAwCfXPnIzJNE9LtBPr65MgNXocMGcI333zDe++9R4kSJTzLixUrhtPpJCEhIcso05EjR4iMjMyyjb///pvHHnuMBx98kJ49e3qWnzp1io0bN7Jp0yaGDh0KZIxmmaZJlSpVmDlzpiaBEBEREZHzOpmUzNvdY0lNO0pwsZJ0nzrV6kiXTIUpnzNNk6FDh/LFF18we/ZsypYtm+X5atWq4XA4WL16NXfeeScA27dvZ//+/VmuX9q2bRuPPvoorVq14umnn86yjeDgYJYsWZJl2dy5c1mzZg2TJk2iTJkyufPmRERERCTf27LhD1YMn4DTnXE5iN00LU6UPSpM+VxcXBxLly5l2rRpBAUFea5LCgkJwd/fn5CQENq2bcvIkSMJCwsjODiYYcOGERMT4ylMW7du5dFHH6VJkyZ06tTJsw273U54eDg2m81zTVSmiIgI/Pz8zlouIiIiIpJp2ey32fLpF7jNE4CNkCKleHzaNKtjZYsKUz43b948ADp27Jhl+YgRI2jTpg0AAwcOxGaz0adPH9LS0mjSpAmDBw/2rLtixQqOHj3K4sWLWbx4sWd56dKlWblyZR68CxEREREpaGYNHMDRf/4GUjAMf66qXpW2g+KsjpVtKkz53JYtWy66jp+fH4MHD85Sks4UGxtLbGxstvZ7Oa8RERERkYLP7XLzetceJJ86ALixGUVo0v5e6ra43+pol0WFSUREREREcsS/+/fx4bMvkuY6BIDDFsVDIwYRdXUFi5NdPhUmERERERG5Yqs/X8ZPb83HZR4FIDCgJF1nTMPH4bA42ZVRYRIRERERkSvy/tiR7P1lHaZ5CvAl6qqr6Th6vNWxcoQKk4iIiIiIXBbTNHmjV29OHtkHpGMzQqh+Z1Nu6/SE1dFyjAqTiIiIiIhk26mTp5jVow+pzoMA+BjFaN6/JxVi6lmcLGepMImIiIiISLZsXvcLK0ZPId0dD4C/ozidX59IQHCIxclyngqTiIiIiIhcsuWz3mDzim9wmwmAnbCI0vnuZrTZocIkIiIiIiKXZFb/Zzm6cweQimEEUr5OTVo/N8jqWLlKhUlERERERC4oLTWNN3v0IjnpAGBiN4pyQ6cHqHNnC6uj5ToVJhEREREROa8Du3fwfv+hON0ZN6P1tUfRbsxgIkpfZXGyvGGzOoBcmenTp9O2bVtiYmJo2LAhPXv2ZPv27VnWSU1NJS4ujvr16xMTE0NsbCzx8fGe548dO0aXLl1o0qQJ1apV48Ybb2TIkCGcPHnynPv89ddfqVKlCvfee2+uvjcRERERsdaqTz9hfr+XTpclg8CgkjzxzvRCU5ZAhSnfW7t2Le3bt+f9999n1qxZpKen06VLF5KSkjzrDB8+nK+//pqJEycye/ZsDh06RO/evT3P22w2br31Vl577TVWrFjByJEj+fHHHxk8ePBZ+0tISKB///40bNgwT96fiIiIiFhjwYgh/DR7Di7zGOBH8QqVeeKtGfg4HFZHy1P54pS8vXv3Mm3aNNasWUN8fDxRUVG0bNmSHj164Ovrm3s7Nk1wJl18vcvddloy+JhgGP9f7gjM+vNFzJw5M8vPI0eOpGHDhvz555/UrVuXxMREFi5cyNixYz0lZ/jw4TRr1oz169dTq1YtwsLCaNeunWcbpUuXpl27dmdtG2Dw4ME0b94cu93Ol19+mc03LSIiIiL5wfQeT3Dy2H7Ahc0IpUbzW7m1QxerY1kiXxSm7du3Y5omQ4YM4aqrrmLr1q28+OKLJCcn079//9zZqWnCW3fCnp9yZfMGEHSuJ8o2gM6fZas0nSkxMRGAsLAwADZu3IjT6aRRo0aedSpUqECpUqU8hem/Dh48yBdffEHdunWzLF+4cCF79uxhzJgxvPbaa5eVT0RERES8V+Kxo7zT+zlS00/fjNYWSctBfShfLcbiZNbJF4WpadOmNG3a1PNz2bJl2bFjB/Pmzcu9wgRk1Jr8w+12M3z4cGrXrk10dDQA8fHxOBwOQkNDs6wbERHB4cOHsyx75pln+Oqrr0hJSeHmm2/mlVde8Ty3c+dOxo0bx5w5c/DxyReHjYiIiIhkw19rf+SL8W+Qbp6+Ga1vCbq+MQnfgECLk1kr3/7mm5iY6BlFyS6Xy3XOZaZpev4BoNPyXDslzzRNkpNTCAjwx/jvKXkZK2R7m3FxcWzdupW5c+d63sN///dcOTINGDCAXr16sXPnTsaPH8+IESMYPHgwLpeLvn37Ehsby9VXX53lMzrfdjOfM00Tl8t1zs9c8lbmd6DvQvKCjjfJazrmJC8VxONt+ZtT2fb1atxmIuBDkagyPDbxVaBgvc8zXer7MswL/cbrpXbt2kWbNm3o378/DzzwwCW/zuVysX79+vM+7+PjQ9myZfHz88uBlHlr5MiRfPvtt7z55puULl3as3zt2rX06NGDb7/9lpCQEM/yZs2a0a5dOzp06HDO7a1bt44uXbqwYsUK/P39ufHGG7Hb7Z7n3W43pmlit9uZOnUq9erVO2sbqamp7Nmzh/T09Bx8pyIiIiKSk36eNZNTh/8FnBhGEBGVr6Va8zZWx8oztWrVyvJ77n9ZOsI0duxYZsyYccF1li1bRoUKFTw/Hzx4kMcff5y77rorW2XpTNWrVz/rQ0lJSWHXrl0EBATg7+9/WdvNjowRpmQCAgKyjjBdxnaGDh3KN998w7vvvsvVV1+d5fk6dergcDhYv349d955J5BxTdiBAweoV68egYHnHmLNnEzDbrcTGRnJ4sWLszw/b9481qxZw6uvvkqZMmXOuR2bzYbD4eDaa6/Nk89ULszlcrFhw4ZzHv8iOU3Hm+Q1HXOSlwrK8eZMS+OtHrEkpxwAwG6Ec2P3DtRoeqvFyfJG5vd4MZYWps6dO9O6desLrlO2bFnP44MHD/LII48QExPD0KFDL3u/drv9rIPbbrdjGIbnn7xypfuLi4tj6dKlTJs2jeDgYM/9lUJCQvD39yc0NJS2bdsyatQoihQpQnBwMMOGDSMmJoaYmIyL97799lvi4+OpXr06gYGB/P3334wePZratWt7Pv+KFStm2W9ERAR+fn5nLT/XezvX5y3W0fcheUnHm+Q1HXOSl/Lz8fbv9m18MGjE/29G6xNFhwnDKRpVwuJk3sfSwhQeHk54ePglrZtZlqpWrcqIESOw2XQLKcgY6QHo2LFjluUjRoygTZuModSBAwdis9no06cPaWlpNGnSJMs9lvz8/Pjggw8YMWIEaWlplCxZkttvv51u3brl3RsRERERkTzxw0cL+HnBEtzmccBGUEgJerz5htWxvFa+mPTh4MGDdOzYkVKlStG/f3+OHj3qeS4yMtLCZNbbsmXLRdfx8/Nj8ODB57wRLUCDBg2YP39+tvYbGxtLbGxstl4jIiIiItaaP+RF9v+1CdNMAfwpUSma9nHDrY7l1fJFYVq1ahW7du1i165dWaYXh0srDCIiIiIihd30bt05eeJfwI3NKELN1ndyy4MdL/q6wi5fFKY2bdp4Ti8TEREREZFLl3Aknnf79PfcjNZhi6RV3HOUi65icbL8IV8UJhERERERyb6Nq77mqylvk+4+AoC/Xwm6zpiGr5+vxcnyDxUmEREREZECaOnU8Wz9fi2meRJwEFayHI+fvhmtXDoVJhERERGRAuatp/pw7N/dQDqGEcI1N9SnVa+nrI6VL6kwiYiIiIgUEGnJSczo3oeU1Iyb0foYEdwY24VajZte5JVyPipMIiIiIiIFwJF9u5jzbJznZrR+PsXpMHk0RcIjLE6Wv6kwiYiIiIjkc5vX/sBn49/AZR4FbASFlaT79NcxDMPqaPmeCpOIiIiISD723fuz+XXRctxmAuBLsQrX8ejwUVbHKjBUmERERERE8qmPxg5nxy/rMM1kDCOIqxvXp03sM1bHKlBsVgeQKzN9+nTatm1LTEwMDRs2pGfPnmzfvj3LOqmpqcTFxVG/fn1iYmKIjY0lPj7+nNs7duwYTZs2pWLFiiQkJJxznV9//ZUqVapw77335vj7EREREZFL885zz7D957WYZjI2owjXP3y/ylIuUGHK59auXUv79u15//33mTVrFunp6XTp0oWkpCTPOsOHD+frr79m4sSJzJ49m0OHDtG7d+9zbm/QoEFUrFjxvPtLSEigf//+NGzYMMffi4iIiIhcmunduhO/exuQjo8Rwd39n6LpvfdZHatA0il5F2CaJsnpybm7bSdZLsYL8AnI1sV5M2fOzPLzyJEjadiwIX/++Sd169YlMTGRhQsXMnbsWE/JGT58OM2aNWP9+vXUqlXL89q5c+eSmJhIz549+e677865v8GDB9O8eXPsdjtffvllNt6xiIiIiFwpZ1oab3TpSUpaxrThvvYo2k8cRXhUpMXJCi4VpvMwTZNHlj/C+sPr83S/MVExvHPXO5c9o0liYiIAYWFhAGzcuBGn00mjRo0861SoUIFSpUplKUx///0306ZN4/3332fPnj3n3PbChQvZs2cPY8aM4bXXXrusfCIiIiJyeU4cPsi7fZ4n7fS04f6+JXj8zWn4+flanKxgU2G6gPw2DaPb7Wb48OHUrl2b6OhoAOLj43E4HISGhmZZNyIigsOHDwOQlpbGM888w3PPPUepUqXOWZh27tzJuHHjmDNnDj4+OmxERERE8tI/69aydPRU0t1H0LTheUu/+Z6HYRi8c9c7uXtKXnIyAQEBV3RK3pni4uLYtm0bc+fOzdbrxo0bR4UKFc47iYPL5aJv377ExsZSvnz5y8omIiIiIpdnzeL3WT33E9zmCcBB0auuofPocVbHKjRUmC7AMAwCHYG5sm3TNMEJgY7AHPnLwJAhQ/jmm2947733KFGihGd5sWLFcDqdJCQkZBllOnLkCJGRGee6rlmzhq1bt7JixYr/ZwMaNGhAjx49eOyxx9i4cSObNm1i6NChQMZolmmaVKlShZkzZ2oSCBEREZFcsGTyWLatWotpJmEYAZStW4f7+w6wOlahosKUz5mmydChQ/niiy+YPXs2ZcuWzfJ8tWrVcDgcrF69mjvvvBOA7du3s3//fs/1S5MnTyYlJcXzmg0bNjBw4EDmzJlDuXLlCA4OZsmSJVm2O3fuXNasWcOkSZMoU6ZM7r5JERERkULovYH9OPjPNsCJzQijRutm3Ppge6tjFToqTPlcXFwcS5cuZdq0aQQFBXmuSwoJCcHf35+QkBDatm3LyJEjCQsLIzg4mGHDhhETE+MpTOXKlcuyzWPHjgEZk0NkjkplXhOVKSIiAj8/v7OWi4iIiMiVe6PHEyQe2we48TEiuPWZ7lSr1+iir5Ocp8KUz82bNw+Ajh07Zlk+YsQI2rRpA8DAgQOx2Wz06dOHtLQ0mjRpwuDBg/M8q4iIiIhcWLrTyRtdniA5NWPacIctigfGvEyJMuUu8krJLSpM+dyWLVsuuo6fnx+DBw++5JJUv379i243NjaW2NjYS9qeiIiIiFxc4pF43o7tR5orY9pwP0dxukyfREBQkMXJCjcVJhERERERi+3e9AcfxY0n3YwHDAJDStJjxnRNG+4FVJhERERERCz0y/LFfP/O+7jN44APYaWu5vEJEy1OJZlUmERERERELPLZG6/y18ofMc1TGIY/JWvU4OGBL1kdS86gwiQiIiIiYoF5Lw1k/5bNQBo2I4Qq99zGnR27WB1L/kOFSUREREQkj73Zqxcn4vcAbuxGODf07ESdpjdbHUvOQYVJRERERCSPpDudzOj6BEnJmdOGR9JmxIuUufoai5PJ+agwiYiIiIjkgaQTx3jriWdJdR0EwM+nOJ2mTyIoWNOGezMVJhERERGRXLb/78188OJI0t3xAAQEluSJt97QtOH5gAqTiIiIiEgu2vD1Z3w1fQ4u8xhgJySqHN0mT7Y6llwiFSYRERERkVzy5azp/LHia0zzJOBHiSpVaT94iNWxJBtsVgeQKzN9+nTatm1LTEwMDRs2pGfPnmzfvj3LOqmpqcTFxVG/fn1iYmKIjY0lPj4+yzoVK1Y8659PP/30nPv89ddfqVKlCvfee2+uvS8RERGR/O79YS/x+2efY5onMYwQKt1xu8pSPqQRpnxu7dq1tG/fnurVq+NyuRg/fjxdunTh008/JTAwEIDhw4fz7bffMnHiREJCQhg6dCi9e/dm/vz5WbY1YsQIbrjhBs/PoaGhZ+0vISGB/v3707Bhw7NKl4iIiIhkmPVkLEcP7AZc2I2iNOzSjvq33211LLkMKkwXYJomZnJyrm3bnZyMG7Jc7GcEBGTr4r+ZM2dm+XnkyJE0bNiQP//8k7p165KYmMjChQsZO3YsDRs2BDIKVLNmzVi/fj21atXyvDY0NJTIyMgL7m/w4ME0b94cu93Ol19+eck5RURERAqL1zt349Sp/QD42CK5N24AV0dXtDiVXC4VpvMwTZNd7dqTvG5dnu43oHZtrprz3mXPmJKYmAhAWFgYABs3bsTpdNKoUSPPOhUqVKBUqVJnFaa4uDgGDRpE2bJleeihh2jbtm2WHAsXLmTPnj2MGTOG11577bLyiYiIiBRUyScTmdn9KVLTM6YN97UXp+O08RQpEmZxMrkSKkwXks+meXS73QwfPpzatWsTHR0NQHx8PA6H46zT6yIiIjh8+LDn5z59+tCgQQMCAgL44YcfiIuLIykpiUceeQSAnTt3Mm7cOObMmYOPjw4bERERkTMd2rWd+QOG4nRn/H7lH1CSrtOn4uvna3EyuVL6zfc8DMPgqjnv5eopeUnJyQT+5xS87J6Sd6a4uDi2bdvG3Llzs/3aXr16eR5XqVKF5ORkZs6cySOPPILL5aJv377ExsZSvnz5y8omIiIiUlD9ueobvpj8Fi7zKGAjOKIM3adNszqW5BAVpgswDAPj9MQJOc00TWyALTAwR25YNmTIEL755hvee+89SpQo4VlerFgxnE4nCQkJWUaZjhw5csHrlWrWrMm0adNIS0sjJSWFjRs3smnTJoYOHQpkjGaZpkmVKlWYOXOm5/ooERERkcLkm7mzWLf4c9xmIuBLsehKPDp0uNWxJAepMOVzpmkydOhQvvjiC2bPnk3ZsmWzPF+tWjUcDgerV6/mzjvvBGD79u3s378/y/VL/7Vp0ybCwsLw9fXFx8eHJUuWZHl+7ty5rFmzhkmTJlGmTJkcf18iIiIi3u7jscPZte53TDMFwwjimqaNadWzj9WxJIepMOVzcXFxLF26lGnTphEUFOS5LikkJAR/f39CQkJo27YtI0eOJCwsjODgYIYNG0ZMTIynMK1cuZIjR45Qs2ZN/Pz8WLVqFdOnT6dz584A2Gw2zzVRmSIiIvDz8ztruYiIiEhh8OvbM0k8tB9Ix2YUoW77+2nSQveoLIhUmPK5efPmAdCxY8csy0eMGEGbNm0AGDhwIDabjT59+pCWlkaTJk0YPHiwZ10fHx/mzJnD8OEZw8flypVjwIABPPDAA3n0LkRERETyjxndnuDUyX8BEx9bMe4e+DTR1WtaHUtyiQpTPrdly5aLruPn58fgwYOzlKQzNW3alKZNm2Zrv7GxscTGxmbrNSIiIiL52dnThkfRftIYwotFWJxMcpMKk4iIiIjIRez/ezMfvDiK9NPThvv5Fqfz9CkEBgZYnExymwqTiIiIiMgF/LJ8Md+/8z5u8zhgJziiNNd36YKf7rFUKNisDiAiIiIi4q2WTh3Pd++8d7os+VOiSk0enzzZ6liShzTCJCIiIiJyDu/268vhXdsBJzYjlMr33MpdHbvgcrmsjiZ5SIVJREREROQ/Xu/S7YyZ8CK4pU9XqjdsYnUssYAKk4iIiIjIaeeaCe+hca8QWbKkxcnEKipMIiIiIiLAvr838eGLoz0z4fn7laDrjGn4anKHQk2FSUREREQKvbXLF7PqjJnwQiLK0G3aVKtjiRfIN4WpR48ebN68mSNHjhAWFkbDhg159tlnKV68uNXRRERERCQfWzJlHNt++AnTTAL8KV61Ch1eGmJ1LPES+aYwNWjQgB49ehAZGcnBgwcZPXo0Tz75JPPnz7c6moiIiIjkU+/278vhnf+fCa9Ks1u585EuVscSL5Jv7sP02GOPUatWLUqXLk3t2rXp2rUr69evx+l0Wh3NUtOnT6dt27bExMTQsGFDevbsyfbt27Osk5qaSlxcHPXr1ycmJobY2Fji4+PP2taiRYto0aIF1atXp2HDhsTFxZ1zn7t27SImJobrr78+V96TiIiISF54vUt3Du/cCjjxsUVw+9O9VJbkLPlmhOlMx48fZ8mSJcTExOBwOLL9+nPNne9yuTBN0/NPbsvcx5Xua+3atbRr147q1avjcrmYMGECXbp0YenSpQQGBgIwfPhwvv32WyZOnEhwcDBDhw6ld+/ezJs3z7OdWbNmMWvWLJ577jlq1qxJcnIy+/btOyuf0+nkmWee4frrr2fdunUXzJ/5WbpcLt2vwAtkfgf6LiQv6HiTvKZjTrIjKTGRd3r1zTIT3gNjh1CseMlLOoZ0vBUMl/r9GWZetIMcMmbMGObMmUNycjK1atXi9ddfp2jRopf8epfLxfr168/7vI+PD2XLlsXPzw/I+IU/Pc19pbGzxcfXhmEYl/36Y8eOceuttzJjxgzq1KlDYmIit956K8OHD+e2224DYMeOHbRt25a3336bGjVqkJCQwF133cWECROoX7/+Bbf/6quvcvjwYerVq8fYsWP57rvvzrtuamoqe/bsIT09/bLfj4iIiEhOOvbvHv6c84lnJjw/3+Jc3/NxHL6aCa+wqlWrFna7/bzPWzrCNHbsWGbMmHHBdZYtW0aFChUA6NKlC/fddx/79+9nypQp9O/fn+nTp2e7YFSvXv2sDyUlJYVdu3YREBCAv78/pmny0djfOLA9IXtv6gqVqBBG674xl12aDh/O+Je/ePHiBAYG8scff5Cens5NN93kGXGqWrUqpUqVYvPmzTRo0IBvv/0Wt9vNiRMnuO+++zh16hQxMTH079+fkmfcc2DNmjV89dVXfPzxx3z++ecYhuHZ5rnYbDYcDgfXXnst/v7+l/V+JOe4XC42bNhwzuNfJKfpeJO8pmNOLsUvn33Cxvc+wmUeA+yEFCtDl0mTsr0dHW8FQ+b3eDGWFqbOnTvTunXrC65TtmxZz+Pw8HDCw8MpX748FSpU4MYbb2T9+vXExMRka792u/2sg9tut2MYhucf4IpGei6XcXq/l7Nvt9vNiBEjqF27NhUrVgQgPj4eh8NBWFhYlnUjIiKIj4/HMAz27t2LaZpMnz6dQYMGERISwsSJE+ncuTOLFy/G19eXY8eO8fzzzzNmzBhCQkIu6TPKfB/n+rzFOvo+JC/peJO8pmNOzueTyWP5Z9XPmOYpwJ9S1arw8ItXNhOejrfCwdLClFmALofbnXGqXFpaWk5G8jAMg9bP1s61U/JM0yQpKYnAwMAspeNKTsmLi4tj27ZtzJ07N1uvc7vdOJ1OXnjhBZo0aQLA+PHjady4MT/99BM33HADL774Is2bN6du3bqXlU1ERETEKu/060v8rv/PhFe12a3cockd5BLli0kffv/9dzZs2ECdOnUIDQ1l9+7dvPrqq5QrVy7bo0vZYRgGDr/c+auBaZo4XHYcfvYcGckaMmQI33zzDe+99x4lSpTwLC9WrBhOp5OEhARCQ0M9y48cOUJkZCSA53+vvfZaz/Ph4eEULVqUf//9F8g4HW/lypW89dZbnvxut5sqVaowZMgQ7rvvvit+DyIiIiI57fUu3Tl1cj9g4mNEcPvT3alSv5HVsSQfyReFyd/fn88//5zJkyeTlJREZGQkN9xwAz179sS3kF+gZ5omQ4cO5YsvvmD27NlZTmEEqFatGg6Hg9WrV3PnnXcCsH37dvbv30+tWrUAqF27NpAxGURm2Tp+/DjHjh2jVKlSACxYsCDLTCJfffUVM2bMYP78+bp5sIiIiHidpMRE3urxVJaZ8NpNeIWI4iUv8kqRrPJFYapYsSLvvvuu1TG8UlxcHEuXLmXatGkEBQV5Jn0ICQnB39+fkJAQ2rZty8iRIwkLCyM4OJhhw4YRExPjKUzly5fn1ltv5ZVXXmHIkCEEBwczfvx4rrnmGs+seZkTb2TauHEjNpuN6OjoPH2/IiIiIhezd9tfLHxpjGcmPH+/EnR7c5pmwpPLki8Kk5xf5r2UOnbsmGX5iBEjaNOmDQADBw7EZrPRp08f0tLSaNKkCYMHD86y/ujRoxk+fDjdu3fHZrNRt25d3nzzzcu6z5WIiIiIVX76bDGr3/7AMxNeaLEydJ061epYko+pMOVzW7Zsueg6fn5+DB48+KySdKbg4GCGDx/O8OHDL2m/bdq08RQyEREREW/wyatj+Wf1GTPhVa3Mwy8NtTqW5HMqTCIiIiKS7739XF+O7P7/THjVm9/KbR00E55cORUmEREREcnXzpoJ76muVGnQxOpYUkCoMImIiIhIvnQqMZFZZ8yE57BF0fHV4RSNKnGRV4pcOhUmEREREcl3dm/9i48Hj8GpmfAkl6kwiYiIiEi+smb5J6x558PTM+HZCC1WVjPhSa5RYRIRERGRfOOjyePYsWrt6Znw/ChdrQoPvaiZ8CT3qDCJiIiISL7w1nPPcGz3DjJmwguhRvPbuFUz4UkuU2ESEREREa9mmiavd+1OUuK/gIndiODOpx+ncv0brI4mhYAKk4iIiIh4rZMJCbz9xNNZZsJ75NXhFNFMeJJHVJhERERExCvt3PIni18e65kJL8CvBF01E57kMZvVAeTKTJ8+nbZt2xITE0PDhg3p2bMn27dvz7JOamoqcXFx1K9fn5iYGGJjY4mPj/c8v2jRIipWrHjOf44cOeJZ76effqJ169ZUq1aN22+/nUWLFuXZ+xQREZHCZdWnn/Dx4JGny5KNsGJX0fPdN1WWJM+pMOVza9eupX379rz//vvMmjWL9PR0unTpQlJSkmed4cOH8/XXXzNx4kRmz57NoUOH6N27t+f5Zs2a8cMPP2T5p0mTJtSrV4+IiAgA9uzZQ/fu3alfvz6ffPIJjz76KC+88ALff/99nr9nERERKdjmjxzGT7PnnJ423I8yVWvyuKYNF4volLwLME2T9NTUXNu2MzUFp82GYRie5T5+fll+vpiZM2dm+XnkyJE0bNiQP//8k7p165KYmMjChQsZO3YsDRs2BDIKVLNmzVi/fj21atXC398ff39/zzaOHj3KTz/9xLBhwzzL5s+fT5kyZRgwYAAAFSpU4Ndff+Xtt9/mhht0waWIiIhcOdM0md7jCU4d/xdwYTNCqNn8Nm7RTHhiIRWm8zBNk/kv9WP/1k15ut9SFavwUNyobJWmMyUmJgIQFhYGwMaNG3E6nTRq1MizToUKFShVqpSnMP3Xxx9/jL+/P3fddZdn2fr16z2FK1OTJk0YPnz4ZeUUEREROdOxw4d576kBpJ2e3MHHVowWA2K5pmYdi5NJYafCdCGXWVqs4na7GT58OLVr1yY6OhqA+Ph4HA4HoaGhWdaNiIjg8OHD59zOhx9+SPPmzbOMOsXHx1OsWLEs6xUrVoyTJ0+SkpKSZV0RERGR7Phl5ef88MYcXGbGtdP+viXo+sYkfAMCLU4mosJ0XoZh8FDcqFw9JS8pOYnAgMArOiXvTHFxcWzbto25c+dedq5169bxzz//MHr06MvehoiIiMilen/sK+z95Q9M8xTgILxUOTpNeNXqWCIeKkwXYBgGjlwaOTFNE4fbjcPf/7IL0pmGDBnCN998w3vvvUeJEv+/L0GxYsVwOp0kJCRkGWU6cuQIkZGRZ23ngw8+oHLlylSrVi3L8mLFimWZWQ8yRp2Cg4M1uiQiIiLZZpombzzRk5PH9pN5vVLlWxpxV7dYq6OJZKFZ8vI50zQZMmQIX3zxBe+88w5ly5bN8ny1atVwOBysXr3as2z79u3s37//rOuXTp06xfLly7nvvvvO2k+tWrVYs2ZNlmU//vjjOa+BEhEREbmQ40ePMLXD45w8tgdw4WMrRvN+T6ksiVfSCFM+FxcXx9KlS5k2bRpBQUGe65JCQkLw9/cnJCSEtm3bMnLkSMLCwggODmbYsGHExMScVXaWLVuGy+WiZcuWZ+3noYceYs6cOYwePZq2bduyZs0ali9fzvTp0/PibYqIiEgB8es3X/HD6++Sfsb1Sp1fn0hAULDFyUTOTYUpn5s3bx4AHTt2zLJ8xIgRtGnTBoCBAwdis9no06cPaWlpNGnShMGDB5+1rYULF3L77befNUEEQNmyZZk+fTojRozg3XffpUSJEgwbNkxTiouIiMgl+2DcSPb8vO709Uo+FC1Rjs6vTrI6lsgFqTDlc1u2bLnoOn5+fgwePPicJelM8+fPv+Dz9evX5+OPP85OPBEREREA3ujZk8Qj+4F0DCOESjc1oFmPJ62OJXJRKkwiIiIikmuOHz3Ce7H9SM28v5JRjLue7U7F6xte5JUi3kGFSURERERyxbrvv+a7qW9nvV7ptQkEBIdYnEzk0qkwiYiIiEiO+3DCaHb/9BumeRLwoUjxsnSZNNnqWCLZpsIkIiIiIjnqjV69SIzfR8b1SsFE31CP5r2esTqWyGVRYfoP0zStjlBg6LMUEREpXBJOJPBur6dJdZ6+XskWwZ1Pd6VSvSYWJxO5fCpMpzkcDgCSkpIICAiwOE3BkJSUBPz/sxUREZGCa/2q7/h28lukm/EA+DmK02nKOIKKFLE2mMgVUmE6zW63U6RIEQ4dOgRAYGAghmHk2v5M0yQ1NRWbzZar+7GCaZokJSVx6NAhihQpgt1utzqSiIiI5KJFk8ax88ef/3+9UmQZukyZYnUskRyhwnSGEiVKAHhKU24yTROn04nD4ShwhSlTkSJFPJ+piIiIFEwzYnuTcGgvmdcrXduoDi37PGd1LJEco8J0BsMwKFmyJFFRUTidzlzdl8vlYvPmzVx77bUFcgTG4XAUyPclIiIiGRITEnin5xnXKxkR3PFkJyo3vMnaYCI5TIXpHOx2e67/su9yuQDw9/dXsRAREZF8ZeNPq/hq4gzS3WderzSWoCJFLU4mkvNUmERERETkkn08dSI7vv8Jt5kI2AkrVobHp061OpZIrlFhEhEREZFLMqNPLAkH9wJODCOIa+rXptXT/a2OJZKrVJhERERE5IKSTp3irR59SE37//2Vbun5CNVvuNXiZCK5T4VJRERERM5r069r+XzstP9fr+RTnE5Tdb2SFB4qTCIiIiJyTotfm8Q/3672XK8UGlGKrtNeszqWSJ5SYRIRERGRs7z51JOc+Hc3nuuV6taiVd/nrY4lkudUmERERETEI/nUKWaecb2S3Yjglh4dqHHT7RYnE7GGCpOIiIiIALB53a+sGD2FdPdhION6pUcmjSI0opjFyUSso8IkIiIiIix9YxrbVv6A20wA7IQULUW313W9kogKk4iIiEghN/PpJzm+fw+QhmEEcnXtmrTpN8jqWCJeQYVJREREpJBKSUpiZo8+pKQeAMBuhHNzt3bUvOUui5OJeA8VJhEREZFCaPXyJax9d1GW65U6ThxBWGSUxclEvIsKk4iIiEghkpqaxqzYPpw6cQhIA2wEh5Wi+xuvWx1NxCupMImIiIgUEivencnmZd+Rbh4BwGYUoUKjGrTs08/iZCLeS4VJREREpIA7fvQIc5/pT3JyPJAO+BAQEMmjE0cTVKSo1fFEvFq+K0xpaWncf//9bN68mY8//pjKlStbHUlERETEa304fiR71m7EbR4HwMeIoEbLm7i5XSdrg4nkE/muMI0ePZqoqCg2b95sdRQRERERr7Vnxz988uJwUp2HABPwJaRIcTpNfhWHr6/V8UTyjXxVmL799ltWrVrF5MmT+e6776yOIyIiIuKV3n3heY78vRO3mQiAwxbJDV3uI+a2eyxOJpL/5JvCFB8fz4svvsjUqVPx9/e/om25XK4cSnXlGbwhixQOOuYkL+l4k7ymYy7Dpl/W8PWrM0lzHQLAMAIpWrIkj4wdD+jzySk63gqGS/3+DNM0zVzOcsVM06Rr167Url2bnj17snfvXm699dZsX8PkcrlYv3597gUVERERsYBpmvz81pskHz2CaSYD4GuPomLbO4i4+jqL04l4t1q1amG328/7vKUjTGPHjmXGjBkXXGfZsmWsWrWKU6dO0b179xzZb/Xq1S/4oeQFl8vFhg0bvCKLFA465iQv6XiTvFaYj7k1yxbz69zFOE/fgNZmhFC8YnkefGmoxckKrsJ8vBUkmd/jxVhamDp37kzr1q0vuE7ZsmVZs2YN69evp3r16lmea9u2LS1atGDUqFHZ2q/dbveag9ubskjhoGNO8pKON8lrhemYS01N463esSQlHCbzBrT+vlE8OPJFipW+yup4hUJhOt4KM0sLU3h4OOHh4Rdd74UXXuCpp57y/Hzo0CG6dOnChAkTqFmzZi4mFBEREfE+y9+ewdYVP5DuzrgBrd0oSoXGNWgR+5zFyUQKnnwx6UOpUqWy/BwYGAhAuXLlKFGihBWRRERERPLc8aNHmPv0AJJTDgEuwIfAwEgemaAb0IrklnxRmEREREQKu/fHvsK+Xzb9/wa0tghqtbyZGx9+zNJcIgVdvixMZcqUYcuWLVbHEBEREcl1u//ewuKXR59xA1o/QopG0WmSbkArkhfyZWESERERKQzeGdifI9t3Y55xA9obuz5IzVvusjiZSOGhwiQiIiLiZTb+tOqsG9CGly7NY+MmWJxMpPBRYRIRERHxEs60NN7u25fEwwc8N6D18ynOPc/3pny1GIvTiRROKkwiIiIiXmDVkkX8OnfJGTegDaVUlQq6Aa2IxVSYRERERCyUkpTErD5Pk5SoG9CKeCMVJhERERGLfDrzNbZ9sQaXecYNaG+IoUWvZyxOJiKZVJhERERE8tixw4eZ2/d5UlIP47kBbVAkj746nsCQEKvjicgZVJhERERE8tCCUcPYv27z/29AaxSjdpvbuOGBDtYGE5FzUmESERERyQO7t21m8ctjSE3//w1oQ8Oj6DRpEj4Oh9XxROQ8VJhEREREctnbA57j6M49mOZJABy2KG7q9jA1br7d4mQicjEqTCIiIiK5ZNPPa/hywhtn3IA2iIgypXh0rG5AK5JfqDCJiIiI5IK3nn2G43v3YppJQMYNaJsPfJKrq9awOJmIZIcKk4iIiEgO2rruF1aMmeYZVbIZIZSqei0Pvqgb0IrkRypMIiIiIjnknQHPcWTnbkzzFJAxqtR22ABKlr/O4mQicrlUmERERESu0N8b17N8+GTSXAcBMIxgSlSqQLuXX7E4mYhcKRUmERERkSswe1B/Dv+zM8uoUuu4Zyl9bWWLk4lITlBhEhEREbkMuzZvZPHQCaSl/39UKeq68nQYOsLiZCKSk1SYRERERLJpzuCBHNyy3XNfJV+fKJoPfJLyVWtanExEcpoKk0Vee6QbJlDr3TesjiIiIiKXaP/fW1k0eBSpnlGlICLLX0XHEaMtTiYiuUWFyQInjsR7/kP7zx/riI653uJEIiIicjHzhrzIgb/+xm0mAuBrj6LZgN5UqFHb4mQikptUmCwQGBIKGIBJ/L7dKkwiIiJe7N+d/7Bw0PAzRpUCibiqHI+OGmtxMhHJCypMFnD4+pLx0TtJOHTY6jgiIiJyHgteiWP/hi24zQQgY1Tp9r7dqVSnvsXJRCSvqDBZxDB8ME0nKQknrI4iIiIi/3Fo707eHzCUVOchwMQwAihaugydxk2wOpqI5DEVJsvYAUhJPGlxDhERETnTh6NfYc9vf3pGlRy2KG576nGq1G9kcTIRsYIKk0UM7JhA2qlkq6OIiIgIcPTfvczr9zIpaQfJHFUKK1GKLhNftTqaiFhIhckiBjYA0lPSLE4iIiIiH40fxc61f+A2M06Vd9iiuLHXI9RscpO1wUTEcipMFvEUpjSnxUlEREQKr+OHDjCn7wukpB0C3BiGPyGRJXl80iQMw7A6noh4ARUmqxgGmOB2uqxOIiIiUigtmTyGv1f9jts8DoDDFkmTbg9T++Y7rA0mIl5FhckimSNMZrppcRIREZHCJeFIPO89PYDk1IxRJfAjJLIkXSdP1qiSiJxFhckimf89drvc1gYREREpRJa9NpEt3/6SZVSpQaf7qHfHPdYGExGvpcJkEc9fsEyNMImIiOS2U8eP8c6T/UhOOUjmqFJweHE6vzrx9A3lRUTOTYXJKpl9SQNMIiIiuWrFjKls+moNLvMYAD62YlzfoTWN77nX4mQikh+oMFnEsGU0JlMjTCIiIrki+WQib/d+hqTkQ4AL8CWoaHE6v/oqvn4aVRKRS6PCZJH/FyaLg4iIiBRAX856nY0rfsRlHgUyRpVqPdScG++9z+JkIpLfqDBZxOaTOQuPGpOIiEhOST6ZyOyn+5F06iAZo0oOgsKi6DR5Mn4aVRKRy3BZhWn//v3s37+f5ORkwsPDue666/DVBZPZYvOxA2DqIiYREZEc8c93X/D9mFf/P6pkRFCt9Z3c+mA7i5OJSH52yYVp7969zJs3j2XLlnHgwIEs1944HA6uv/56HnjgAe68805sNluuhC1IbL4ZH72pESYREZErkpacxFu9n+LUyUNAOuAgMCSKTlMm4e/vZ3U8EcnnLqkwDRs2jI8++ogmTZrw5JNPUqNGDaKiovD39+fEiRNs3bqVX3/9lUmTJjF16lSGDx9OjRo1cjt7vubwdwBgohEmERGRy7VixmQ2ffXzGdcqRVC5+a3c0f4Ri5OJSEFxSYUpICCAL7/8kqJFi571XEREBA0bNqRhw4b07t2b7777jgMHDqgwXYQjMOD0I5elOURERPKj4wf2Mee5waSkHSLjvkoO/AMieGTSeEJCQ62OJyIFyCUVpr59+17yBps2bXrZYQoTv+BAAEwVJhERkWxZMPRF9v/5D24zAciYAa9q6zsoWqEigUFBFqcTkYJGs+RZJKBIEQBMM93aICIiIvnEjj9+ZemoaaSlHwTAMAIIioii0/gJ2H3srF+/3tqAIlIgZbswtWrVCsMwzlpuGAa+vr5cddVVtG7dmgYNGuRIwIIqNKLY6UcqTCIiIhcz66k+HDvwL6aZDICvPYobYztTo2ETAFwunbEhIrkj29PZ3XDDDezZs4eAgADq169P/fr1CQwMZPfu3VSvXp3Dhw/TqVMnvvzyy9zIW2CERZU4/cjNiSPxlmYRERHxVms//YhJD3fi6L/bMc1kbEYIxa6tRuzctzxlSUQkN2V7hOnYsWN06tSJXr16ZVk+bdo09u/fz1tvvcWkSZOYNm0at912W44FLWiirrra8/jQnp2EeUacREREJC05ibdin+ZU4mEgDbDh54jk3iHPU/aaa62OJyKFSLZHmJYvX07z5s3PWn7PPfewfPlyz+MdO3ZceboCLCwiCsg4tfHovr3WhhEREfEin70xmWmdenAqcR+Qht0oylUNb6D3ezNVlkQkz2V7hMnPz49169Zx1VVXZVm+bt06/Pwybg5nmqbnsZybw9eXjI/fyYn4g1bHERERsdyxf/cyt9/LZ0wV7kNAYCQdJo4jNExThYuINbJdmDp06MDgwYPZuHEj1atXB2DDhg18+OGHdO/eHYAffviBypUr52zSAsgwfDBNJ0nHEqyOIiIiYqlzTRVevfUd3PJAO4uTiUhhl+3C1LNnT8qUKcOcOXNYvHgxAOXLl2fo0KG0aNECgIceeoiHH344Z5MWSBkff0riSYtziIiIWOOf339h2ehppKUfAsAw/AmOKE6nCRNOn40hImKty7oPU8uWLWnZsuV5n/f397/sQOdzyy23sG/fvizL+vbtS7du3XJ8X3nFwIYJpJ1KsjqKiIhInnvrqT4cP3AA08z4/0FfexRNez1GzcZNLU4mIvJ/l33j2o0bN/LPP/8AcN1111GlSpUcC3U+ffr04YEHHvD8HJTP7+ZtnJ5zIz0lzeIkIiIieWft8k9Y8+7HON2HAbAZIYRXKMejr4yyOJmIyNmyXZiOHDnC008/zdq1awkNzbgAMyEhgfr16zNhwgTCw8NzPGSmoKAgIiMjc237ec1TmNKcFicRERHJfeebKrzV0IGUKV/B6ngiIueU7cI0dOhQTp06xaeffkqFChn/cfv777/p378/w4YNY/z48TkeMtOMGTN47bXXKFmyJM2bN+exxx7Dxyf7g2TecDdwl8sFhgEmuJ0ur8gkBVvmMaZjTfKCjjf5rxUzp7F15c+4zKMA2I2ilG1Qg1axzwBXfqzomJO8pOOtYLjU788wTdPMzobr1KnDrFmzqFGjRpblf/zxB507d+aXX37JzuYu2axZs6hSpQphYWGsW7eO8ePH06ZNG55//vlL3obL5WL9+vW5ku9yrBo7Baf7MP4BJWgQ+4TVcURERHLcyaOH2fjuB6SkHSZzqnC/gGLEdHkE/8D8fWq9iBQMtWrVwm63n/f5bA/PuN1uHA7H2Rvy8cHtdmdrW2PHjmXGjBkXXGfZsmVUqFCBTp06eZZVqlQJh8PB4MGD6du3L77ZnEWnevXqF/xQ8oLL5eJHI+PGtbgzviiR3ORyudiwYYNXHP9S8Ol4E4D3X3mZA39lnSq8xr230vT+nJ8qXMec5CUdbwVD5vd4MdkuTA0aNOCVV15h3LhxFC9eHICDBw8yYsQIGjZsmK1tde7cmdatW19wnbJly55zec2aNUlPT2fv3r1cc8012dqv3W73roPbNL0rjxRoXnf8S4Gm461w+mf9Lywf/Rqprowbs+flVOE65iQv6XgrHLJdmF566SWeeOIJbr31VkqUKAHAgQMHuO666xgzZky2thUeHn7Zk0Rs2rQJm81GRETEZb3eGxg2A1xgZm9gTkRExGu99dSTHD/wb5apwm+OfYxqDTVVuIjkT9kuTCVLluSjjz7ixx9/ZPv27QBUqFCBRo0a5Xi4TOvWreP333+nQYMGBAUFsW7dOkaMGEHLli0JCwvLtf3mutNn5GXzMjIRERGv89Oyj/lp9ieeqcINI4TICuXoqKnCRSSfu6z7MBmGQePGjWncuHFO5zknX19fli1bxpQpU0hLS6NMmTI89thjWa5ryo8MW0ZjUl8SEZH8KjUpiVl9nuJUYjwZU4Ub+DmK02bo85TSVOEiUgBcUmF69913L3mDjzzyyGWHOZ+qVavy/vvv5/h2LWc/XZhQYxIRkfxn2YypbP3qpyxThV/doAatnnrO4mQiIjnnkgrT22+/fUkbMwwjVwpTQWXzyTwnTxcxiYhI/nH04AHmPfcCKamHyJwqPDAwkkcmjScoJMTqeCIiOeqSCtPKlStzO0fh5JMxq4pGmEREJL+YP3Qw//65LctU4TXb3M5N97e3OJmISO64rGuYJGfYfDM+fhONMImIiHfbuv4XVox5jbT0/08VHhJRnMfyYKpwERErXVJheuONN+jYsSMBAQEXXff333/n2LFj3HTTTVearcDz8cv8PxiXpTlERETOJyUpiXeeeoZTCfGYZgqQMVX4Lb0foWqjm6wNJyKSBy6pMP3999/cfPPN3HXXXdx8881Ur17dc/+k9PR0/v77b3799VeWLFnCoUOHGDVKU4heCrt/RmEyVZhERMQLLXjlZf7d8A8u8xgANiOUYteUoePw0RYnExHJO5dUmEaPHs3mzZt57733ePbZZzl58iR2ux2Hw0FKSsZfmypXrsz9999PmzZt8PPzy9XQBYVPUBAApplucRIREZH/W/vZYta88zFO96HTSxwEBBTj4dFDKRpVwtJsIiJ57ZKvYapUqRLDhg1jyJAhbNmyhX379pGamkrRokWpVKmSZ8RJLp1/SOZNd1WYRETEekcO/suC/i+SnHwEcAIZp9816NSGurc3tzaciIhFsj3pg81mo3LlylSuXDk38hQq/mGZhcnNiSPxhEUUszSPiIgUXm8/+wzH9v6L20wEMu6pVKrGdTww8CWLk4mIWEuz5FkouFiU5/GBXf+oMImISJ774p3p/PXZatLd8QAYRgDBYRE8OmE8foGBFqcTEbGeCpOFAkLCAAMwOf7vv1bHERGRQmTHxt/5dOQkUp2Hybj5rA0/RyR39+tFhRq1rY4nIuI1VJgs5OPrS8ZX4ORE/EGr44iISCHgTEtj1pNPcfLYYUwzGQAfoxjRt9Xl7sd7WZxORMT7qDBZzDB8ME0np46esDqKiIgUcAvHDGfPr5txmUcBMIxgipYqSYeRo3TzWRGR88h2YTp69Oh5Z8TbsmULFStWvOJQhUvGV5B68pTFOUREpKD67asVrJq5gDRX5jThPgT4F+O+V14gqszVVkYTEfF6tuy+oEWLFnzzzTdnLZ85cyb3339/TmQqVIzTX0HaqSSLk4iISEFz4kg8r3XuxtdvTPeUJYctikYdOtLznTdVlkRELkG2R5gee+wxYmNjadOmDc8//zwnTpygX79+bN26lXHjxuVGxgItszClp6RZnERERAqS2c/3I37HXtxmAgA2owglKl/Nw4OHWZxMRCR/yXZh6tq1K40bN6Zfv360bNmSEydOUKNGDRYvXkxkZGRuZCzQPIUpzWlxEhERKQi+nvcuGxZ/jdN9+PQSf4JCI+g4fixBISGWZhMRyY8ua9KHcuXKcd111/H5558D0KxZM5Wly2UYYILpdFmdRERE8rF/t29j0eBRpKQdBlyAgZ9PFLc82YUq9RpZHU9EJN/KdmH69ddfee655yhSpAiLFy/mt99+Y+jQoXz77bfExcURFhaWGzkLrMwRJne62+IkIiKSHznT0njnmWdIiD+MaWZMIORjRHDNDbVo0etpi9OJiOR/2S5Mjz76KI899hhPPvkkDoeDChUqUL9+fZ577jlatGjBd999lxs5CyzDyPhft8u0NoiIiOQ7n0way44fN+AyjwBgGEGERkXx6NhxmiZcRCSHZLswvfXWW9SrVy/LsnLlyjFv3jxee+21HAtWWBiZjclUYRIRkUvz14/fsHLKbFJdhwATsOPvF0nruOcpVb6C1fFERAqUbBem/5alTDabjV69dIfwbMvsSzojT0RELuJUYiKzn3qWUyfjgVQAHLZIqre5jZvvb29tOBGRAuqSC9PHH398Seu1atXqMqMUToYtozGZGmESEZELmDt4IAe37MZtHgfAZoQReV1ZOgwdaW0wEZEC7pIL04ABAwgMDMTHx+e8v9wbhqHClE3/L0wWBxEREa+06pMF/Dp/BU73odNL/AgMjqD92JGEFg23NJuISGFwyYWpQoUKxMfH07JlS9q2bUulSpVyM1ehYfM5XZhQYxIRkf87tHcnHwwcRkpqPJAOgK89iht6dKBW01usDSciUohccmH69NNP+f3331m4cCEdOnSgXLly3HfffbRs2ZLg4ODczFig2RynvwJdxCQiIkC608m7/Z7l+L8HMc2TANiNcMrWr0rbp/tbnE5EpPDJ1qQPNWvWpGbNmgwcOJDPPvuMhQsXMnr0aG699VZGjBiBr6YwzTabww5ohElEROCTV8ewc81G0t2Z04QHEhwRyWPjJ+Drp/+PFRGxQrZnyQPw9/enVatWlC5dmkmTJrFs2TJeeuklFabL4PB3AGCiESYRkcLqk1dHs2vNJpzuw6eX2PH3LUbzF57hqopVLc0mIlLYZbswHTx4kI8++ohFixaRlJREy5YtefnllwkLC8uNfAWeIyjw9COXpTlERCTvfTxxNLt/OrMogcMWRaXmN3BH+04WJhMRkUyXXJiWLVvGokWL+Pnnn2nSpAn9+/fnpptuwm6352a+As8vKAAAU4VJRKTQOF9RuvrGGFr2iLUwmYiI/NclF6ZnnnmGUqVK8dhjjxEREcG+ffuYM2fOWes98sgjORqwoAsoUgQA00y3NoiIiOS6jyaOZs85ilL5m2Jo0V1FSUTEG11yYSpVqhQAS5YsOe86hmGoMGVTaESx049UmERECqqPJoxmz9qzi9I1N8XQXEVJRMSrXXJhWrlyZW7mKLTCokqcfuTmxJF4wjwFSkRE8jsVJRGR/O+yZsmTnBN11dWexwd2/aPCJCJSAJyvKFW4qTb3dO9tYTIREcmuyypMq1evZvXq1Rw5cgS3O+t02CNGjMiRYIVFWEQUYAAmx//91+o4IiJyBT6aMIo9azerKImIFCDZLkxTpkxh6tSpVKtWjcjISAzDyI1chYbD15eMr8HJifiDVscREZHLcL6idO3NtWnWTUVJRCQ/y3Zhmj9/PiNGjKBVq1a5EKdwMgwfTNPJqaMnrI4iIiLZoKIkIlLwZbswOZ1OateunRtZCrGMryH15EmLc4iIyKVQURIRKTyyXZjuu+8+lixZQq9evXIjT6FkYMME0k4lWx1FREQuQEVJRKTwyXZhSk1N5f3332f16tVUrFgRH5+sm3j++edzLFxhYWADID0lzeIkIiJyLipKIiKFV7YL05YtW6hUqRIAW7duzfKcJoC4PJmFyZXqtDiJiIicadGEUexVURIRKdSyXZhmz56dGzkKN8MGJrjTXVYnERERYOG4kez7ZYuKkoiI6Ma13sAgY2TOne6+yJoiIpKbVJREROS/VJi8QOaZjG6XaW0QEZFCSkVJRETOR4XJC3iu/TJVmERE8tL5i1IdmnXTbLAiIqLC5B1OFyZTZ+SJiOQJFSUREblUKkxewMiYJA9TI0wiIrlq7RefsuathTjdhzzLHLYorru5DnerKImIyDmoMHkBm/30CJP6kohIrkhLTeOt3n04lXAYSAVUlERE5NKoMHkBI7MwocYkIpLTls98jS1frMFlHgHAZhThqrpVaNN3oMXJREQkP8hXhembb75h6tSpbNmyBT8/P+rWrcu0adOsjnXFbI7TX4MuYhIRyTFHDx5g3nMvkJJ6CHADPgQERPLIxNEEFylqdTwREckn8k1hWrFiBS+++CJPP/00DRo0wOVysXXrVqtj5Qi7b8bXoBEmEZGcMS/uBQ5s2o7bTADAx1aMmq1u5aYHO1qcTERE8pt8UZjS09N55ZVXeO6557j//vs9y6+99loLU+UcH39fAEw0wiQiciW2/PYTn499gzTXQQAMw5+QYsV5bPwEHL6+FqcTEZH8KF8Upr/++ouDBw9is9lo1aoV8fHxVKpUiX79+hEdHZ3t7blcrlxIeXkZXC4XjkD/zKVekU0KpjOPOZHcltfHW7rTyXvPPcuJwwcxzWQAfO1R3NTrUao0aJKnWcQa+m+c5CUdbwXDpX5/hpkP5rL+9NNPeeaZZyhVqhQDBgygdOnSzJo1ix9++IEVK1ZQpEiRS9qOy+Vi/fr1uZr1cmxYspAjm/7AMAK58bn+VscREclXdvz0Hfu+/510dzwANiOU4LJR1H5Ip9+JiMjF1apVC7vdft7nLR1hGjt2LDNmzLjgOsuWLcPtzjhVrUePHtx5550AjBgxgqZNm/LZZ5/x0EMPZWu/1atXv+CHkhdcLhcbNmygevXqHFy3hiOb/sA006lVq5aluaTgOvOYs/r4l4IvL463pMRE3nv6OZKSDgPpgA0/3yjaDn2eqLJX58o+xXvpv3GSl3S8FQyZ3+PFWFqYOnfuTOvWrS+4TtmyZTl8OONO7BUqVPAs9/X1pWzZsvz777/Z3q/dbveag9tutxMWGXX6p3SvySUFlzcd/1Lw5dbx9snE0exYswGXeSxjP0Y419xYh5ZPPJnj+5L8Rf+Nk7yk461wsLQwhYeHEx4eftH1qlWrhq+vLzt27OD6668HwOl0sm/fPkqVKpXbMXNd0ZKlTz9yc+JIPGERxSzNIyLirfb/vZlFL48h1XkIMAFfAkMi6TRpAv6BgVbHExGRAihfTPoQHBzMQw89xOTJkylZsiSlSpVi5syZANx1110Wp7tyUWXKeh4f2PWPCpOIyDnMHvAsh3fuxTRPAuCwRVGnw700vudei5OJiEhBli8KE0C/fv3w8fGhX79+pKSkULNmTd555x3CwsKsjnbFwooVBwzA5Ni+fVDb6kQiIt5jw7df8M3r80hzHwLAMIIIK1WSzuMmYBiGxelERKSgyzeFyeFw0L9/f/r3L3izyGXcG8QBpJFw9LDVcUREvEK608ms3rEkHD8MpAIGfj5R3PX8k1xbrYbV8UREpJDIN4WpoDMMO6YJp46esDqKiIjlvn7nDf5Yvop08wgANqMIJWtV4qEBL1icTEREChsVJq+R8VWkJCZanENExDqJ8QeZ3XcQySmHARfgg39AMR4eO4rwYhFWxxMRkUJIhclLGNgwAWdSitVRREQs8eErg9mzYRtuMwEAH6MY193TlGYdO1ucTERECjMVJi9hYAMgPSXN4iQiInlr5+8/s2T066SlHwTAMPwJLBrJYxMm4u/vZ3E6EREp7FSYvERmYXKlOi1OIiKSN9KdTmY/25djB//FNJMB8LVH0ajHo9RpeqPF6URERDKoMHkLwwYmuNNdVicREcl1Py/9kNVzluJ0xwNgM0Iocs1VPPbKCE0VLiIiXkWFyUsYZPyC4E53W5xERCT3pJw6ydt9nuHUyUNAOmDDzzeS5nEDufqaClbHExEROYsKk5fI/IOq22VaG0REJJcsmzKWrT/8jss8BoDdCKd041rcH/uMxclERETOT4XJS3hOQTFVmESkYInf9Q8LBg0nxXkIMAFf/IOL0WHCOMJCQ6yOJyIickEqTN7idGEydUaeiBQgC14cwIHtezDNkwA4bJFUfbAFt7ZqY3EyERGRS6PC5CWMjEnyMDXCJCIFwJZVK1n12jyc7kMAGEYQgcVL8Pj4CfjYbRanExERuXQqTF7CZj89wqS+JCL52J4/f2PJqGkkpx4BnICBrz2Kps/GUrN2LYvTiYiIZJ8Kk5cwMgsTakwikv8c3LGFRXFjSUo+CqQCYDeKEFalAo+9+LKmChcRkXxLhclL2BynvwpdxCQi+UjCwX3MGxTHqZPHPDeftRmh+IcXoeJDD3Nj40YqSyIikq+pMHkJu2/GV6ERJhHJD5JPHGdO/wEkHD+GaZ4CwDCC8Q8tQutXhhMVHsb69eutDSkiIpIDVJi8hI+/LwAmGmESEe/lTE5mdr9nOXH4KG4zEQDDCMQvsAj3DH6Rq68qC4DL5bIypoiISI5RYfISvoH+px/plwwR8T7pTidzBzzHkX2HcZsnTi/1xz+gCLc//xzRFStamk9ERCS3qDB5Cb/gYABMFSYR8SLpTicfvPwCB//Zj8s8dnqpL35+4dzw5BPUrFPH0nwiIiK5TYXJSwQWCQPANNMtTiIikmHhK4PZs2EnLvPI6SU++DkiqPt4B+rfdLOl2URERPKKCpOXCClW7PQjFSYRsdaSV8ewfc2fpLvjTy+x4esTSY12rbjxnhaWZhMREclrKkxeomjJ0qcfuTlxJJ6wiGIXXF9EJKd9MXMqm778Baf78OklBr72SCrdexu3P9jO0mwiIiJWUWHyElFlynoeH9j1jwqTiOSZ7xa8w+8ff0ua+zCcvrWBwxbJVbfU596uPawNJyIiYjEVJi8RVqw4YAAmx/btg9pWJxKRgu6XZR+zes4S0tIPw+lbGjhskZSsX5X7n3rW2nAiIiJeQoXJSzh8fQEHkEbC0cMXW11E5LJt/P5Lvnl9Hqnp8WTeysDHKEZk9fI8PPAlDMOwNqCIiIgXUWHyIoZhxzTh1NETF19ZRCSbtv/+K8vHvkZK2hHACYDdCCf8ujJ0HPKKipKIiMg5qDB5lYyvIyUx0eIcIlKQ7Pt7E58MG0dy8jEgFQC7UZTQspF0GDYSXz9fawOKiIh4MRUmL2JgwwScSSlWRxGRAuDI/r28/8IQkpOOYZrJANiMUIKjIug4eiz+/n4WJxQREfF+KkxexMAGQHpKmsVJRCQ/O3EknvkDBnEq8TimeQoAwwgmqEhR2o0eRUhoqMUJRURE8g8VJi+SWZhcqU6Lk4hIfpSalMS7zz3LySPHcJsZp/YaRiABwUV5aMQwikZGWpxQREQk/1Fh8iaGDUxwp7usTiIi+YgzLY3Z/Z7jxIF43GbGpDGG4U9AQFFaxw2kRLnyFicUERHJv1SYvIhBxgxV7nS3xUlEJD9wpqUx98XnObbrEC7z2Omlvvj7hdPs+ScpX7m6pflEREQKAhUmL5I5o6/bZVobRES83vxhL3Ng4w5c5pHTS3zw943g5tguVKnXyNJsIiIiBYkKkxfx3APFVGESkXNbPG0iO77/nXR35g2u7fj5FKNh5weoc+udlmYTEREpiFSYvMnpwmTqjDwR+Y+V82ez8ZOvcboPnV5i4GuPJOaBO2nS6kFLs4mIiBRkKkxexMiYJA9TI0wictovX33Gmrc+IDX9MJDx1xSHLZLoW6/nrsd7WRtORESkEFBh8iI2++kRJvUlkUJv2/rfWDFuGqlp8UA6AD5GBKVrR3Nfv0HWhhMRESlEVJi8iJFZmFBjEimsDuzewUeDh5OUdBRIBcBuFCXimpJ0HD7a2nAiIiKFkAqTF7E5Tn8duohJpNA5cfQo8wY8T1LCcUzzFAA2I5TQqAgeGTsOh6+vxQlFREQKJxUmL2L3zfg6NMIkUnikpabx7nN9STx0BLeZAIBhBBIUFk77USMILlLU4oQiIiKFmwqTF/EJyPgLsolGmEQKOtM0eXfQAI5t33/GTWf9CAwM576hLxBZ5ipL84mIiEgGFSYv4hvgf/qRy9IcIpK7FowaxoF120jPctPZYtz1bA8q1Lze0mwiIiKSlQqTF/ELDgbAPD0jlogULEvemMqOr3/B6bnprA0/n0iadLmPWrfcbWk2EREROTcVJi8SFF4EANPUCJNIQfLtRwv444MVpLkOw+lrFH1tUdRsdTNNH+xobTgRERG5IBUmLxIcHnH6kUaYRAqC9T98yw+vv0uqM57MU219bJFc26Q69/R6xtpwIiIicklUmLxI0ZKlTz9yc+zQAYpGlbA0j4hcnu2bNrB8xKukpB4F0gCwG+GUqlaeB16IszaciIiIZIsKkxcpflV5z+NDe3epMInkM4f+3c+Hg14mJekYppkMgM0oQkS54rR7ZSQ+DofFCUVERCS7VJi8SGjRCMAATI7t2we1rU4kIpfi1MlTvPfcc5w6dhTTPAmAYQQTGhHBI2PH4BsQaHFCERERuVwqTF7E4esLOIA0TsQfvtjqImKx1NQ03nu+Hwn7D+M2TwBgGAEEBofTbsQQQiOLW5xQRERErlS+KEw//fQTjzzyyDmf++CDD6hRo0YeJ8o9hmHHNCHp+Amro4jIeZimyezBL3B06x5c5tHTS30J9I/g3hf7UuraSpbmExERkZyTLwpTTEwMP/zwQ5Zlr776KqtXr6Z69eoWpcotGV9JSmKixTlE5Fw+nDCGfWv/JN0df3qJHT9HMW5/shMV6zaxNJuIiIjkvHxRmHx9fYmMjPT87HQ6+eqrr+jQoQOGYViYLOcZ2DABZ1Ky1VFE5AzL3p3J38tX4XQfOr3EwNcnigbtm1O3WWtLs4mIiEjuyReF6b9WrlzJ8ePHadu27WW93uWy/sawmRn+m8XADoAzOc0rckrBcb5jTi5s1fIl/D53yembzroBcNgiqXJXA27u8Digz/RcdLxJXtMxJ3lJx1vBcKnfn2GappnLWXJc165dAZgxY0a2XudyuVi/fn0uJMo5P4yZRLp5hMCwUtTr3t3qOCKF1ta1q4n/fh1priNk3kzaxyhG0colqdr8PmvDiYiISI6pVasWdrv9vM9bOsI0duzYi5aeZcuWUaFCBc/PBw4c4IcffmDixImXvd/q1atf8EPJCy6Xiw0bNpyV5QfDBiYYpkGtWrWsCygFzvmOOclqxdx3+Wf5D1lGlOxGUYpHl+GBwcOsDZeP6HiTvKZjTvKSjreCIfN7vBhLC1Pnzp1p3frC5/6XLVs2y88LFy6kSJEi3HLLLZe9X7vd7jUH93+zGGRck2Wmu70moxQs3nT8e5OP35jGnm9+Ic0Vz/+LUjiR15TgwbhXdNPZy6TjTfKajjnJSzreCgdLC1N4eDjh4eGXvL5pmixatIhWrVrhKKC/vGTOYeF25bszJUXyHdM0+eDVcRz46S+c7sNAxr93PrYISlYuywMvaURJRESksMtXkz6sWbOGvXv3ct99Bff6Ac+sf/nv0jKRfMM0TeaOHMaRP7afLkoZfGzFKFfrGlr3f8nCdCIiIuJN8lVh+vDDD4mJiclyTVNB4+lLbmtziBRELrfJ7Jdf4MTWfaSb8Z7lDlskFRpV5Z7YZy1MJyIiIt4oXxWmcePGWR0h99lOX8OkESaRHJOcksrcl1/g5M5DpJtHTi818LVFUvm267mtS09L84mIiIj3yleFqTCw2TMLk8VBRAqAk0kpzBs0gFP/HsVlHj291IavPZKYljfQ5KHHrIwnIiIi+YAKk5cxfGwAmKgxiVyu4ycSWTDoeZLij+M2j59easfPpxj1H76burqPkoiIiFwiFSYvY/M5PTWlLmISybYDBw/z0UsvkXLiBG4z4fRSH/wdEdzQpS01bm5maT4RERHJf1SYvIzdN+Mr0QiTyKXbvXsPS4cOIzUxAbeZeHqpL/6+4dze+1Gi699gaT4RERHJv1SYvIxPgC8AJhphErmYbVu38fnI0aQmJWCap04v9SPQP5xmz/Xgqmp1LM0nIiIi+Z8Kk5fxDfA//chlaQ4Rb/bHuvV8P3EKqaknMM1kAAwjgMDAorR6oS8lrqlocUIREREpKFSYvIxfcDAAJukWJxHxPj//+CM/vf4WqanHgFQADCOIoJAi3D9kEOEly1kbUERERAocFSYvExReBADT1AiTSKZvP/+MDe9+QKrzGJAGgGGEEFqkCA8NiyO4WJS1AUVERKTAUmHyMsHhEacfaYRJZMWiRWxd9ClpziNk/jthM0IpElmUh4a9QkBYEUvziYiISMGnwuRlipYsffqRm2OHDlA0qoSleUTymmmaLJkzm13LviHNdYTM6/lsRhEiSkXw8CsjcQQEWBtSRERECg0VJi9T/KrynseH9u5SYZJCwzRNFs54nf3f/IzTFQ+nZ4q0G0WJvLo4Dw4dgY/DYW1IERERKXRUmLxMaNEIwABMju3bB7WtTiSSuw4eO8nnb73GsV824XQfhtP3IPOxRVCiYinaDhqioiQiIiKWUWHyMg5fX8ABpHEi/rDVcURyVFq6m7Wr17JpyYekHjiOy+nCZZ70TA0O4GMrRrkaV9P6+ZetCyoiIiJymgqTFzIMO6YJScePWx1F5LKZpsmOPQf4ce47JGzbjis5nXR3Km7zxDnWtuGwRXBtg0o0e7J/nmcVEREROR8VJq+U8bWkJJ60OIfIpUtOc7Fy4QL2/rCKtBMpuNKduMwEzjXjo2EE4WME4RfgQ8mKZWjS/hHCy1yd55lFRERELkaFyQsZ2DABZ1LyRdcVsYJpmqz7dR3rF84nef9RXGku0s1TmGbSOdb2xccIweFwEFoihHotmxF9w+15nllERETkcqgweSEDOwDpKU6Lk4hkOBh/jG9mv8nRP/8mPcl5+tS6BDInaPg/A5sRho/dj4AQX66tV53GD3fSNOAiIiKSb6kweSEDAwBXqgqT5L10l5tvFy/in6+/Je1oEq70dNLNBODs4zHj1LpAHP4+RFUoyQ0dOhB1dXTehxYRERHJJSpM3siwgQnudJfVSaQQ2LrpL1bPfY+Tew7jSk0n3UzCNE+dY00HPrZQfHwcBEcFU+ee26l2yz15nldEREQkL6kweaHMESZ3utviJFLQJCcns3jaZA5u2ITz5Jmz1p3r1LpQfGx++AX7cnXtyjTt2AX/oGArYouIiIhYRoXJCxkZfQm367+/xIpkj2mafPbuTHZ8/RPOlDTSzUQg7az1DCMQHyMIh58P4VdHcmP7DpS4rkreBxYRERHxMipMXsjIbEymCpNkX0pKKh9PHEP8nztwOlPOcd8jH+xGxql1gRFB1LzjRurc09aSrCIiIiLeToXJC3n6ks7Ik0t06N/9fDphHCf3HsfpTvzP9N4GPrZwfAP8CCkfxb29niIkvJhlWUVERETyExUmb2TLaEymRpjkAjb9upbvZ75NyrEUnO7jZD3VzgeHrSgBRQNo2qkdFes2weVysX79egLDilqUWERERCT/UWHyQjZ7ZmGyOIh4nW8/WsBfS78i7VQa6eZR4P/DkIYRgMMWSmjpUJo/9RQRpa+yLqiIiIhIAaHC5IUMHxsA5lkzl0lh40xLY+nrk9n/yyacaam4zGNZnrcZoTh8AihepSz3Pt0P34BAi5KKiIiIFEwqTF7I5mPPeKCLmAqlE0ePsnj8GE7sOESa6xSmeTLL83YjHF9/P667sQ63d+phUUoRERGRwkGFyQvZfTO+Fo0wFR67tvzJF9Omk3ToJE73CSD1jGft+NiK4h/iR4OHWlPzlrusiikiIiJS6KgweSGfAF8ATFwWJ5Hc9MtXn/HLgo9JTUwh3X0MsnzffjhsYQRFBXN7r+6Ui65qVUwRERGRQk2FyQv5BvgDKkwFjWmarJj1Btu/+4W0lFRc5tEszxtGML72IIpeE0Wrvv0IKqLZ7ERERESspsLkha5r0oT9f/2BaZ5kwSuDeXBQnNWR5DKlJCXxycQxxP+1m7T0ZNxmQpbnbUYR/Hz9KVO3Ms169MHH4bAoqYiIiIiciwqTF7r+1rtYPfN90lyHOLhxt9VxJJsO79vDpxMmkLj/BE53AqaZfMazNnyMovgF+VGj5a00uvdBy3KKiIiIyMWpMHmp6JvrsPHL5Tjdh/n49Um06tHH6khyEUtfm8T279bjdB8DnGc848i4iWx4AE27PELF2vWtiigiIiIi2aTC5KXu7NqLzSt/Jt0dz57v1oNmj/Zq748Ywp71v5M5u51hBOKwBxNaJpwWTz1FeMky1gYUERERkcuiwuTFytS4hp3r40lzHWHZB3Npdn87qyPJObz34gAObt0COLEb4ZSpXZGWsU/rJrIiIiIiBYDN6gByfq36DcJuhAMutn/yJaap+zJ5m1nPPsPBrZsAJz5GBK3j+nFfv0EqSyIiIiIFhAqTF7Pb7USWiwIg1Xmcr776yuJEcqY3Y3tzdM/fgAsfWyQPjYnjqorVrI4lIiIiIjlIhcnLPTBkGDYjBEhj87tzNcrkJaZ378GJQ7sANw5bFI9NGUPxsldbHUtEREREcpgKk5dz+PsTFhEBQFraSb7+ab21gYTXOnfj5PG9gImvPYoub7xKWEQxq2OJiIiISC5QYcoH7nt5MIYRgGkm8ecbkzXKZBFnWhpTH3mcpFP7AfDzKU6Pt18nKCTE4mQiIiIikltUmPKB0MhIggIzRpnSk1L55o9/LE5U+DjT0pje+QlSUg8A4O9Xgu6zXsPh62txMhERERHJTSpM+USLfk8CDtzmCX5/baRGmfJQalIS0x97glTnQQACAkvS6903VZZERERECgEVpnyiVKXKBPidvk7meBrf/LXP2kCFROKxo0zv0ptUV0ZZCg4tTc9ZMyxOJSIiIiJ5RYUpH7mxSzvAhss8ym/TX9EoUy6L37+HWT374nQfAmyEFruK7jOmWx1LRERERPKQClM+UvXGm/HziQTAcTiFlZsOWJyo4Nq3bRNznnkRp/swYCe89DV0nTrV6lgiIiIiksdUmPKZOi1uBcDpPsyat8dolCkX/L3+Fz54cQTpZjzgQ1SFinQaP9HqWCIiIiJiARWmfKbhQ+1w2DJGmUL3HuOLPzXKlJM2fP81S0ZOxGUeBXwpXb0mHYePtjqWiIiIiFhEhSkfuq5BDQDSXEf5ZsFruN0aZcoJPy37mC+nzsBtHscw/LmmQX0eeiHO6lgiIiIiYqF8U5h27NjBE088Qf369alduzYPP/wwa9assTqWJe7o3Qe7URRwUWr7Hj7/S6NMV+qb+e+y6t35uM0EDCOQSrfeTOun+1sdS0REREQslm8KU48ePXC5XLzzzjssWrSISpUq0aNHDw4fPmx1tDxnt9spfW15AFLTT7B80VyNMl2Bz96cym8fL8U0T2IYwdRq1ZxmXXtZHUtEREREvEC+KExHjx5l586ddOvWjUqVKnH11VfTt29fkpOT2bZtm9XxLHHvi4OwGSFAGtdt+4PPdC3TZflowij++vJrTDMJmxFKw44PcstDj1gdS0RERES8hI/VAS5F0aJFKV++PB9//DFVqlTB19eXBQsWEBERQdWqVbO9PZfLlQspLy/D5Wax+/gQHlWS+IOJpDmT+WDJUm6v1AmbzcjJmAXaByOGsm/DH0AadqMoTXs8Qs0bbvGK4yM3XOkxJ5IdOt4kr+mYk7yk461guNTvzzDzybzUBw4coGfPnvz111/YbDbCw8N54403qFKlyiVvw+VysX79+twLmcdSExNZ8/pUTDMZ34CimK2607hsgNWx8oXf5rxDwr7dQDp2I5zo++6mePloq2OJiIiISB6rVasWdrv9vM9bOsI0duxYZsyYccF1li1bxjXXXENcXBwRERHMmTMHf39/PvjgA3r06MGHH35IVFRUtvZbvXr1C34oecHlcrFhw4YrzvLnnA9ISNhFeoqbnzbvocc992PXKNMFvftcXxL27QTc+BjFuDeuH2WvrWh1rFyXU8ecyKXQ8SZ5Tcec5CUdbwVD5vd4MZYWps6dO9O6desLrlO2bFnWrFnDN998w88//0xwcDAAVatW5ccff+Tjjz+mW7du2dqv3W73moP7SrM07/8Mcwc9i9s8QYO/P2X5n025t1bpHExYsMzo1YuE+N2AicMWycNjhxBZuqzVsfKUNx3/UvDpeJO8pmNO8pKOt8LB0sIUHh5OeHj4RddLTk4GwDCyjpwYhoHb7c6VbPlFyWsrEOhfnKSUvXDSxltf/kLzGqU0ynQO07t252TCPgActigenTqWsEs4/kRERESk8MoXs+TVqlWL0NBQBgwYwObNm9mxYwejRo1i37593HTTTVbHs9wt3R4BbLjMo9zwzwcs/n2f1ZG8zmudunrKkq+9ON1mTlFZEhEREZGLyheFKTw8nDfffJOkpCQeffRR2rZty2+//cbUqVOpVKmS1fEsV7FxI/x8Mq7j8j3uwxtf/EG6q3CPvGVKdzqZ2vFxkpL+BcDPUZzus17DPzDQ4mQiIiIikh/ki2nFIWOihpkzZ1odw2td3/puVn0wC6c7nsZ73+fj9TW4r04Zq2NZypmWxvROT5CafhAAf78S9Hz7DQxbvvg7gYiIiIh4Af3mWEA0uK8tDlskAGHxBq9/9VehHmVKPpnI64/18JSlgMCS9Hr3TZUlEREREckW/fZYgEQ3rgtAmusodQ8sYtG6wnktU8KReGZ0fZI01yHAICisND1nXXj6ehERERGRc1FhKkDu6NkDuxEOuChzMIWpX23GWchGmeL37WJW72dxug8BNkKjrqLHG9OtjiUiIiIi+ZQKUwFis9koUzEagJT0BGrEL2fhr3stTpV3dm/9kzl9XyLdHQ/YKVqmAl0nT7E6loiIiIjkYypMBUzLgc9hM0KANCofOMzkr7aRll7wR5m2/LKaRS+NJN08AjiIvLYyncdNsDqWiIiIiORzKkwFjK+fH8VKXAVAijOVCse/5YNf91icKnf98fUXLBs7FZd5DPCjdM0YHnllpNWxRERERKQAUGEqgFq91B/DCMA0k2h46G+mrvyb1HSX1bFyxeolC/lq+izc5nEMI4DyjRvx0MCXrI4lIiIiIgWEClMBFBJelNDQUgCkJBuUOPYb7/9S8K5l+nruW6ye8z5uMwHDCKLibbfQpk9fq2OJiIiISAGiwlRAtejXB3DgNk9w29Gfmbryb1KcBWeUafnrr7Ju8XJM8xQ2I4SY1i255/EnrI4lIiIiIgWMClMBVfzaCgQFlADAeTKAkMStLPi5YFzL9PG4Efz19XeYZjI2I4wGj7bj5gfbWx1LRERERAogFaYC7JZujwI20s0jtDr+FdO+yf+jTHNefJ5/1q4FUrEbRbm5d3ca3t3C6lgiIiIiUkCpMBVg0Y0a4O8oDoDreAiOxD3M/Wm3xakuz5at25jSoQsHtm4AnNiNCJoNfIZaTZpaHU1ERERECjAVpgKuXpvmADjdh3kg6VNe+/affDXKdDwpjdcGv8Cyl+JIdR4EwNceRdvhLxBdI8bidCIiIiJS0KkwFXB129yLwx4FgHE4BDPxEO+t2WVxqotLcbqYsWIts3t0I2nzBtzmccCPyNLRxM59i7LXXGd1RBEREREpBHysDiC5r3KTRvzx7cekuY7ysPMTXv82knb1yxHo631fv9ttsvj3/fw071VK7D5IunkEAB9bMe7s/RiVGt9kbUARERERKVQ0wlQI3NqjM3YjHHDhf8Cf1JPHvXKU6ce/43lo8nL2TO5PsV3/nC5LPoRHXEOv2W+qLImIiIhInvO+IQbJcTabjXKVq7Ljr+9JSU/kQfdSpn9bhPb1ryLIz/pDYMuBREYs30TAnx9ww7540tzHAbAbRWn0wL3Ua3OftQFFREREpNDSCFMh0eL5p7EZIUAaEQdcnDx1kndXWzvKdOBECv0+/J2HX/2UumvGct3e3aS5DwMGwYHl6PbGVJUlEREREbGU9cMLkiccvr5ElSrPgX1/kJzmpI3xOW98F0THhlcRnMejTIkpTqb/r707j4u63vs+/poBRkBEQRRc2MQETU7p0UtNSo9pV2Zq5nLnxpWaXi4PzXOso+beaeFGTU0Nd9O8tdQys5vj8fY2t7IizTJzYxFzYREEZJGBmbn+8DjX4TIyFRhh3s/Hg0fNb/384MM47/n+5suBZNYcTqar+QtGXszgRmkhAAaDF5Fd/0SPsf9ZpTWJiIiIiPwajTA5kb6z/orB4I7NVkBoWjZ5hTfY8NX5Kjt/icXKxiPn6Tp/P5u/OMbknJWEp16muPQqAO5ujYmOXaCwJCIiIiIPDI0wOREvn3rUrRdIzrVzFBS58gwHWXXQnehOwdRxd6u089psNv5xMo3/vfsMKVfz6cVBWl++TEGxDcgB3Al9+I88P3t6pdUgIiIiInIvNMLkZHq/Oglww2rL5ZHsZPKKinn/y/OVdr6jqdkMWHGEsZuOkX/1Eq+XxtHifDqFxTmABTeXhgyYNlthSUREREQeSBphcjINw0Kp7dGYgqJUCvLq0M3vGKsPmfiPziF4V+AoU3JmPrG7z7D7ZBpgY4DbQSIuJZNZUAu4OV24f+NWDF7wN1xcXCrsvCIiIiIiFUkjTE6o+5gXASOltiwez/uOvBslrDucUiHHvppfzOydP/HUooPsPplGI0M2Kz2XE5SYSW7BDcCMi8GH7iMmMGzRWwpLIiIiIvJA0wiTE2r+WHvc3wvgRsll8rL8+Lc6p1h72I0RnUOp63Fvo0xFZgtrDyez4kAy+cWlgI1Zjb/DdCqBkyne2Gw3pwuv6x3GsEVv4u5Vu0KvSURERESkMmiEyUl1eL43ACXWTHqbv+D6jVLW3sMok8VqY2vCL3Rd8AUL9pwlv7iUPwXc4PNGyyn85jwZ2QZstgIMhjq0f/oFXlq9WGFJRERERKoNjTA5qXbP9+ar7TsosWSQc8Wfh4NTWHfYlZGdQ6jnabrj/jabjf1nM4mJP82Z9OsANK1bi+URP5B0YBf/L60JVtvN6cI93QMZGjMP70YNK/WaREREREQqmkaYnNjDj0cBYLZkM5Td5BeXsubQnUeZfrqUy9A13zBifQJn0q/j7e5KzJ/q8KnfAg7v+J6UK95YbbkYDO6Et+3BuA1xCksiIiIiUi1phMmJ/ek/X+TEwS+wWK9x7UJ9QoOusP5LF0ZFheJT+/ZRpl+yC1m45wyfHr8MgMnFyIuPBTHZ+wu+/Px9NqU+jMWW9c91AfR/7RUat46o0msSEREREalIGmFyYkajkZCWkQDcKM1ntOn/UmC2sOpQcpntcgtLeCv+FE8uPGAPS30fbcyBUYG8fGUyG9cf4MfzQf8MS640CW7P+A9WKiyJiIiISLWnESYn12vaZJZFf4/Vdp28lLoENM5iw1cuvBQVipe7Kx8cSWXpvkRyi0oA6NSsPq893YLIi/+Hb9ct5+ukTpRYMwFwMfry76NG0bJ7F0dekoiIiIhIhVFgcnJuJhMNmzQn7eL3FJpLmegVz4z84byy7QfOZeRz8VoRAC38vZjesyVdfbMo3TmAtd+5k5v7B/t04b4+4Qxb9CZuHrUce0EiIiIiIhVIgUl4buYrrBw3CputgMJkD+o1vM4XZ26ua1inFlOeakH/RwNw/Xopp7YsYe+5bpgtV4FCjIY6dHq2Px2HDXDoNYiIiIiIVAYFJqG2T13q1Qvm2rUz5BeamOa3nzev92PME80Y9XgontfOYF03jE0nITPjcft04bU9ghkW+zpeDes7+ApERERERCqHApMA0PvViWx8bTJWWy7mxOv8uOQxDK7ucGghFw+8w47EpzCbc4Gb04W3/rcneeov4xxdtoiIiIhIpVJgEgAahIVQ27MpBYXnyc7xwbJnFi4XE/g0qZDUi/+OxZYNQC3XAAbNnEbDls0dXLGIiIiISOXTtOJi99SY/wCMWGxZfLjnB5Z924TkX0L/GZZcCW7WifEfrFJYEhERERGnoREmsWvWqT3u7zXihvkS6Rm+QCEArsb69Bo7nuZdOji2QBERERGRKqYRJimj0/N9/vl/xYCRBn4PM379KoUlEREREXFKGmGSMtr268Xxv/9/8vOvEdX3edr+r96OLklERERExGEUmOQ2I1e94+gSREREREQeCLolT0REREREpBwKTCIiIiIiIuVQYBIRERERESmHApOIiIiIiEg5FJhERERERETKocAkIiIiIiJSDgUmERERERGRclSbwHTy5ElGjBhBu3bt6NChA7NmzaKgoMDRZYmIiIiISA1WLQJTeno6I0aMICgoiK1bt7J69WrOnTvH9OnTHV2aiIiIiIjUYK6OLuD32L9/P66ursyZMwej8WbGmzdvHn369CE1NZXg4GAHVygiIiIiIjVRtQhMZrMZNzc3e1gCcHd3B+Do0aN3HZgsFkuF1ncvbtXwINQizkE9J1VJ/SZVTT0nVUn9VjP83p9ftQhMHTt2JCYmhjVr1hAdHU1RURELFy4EIDMz866Pd+LEiYou8Z49SLWIc1DPSVVSv0lVU89JVVK/OQeHBqYFCxawevXq39wmPj6ehx56iJiYGGJiYnjnnXcwGo0MHz4cPz8/DAbDXZ83MjISFxeXey27QlgsFk6cOPFA1CLOQT0nVUn9JlVNPSdVSf1WM9z6Od6JQwPTyJEj6dev329uExgYCEDv3r3p3bs3V69excPDA4PBwPvvv29ffzdcXFwemOZ+kGoR56Cek6qkfpOqpp6TqqR+cw4ODUy+vr74+vre1T5+fn4AbN++nVq1atG5c+fKKE1ERERERKR6fIYJYNOmTbRp0wZPT0+++uorYmNjmTJlCt7e3o4uTUREREREaqhqE5h+/PFHli5dSkFBAc2aNWPevHk899xzji5LRERERERqsGoTmGJjYx1dgoiIiIiIOJlqE5gqgs1mAx6MOfM1f79UNfWcVCX1m1Q19ZxUJfVbzXDr53crI5THYLvTFjWI2WzWfPkiIiIiImIXGRmJyWQqd71TBSar1UppaSlGo/Ge/n6TiIiIiIjUDDabDavViqurK0ajsdztnCowiYiIiIiI3I3yo5SIiIiIiIiTU2ASEREREREphwKTiIiIiIhIORSYREREREREyqHAJCIiIiIiUg4FJhERERERkXIoMImIiIiIiJRDgUlERERERKQcCkwiIiIiIiLlUGASEREREREphwJTFbNarVgsFkeXIU7OZrM5ugRxIuo3ERGpzlwdXYAzSUxMZMWKFVy9epXg4GD69u1L27ZtHV2WOIGMjAzS0tLIzc3lsccew8XFxdElSQ2mfpOqduXKFZKSksjKyqJr1654eHhgMpkcXZbUYOo552Kw6a2/KpGcnMygQYN44oknaNKkCQcPHsTV1ZW+ffsSHR3t6PKkBjt9+jTjx4/Hzc2NrKwsGjRowIQJE4iKiqJevXqOLk9qGPWbVLXTp0/z0ksv4ePjw+XLl/H29mbQoEH069ePgIAAR5cnNZB6zvkoMFUBm83G4sWLSU1NZfHixQDk5+fzwQcf8I9//INevXoxevRoxxYpNVJ2djZDhw7lqaeeYsCAAZhMJmJiYjhz5gw9e/Zk6NCh+Pr6OrpMqSHUb1LVcnNzGTFiBJ06dWLkyJH4+Pgwf/58jh49SmhoKJMmTaJJkyaOLlNqEPWcc9JnmKqAwWAgIyODq1ev2pd5eXkxfPhw+vTpw+7du/nss88cWKHUVNnZ2RQXF9OjRw8CAwPx9/dn0aJFdOvWjT179vDJJ59QVFTk6DKlhlC/SVUrKCggJyeHqKgo6tevj9FoZOrUqfTp04fU1FTWrFlDdna2o8uUGkQ955wUmCrZrQG8Vq1aYbFYSE5Otq/z8vKif//+tGrVis2bN+uFhFS40tJSLBYLN27cALD/95VXXqFDhw5s2bKF1NRUQB/Ml/tnNpvVb1KljEYj7u7upKenAzef8wCGDRtGjx49+Oabbzh27BignpOKoZ5zTgpMlcxgMADQpUsXUlJSWLNmDQUFBcDNX6S6desyfvx4jh8/TkJCgiNLlRooIiKCBg0a8O677wLg7u6O2WwGYObMmdSrV49Vq1YB/92rIncjIyODxMRE4OYbQ35+fuo3qVRFRUX2vgoICCA4OJgNGzZw/fp1XF1d7S9gR40aRZMmTdi4cSOgnpOKERAQQFBQkHrOySgwVZGgoCAWL17Mrl27WLhwIdnZ2fZfJFdXV8LDw6lTp46Dq5TqrrCwkPz8fPLz8+3LXn/9dRITE5kyZQoAJpPJ/uTevn17CgsLHVKrVH/p6en07t2bxYsXc/z4cQDeeOMNzp49q36TSnH27FkmT57MDz/8YO+lN998k7y8PF5++WXMZjOurv89AXBUVBQWi0V/zkPuWVpaGvHx8ezZs4eff/4ZgLfeeks952QUmKpQx44dWbJkCdu2bWPOnDnEx8eTlJTExo0bycrKolGjRo4uUaqxxMREJk6cyPDhw+nZs6f9c3FhYWHMmDGDL7/8kkmTJlFSUoLRePNXPysrC09PT0pLS3XrgNy18+fPk5+fz/Xr19myZQs///wzLVu2ZPbs2Rw6dIgJEyao36TCnDt3jqFDh+Lv70/Tpk3x9PQEwNfXl4ULF3Lu3DlGjRrF+fPnKS4uBm4GrNq1a+vFq9yTM2fOMGTIENauXcu8efN49913SUlJsfdcUlKSes5JaJY8Bzh58iQxMTFcunQJFxcXjEYjixYtolWrVo4uTaqpxMREhg4dynPPPUfr1q05efIkmzZtYuvWrbRq1YqioiKOHDnCvHnz8PT0pFmzZri5uXHgwAE++ugjWrRo4ehLkGooJyeH6dOn07VrVz766CNCQ0OZOHEiISEh7N27l0WLFmGxWAgLC1O/yX0pLCxk4sSJBAYGMnfuXACSkpIwm834+PgQEBDAuXPnmDx5MqWlpXh7e9OgQQOOHDnCli1biIiIcOwFSLVz6dIlBg8eTN++fRk3bhwJCQnMmDGD9957jz/84Q8A6jknosDkIPn5+eTk5FBQUECDBg001a7cs5ycHKZMmUJoaCgzZ860Lx8+fDjh4eFlluXn5xMXF0dubi61atVi8ODBNG/e3BFlSzVnsVjIzc1l8ODBbNy4kR9//JGVK1cSHh7OhQsXqF+/Pm+88QbLly/n+vXr6je5L2azmRdffJGZM2cSHh7OmDFjyM3NJSkpiYceeoiBAwcycOBAAD744AMyMjIwmUz06tWLZs2aObh6qY4++ugjPv/8czZu3Gj/CMWYMWN48sknMZlMNG7cmA4dOgDqOWfgeudNpDJ4eXnh5eXl6DKkBigtLSUvL4+nn34aAKvVitFopGnTpuTk5AA3Jxix2Wx4eXnx6quvltlO5F4YjUZ8fX2JjIzk7Nmz9OjRA5PJxNSpUykuLua1117Dy8uLqVOnAuo3uT95eXmkpKRw7do1YmNjgZufl8vIyODrr79myZIleHh48OyzzzJ8+HAHVys1gc1m48qVK5w6dYpWrVoRFxfHwYMHKSkpIS8vjytXrjB58mQGDRqknnMC+tdLpJrz8/Nj/vz5tGvXDsB+37S/v7/9BarBYMBoNJaZDEKz98j9uNU/Li4ufPvttwDs2bMHq9VK48aN+f777+0TQfzr9iL3on79+nTq1Il9+/aRmprKiy++SEREBE888QTR0dF06tSJhIQESktLsVqtgKZ0lvvTuXNn/Pz8mDx5MpMmTWLJkiUsW7aMdevWsWrVKp555hl27dpFdna2es4JaIRJpAYICQkBbr6L7+bmBtx84s7KyrJvs3LlSkwmE8OHD8fV1VUvYOW+2Gw2DAYDHTt25OLFi8ydO5cDBw7w8ccfc/r0aWJjY3Fzc6NVq1aYTCb1m9wXg8HAiBEjiI6OpqioiEGDBtnXBQQE4Ofnx4kTJ3BxcbH3mnpO7kdgYCDz58/nxIkTJCUlAdC9e3fgZoBv2LAhCQkJ1K5du8ybk1IzKTCJ1CBGo9H+QvbWY4AlS5YQFxfHp59+Wmb6U5F7davHmjZtyvTp0/Hz82PFihUEBgYSGBiIwWAgPDwck8nk4EqlpoiMjGT16tUMGzaMrVu3EhgYyEMPPQRASUkJISEhlJaW2t80Erlft57Ptm3bxk8//YTZbLY/p2VlZdGkSRPNhuckNOmDSA1z67MiS5cuJTMzk+DgYBYvXsyHH37Iww8/7OjypIYpKSlh586dtG7dmoiIiDKBXaQyJCQk8Je//IWAgABatGhBSUkJ+/btY/PmzZqBUSpFYmIiL7zwAmPHjsXPz49z586xdetWNm3aRHh4uKPLkyqgwCRSQ8XFxbFkyRK8vLxYv349kZGRji5JaihN6CBVLTk5mc8++4wffviB4OBghgwZorAklerrr79m1qxZGI1GGjZsyIwZMzR1uBNRYBKpoU6cOMHAgQP5/PPPNZWziNRItz5sr8AuVSEnJ4fS0lJMJhPe3t6OLkeqkAKTSA1WWFiIp6eno8sQERERqbYUmERERERERMqhMWwREREREZFyKDCJiIiIiIiUQ4FJRERERESkHApMIiIiIiIi5VBgEhERERERKYcCk4iISAWwWq2sWbOGU6dOOboUERGpQApMIiIiFSAuLo6EhARatGhxx20vXrxIeHi4wpWISDXg6ugCRESk5sjMzGTlypUcOHCAtLQ06tSpQ1BQEH369KFfv354eHg4usRfNW3aNHbs2HHb8qioKNauXQtAeHg4y5cvp3v37rdt991337F//342bNiAi4vLHc/XqFEjDh8+jI+Pz/0XLyIilUqBSUREKsQvv/zC4MGDqVOnDn/+858JDw/HZDJx5swZtm7dir+/P08++eSv7ltSUoKbm1sVV1zW448/zttvv11mmclk+l37tmvXjm3btv2ubc1mMyaTiQYNGtx1jSIiUvV0S56IiFSIuXPn4uLiwscff8wzzzxDWFgYgYGBdO/enVWrVtGtWzf7tuHh4WzevJmxY8fy6KOPsmLFCj755BPatWtX5ph79+4lPDzc/njp0qX07duXDz/8kC5duvDII4/w8ssvc/36dfs2VquVZcuW8cQTT9C6dWv69u3LwYMH71j/rRDzr19169YFsNc+YcIEwsPD7Y8vXLjAuHHjeOyxx2jTpg39+/fnq6++KnPcbt26sXz5cv7617/Stm1bZs+e/au35H377bcMGDCA1q1bExUVxYIFCygtLf29334REakkCkwiInLfrl27xpdffsnQoUPx9PT81W0MBkOZx8uWLaNHjx7s2rWL/v37/+5zXbhwgb///e+sWLHCPsnC3Llz7es3btzI+vXrmTp1Kp999hlRUVGMHz+e8+fP38ulAbB9+3YA3n77bQ4fPmx/XFhYSJcuXXj//ffZsWMHXbt2ZezYsVy+fLnM/uvWrSMiIoJPP/2U8ePH33b89PR0xowZQ2RkJDt37mTu3Lls376duLi4e65ZREQqhgKTiIjctwsXLmCz2QgNDS2zvEOHDrRp04Y2bdowf/78MuueffZZ+vfvT2BgII0bN/7d5youLiY2NpaWLVvSvn17Zs6cSXx8PJmZmQCsXbuW0aNH06tXL5o1a8arr75KREQEGzZs+M3j7t+/317rra8VK1YA4OvrC4C3tzcNGjSwP46IiOCFF16gRYsWhISEMHHiRIKDg9m3b1+ZY3fs2JGRI0cSFBREUFDQbefevHkzAQEBzJ49m7CwMLp3787EiRNZt24dVqv1d39vRESk4ukzTCIiUmm2b9+O1WrllVdewWw2l1nXunXrezpmo0aN8Pf3tz9u06YNVquVlJQUPDw8yMjIoG3btmX2adu2LadPn/7N43bo0KHMSBVgvyWvPPn5+SxYsID9+/eTkZGBxWIBuG2E6U7XmpSURJs2bcqMwv3xj3+ksLCQtLS0uwqUIiJSsRSYRETkvgUFBWEwGEhJSSmzPDAwEAB3d/fb9vmft+4ZjUZsNluZZSUlJRVcafk8PDwIDg6+q31iYmI4ceIEcXFxhISE4OHhwcCBA2+r+0GdHVBERO5Mt+SJiMh98/HxoXPnzmzatInCwsJ7PkZBQUGZ/X9tVOjKlSukp6fbHx8/fhyj0UhoaCheXl40bNiQY8eOldnn2LFjNG/e/J7qusXNzc0+gvSv53766adp2bIlHh4e5OXlkZiYeNfHDgsL4/vvvy8TGI8ePUrt2rUJCAi4r7pFROT+KDCJiEiFmDNnDhaLhf79+xMfH09SUhLJycns3LmT5OTkO/59okceeQQPDw/eeecdLly4wK5du/jkk09u265WrVpMmzaN06dP89133/HGG2/Qs2dP+zTdo0aNYvXq1cTHx5OcnMyCBQs4ffo00dHRv3l+s9lMZmZmma/s7Gz7+iZNmnDkyBEyMzPJzc0FIDQ0lPj4eH7++WdOnTrFlClTMBrv/p/WIUOGkJaWxt/+9jeSkpLYu3cvS5cuZcSIEfd0PBERqTi6JU9ERCpEUFAQO3bsYOXKlSxcuJD09HTc3Nxo3rw5I0eOZMiQIb+5f7169Zg/fz6xsbFs27aNTp06MXHiRGbNmnXbeXr06MHo0aPJzc2la9euzJkzx74+Ojqa/Px8YmJiyM7OJiwsjPfee4+QkJDfPP+hQ4eIiooqsyw0NJTdu3cDMHXqVGJiYti2bRv+/v7s27ePadOm8dprrzF48GB8fHwYPXo0N27cuIvv2k3+/v6sWrWK2NhYtm7dSr169RgwYADjxo2762OJiEjFMtj+5w3jIiIiD6ilS5eyd+9edu7c6ehSRETESWicX0REREREpBwKTCIiIiIiIuXQLXkiIiIiIiLl0AiTiIiIiIhIORSYREREREREyqHAJCIiIiIiUg4FJhERERERkXIoMImIiIiIiJRDgUlERERERKQcCkwiIiIiIiLlUGASEREREREpx38BfE+NC3hgv84AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar métricas\n",
        "df_metrics_female"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "s9P5Iz3bKeH8",
        "outputId": "2aed5090-f3d0-4cb8-b390-ad581272cc13"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Local      Sexo Grupo Etário      RMSE      sMAPE       MAE\n",
              "0   Brasil  Feminino            0  0.000330   2.345787  0.000270\n",
              "1   Brasil  Feminino            1  0.000016   2.602196  0.000012\n",
              "2   Brasil  Feminino            5  0.000024  12.556527  0.000024\n",
              "3   Brasil  Feminino           10  0.000006   1.944616  0.000005\n",
              "4   Brasil  Feminino           15  0.000013   2.553614  0.000012\n",
              "5   Brasil  Feminino           20  0.000004   0.604484  0.000003\n",
              "6   Brasil  Feminino           25  0.000020   2.218198  0.000015\n",
              "7   Brasil  Feminino           30  0.000022   2.167954  0.000019\n",
              "8   Brasil  Feminino           35  0.000038   2.630106  0.000033\n",
              "9   Brasil  Feminino           40  0.000074   3.095526  0.000057\n",
              "10  Brasil  Feminino           45  0.000075   2.373533  0.000064\n",
              "11  Brasil  Feminino           50  0.000248   5.674451  0.000223\n",
              "12  Brasil  Feminino           55  0.000438   6.928444  0.000405\n",
              "13  Brasil  Feminino           60  0.000699   7.687572  0.000684\n",
              "14  Brasil  Feminino           65  0.000854   5.967680  0.000824\n",
              "15  Brasil  Feminino           70  0.000439   1.858890  0.000383\n",
              "16  Brasil  Feminino           75  0.001247   2.982412  0.001063\n",
              "17  Brasil  Feminino           80  0.001553   2.134600  0.001330\n",
              "18  Brasil  Feminino           85  0.002026   1.725478  0.001901\n",
              "19  Brasil  Feminino           90  0.000616   0.284663  0.000539"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4f7a745-dffb-403f-8048-07d2d7dbb111\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Local</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Grupo Etário</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>sMAPE</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000330</td>\n",
              "      <td>2.345787</td>\n",
              "      <td>0.000270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>2.602196</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>12.556527</td>\n",
              "      <td>0.000024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>1.944616</td>\n",
              "      <td>0.000005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>15</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>2.553614</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>20</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.604484</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>25</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>2.218198</td>\n",
              "      <td>0.000015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>30</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>2.167954</td>\n",
              "      <td>0.000019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>35</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>2.630106</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>40</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>3.095526</td>\n",
              "      <td>0.000057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>45</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>2.373533</td>\n",
              "      <td>0.000064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>50</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>5.674451</td>\n",
              "      <td>0.000223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>55</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>6.928444</td>\n",
              "      <td>0.000405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>60</td>\n",
              "      <td>0.000699</td>\n",
              "      <td>7.687572</td>\n",
              "      <td>0.000684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>65</td>\n",
              "      <td>0.000854</td>\n",
              "      <td>5.967680</td>\n",
              "      <td>0.000824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>70</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>1.858890</td>\n",
              "      <td>0.000383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>75</td>\n",
              "      <td>0.001247</td>\n",
              "      <td>2.982412</td>\n",
              "      <td>0.001063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>80</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>2.134600</td>\n",
              "      <td>0.001330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>85</td>\n",
              "      <td>0.002026</td>\n",
              "      <td>1.725478</td>\n",
              "      <td>0.001901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Brasil</td>\n",
              "      <td>Feminino</td>\n",
              "      <td>90</td>\n",
              "      <td>0.000616</td>\n",
              "      <td>0.284663</td>\n",
              "      <td>0.000539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4f7a745-dffb-403f-8048-07d2d7dbb111')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4f7a745-dffb-403f-8048-07d2d7dbb111 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4f7a745-dffb-403f-8048-07d2d7dbb111');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-93b14c5b-03c9-48e3-b397-cd9bc956ab13\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93b14c5b-03c9-48e3-b397-cd9bc956ab13')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-93b14c5b-03c9-48e3-b397-cd9bc956ab13 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_acbd862c-ac9b-41e9-93a2-9e8fec878b75\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_metrics_female')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_acbd862c-ac9b-41e9-93a2-9e8fec878b75 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_metrics_female');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_metrics_female",
              "summary": "{\n  \"name\": \"df_metrics_female\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Local\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Brasil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sexo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Feminino\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grupo Et\\u00e1rio\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005811714914549053,\n        \"min\": 4.036478680882586e-06,\n        \"max\": 0.0020256863259751,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.0003300718560201543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sMAPE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.90080923673329,\n        \"min\": 0.2846634810503301,\n        \"max\": 12.556526722522124,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          2.3457871787293474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005281468080716215,\n        \"min\": 3.394428220391296e-06,\n        \"max\": 0.001901289893054961,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.00026960696648359317\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}